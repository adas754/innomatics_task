{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpYuGJYoQu61sTOrt6Mf5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adas754/innomatics_task/blob/main/task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n"
      ],
      "metadata": {
        "id": "Zzv2Q7i75QrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "bZuU-xG75bfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-processing hasan_1 text"
      ],
      "metadata": {
        "id": "I6fbSENKngQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path=\"/content/hasan_1.txt\"\n",
        "output_file_path=\"/content/cleaned_hasan.txt\""
      ],
      "metadata": {
        "id": "-4GgjFUaCOYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(file_path, output_file):\n",
        "    with open(file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line_number, line in enumerate(input_file, start=1):\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove punctuation\n",
        "                doc = nlp(clean_line)\n",
        "                # Spell check and join tokens\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct and not token.text.startswith(('q', 'x'))]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "clean_text(file_path, output_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "-w-OJVe1Dmfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/content/cleaned_hasan.txt\"\n",
        "output_file = \"/content/cleaned_hasan_new.txt\""
      ],
      "metadata": {
        "id": "YzZ2MJAgK1j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "clean_file(input_file, output_file)"
      ],
      "metadata": {
        "id": "koslhlNboM53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-processing bill_text"
      ],
      "metadata": {
        "id": "W5Q6a2jCnoug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_1=\"/content/bill.txt\"\n",
        "output_file_path_1=\"/content/cleaned_output_bill.txt\""
      ],
      "metadata": {
        "id": "0sfzY-PkOdTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(file_path, output_file):\n",
        "    with open(file_path_1, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line_number, line in enumerate(input_file, start=1):\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove punctuation\n",
        "                doc = nlp(clean_line)\n",
        "                # Spell check and join tokens\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct and not token.text.startswith(('q', 'x'))]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "clean_text(file_path_1, output_file_path_1)\n"
      ],
      "metadata": {
        "id": "J1u9p-mlOT7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_1 = \"/content/cleaned_output_bill.txt\"\n",
        "output_file_1= \"/content/cleaned_output_new_bill.txt\""
      ],
      "metadata": {
        "id": "fBRecDeITjHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(input_file_1, output_file_1):\n",
        "    with open(input_file_1, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "    with open(output_file_1, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "clean_file(input_file_1, output_file_1)\n"
      ],
      "metadata": {
        "id": "A9cKLebbYpUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-process ali.txt"
      ],
      "metadata": {
        "id": "_eGofsyGo6S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_2=\"/content/ali.txt\"\n",
        "output_file_path_2=\"/content/cleaned_alii.txt\""
      ],
      "metadata": {
        "id": "gBwaaf97T4V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(file_path, output_file):\n",
        "    with open(file_path_2, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Split the line by whitespace and check the first word\n",
        "                first_word = line.strip().split()[0]\n",
        "                if not first_word.startswith(('q', 'x')):\n",
        "                    # Remove HTML tags\n",
        "                    clean_line = re.sub(r'<.*?>', '', line)\n",
        "                    # Remove URLs\n",
        "                    clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                    # Remove non-printable characters\n",
        "                    clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                    # Remove punctuation\n",
        "                    doc = nlp(clean_line)\n",
        "                    # Spell check and join tokens\n",
        "                    cleaned_tokens = []\n",
        "                    for token in doc:\n",
        "                        cleaned_tokens.append(correct_spelling(token))\n",
        "                    cleaned_line = \" \".join(cleaned_tokens)\n",
        "                    # Remove specified characters\n",
        "                    cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                    # Remove brackets and parentheses\n",
        "                    cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                    # Remove non-ASCII characters\n",
        "                    cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                    # Remove extra white space\n",
        "                    cleaned_line = ' '.join(cleaned_line.split())\n",
        "                    # Remove empty lines after the colon\n",
        "                    if cleaned_line.strip() == '':\n",
        "                        continue\n",
        "                    output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "clean_text(file_path_2, output_file_path_2)\n",
        "\n"
      ],
      "metadata": {
        "id": "xCA0JqmpU814"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path_2=\"/content/cleaned_alii.txt\"\n",
        "output_file_2= \"/content/cleaned_output_new_alis.txt\""
      ],
      "metadata": {
        "id": "sgQXqKo_pGwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(input_file_1, output_file_1):\n",
        "    with open(output_file_path_2, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "    with open(output_file_1, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "clean_file(output_file_path_2, output_file_2)"
      ],
      "metadata": {
        "id": "j17Vfa8mpjPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-process mike.txt"
      ],
      "metadata": {
        "id": "MVLvve6N-OWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_3=\"/content/mike.txt\"\n",
        "output_file_path_3=\"/content/cleaned_mike.txt\""
      ],
      "metadata": {
        "id": "67Lfn_JqppIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(file_path_3, output_file):\n",
        "    with open(file_path_3, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line_number, line in enumerate(input_file, start=1):\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove punctuation\n",
        "                doc = nlp(clean_line)\n",
        "                # Spell check and join tokens\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct and not token.text.startswith(('q', 'x'))]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "clean_text(file_path_3, output_file_path_3)"
      ],
      "metadata": {
        "id": "gHiHMcW0HDnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path_3=\"/content/cleaned_mike.txt\"\n",
        "output_file_3= \"/content/new_mike.txt\""
      ],
      "metadata": {
        "id": "s2QDYXcKHb1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(output_file_path_3, output_file_1):\n",
        "    with open(output_file_path_3, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "    with open(output_file_1, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "clean_file(output_file_path_3, output_file_3)"
      ],
      "metadata": {
        "id": "CGVwuoOaIyqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-processing ricky.txt"
      ],
      "metadata": {
        "id": "9LOlrQYeJa3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_4=\"/content/ricky.txt\"\n",
        "output_file_path_4=\"/content/cleaned_ricky.txt\""
      ],
      "metadata": {
        "id": "TlUMIlz9JXEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(file_path, output_file):\n",
        "    with open(file_path_4, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Split the line by whitespace and check the first word\n",
        "                first_word = line.strip().split()[0]\n",
        "                if not first_word.startswith(('q', 'x')):\n",
        "                    # Remove HTML tags\n",
        "                    clean_line = re.sub(r'<.*?>', '', line)\n",
        "                    # Remove URLs\n",
        "                    clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                    # Remove non-printable characters\n",
        "                    clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                    # Remove punctuation\n",
        "                    doc = nlp(clean_line)\n",
        "                    # Spell check and join tokens\n",
        "                    cleaned_tokens = []\n",
        "                    for token in doc:\n",
        "                        cleaned_tokens.append(correct_spelling(token))\n",
        "                    cleaned_line = \" \".join(cleaned_tokens)\n",
        "                    # Remove specified characters\n",
        "                    cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                    # Remove brackets and parentheses\n",
        "                    cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                    # Remove non-ASCII characters\n",
        "                    cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                    # Remove extra white space\n",
        "                    cleaned_line = ' '.join(cleaned_line.split())\n",
        "                    # Remove empty lines after the colon\n",
        "                    if cleaned_line.strip() == '':\n",
        "                        continue\n",
        "                    output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "clean_text(file_path_4, output_file_path_4)"
      ],
      "metadata": {
        "id": "9pe4ruTRJ15i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_qx(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                if not line.lstrip().startswith(('qx', 'q', 'x')):\n",
        "                    output_file.write(line)\n",
        "\n",
        "remove_qx(\"/content/cleaned_ricky.txt\", \"/content/updated_ricky.txt\")"
      ],
      "metadata": {
        "id": "Up_gPju0lpvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path_4=\"/content/cleaned_ricky.txt\""
      ],
      "metadata": {
        "id": "LGhx5ePUL7Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_qx(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                if not line.lstrip().startswith(('qx', 'q', 'x')):\n",
        "                    output_file.write(line)\n",
        "\n",
        "remove_qx(\"/content/cleaned_ricky.txt\", \"/content/updated_ricky.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfhOSOqpPoyO",
        "outputId": "0fed0557-2aed-48fe-d675-25cb497e3e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines starting with 'qx', 'q', or 'x' removed and saved to updated_ricky.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path_4=\"/content/updated_ricky.txt\"\n",
        "output_files_4= \"/content/new_mikes.txt\""
      ],
      "metadata": {
        "id": "0pc9q7_VYFjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(output_file_path_3, output_file_1):\n",
        "    with open(output_file_path_4, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "    with open(output_file_1, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "clean_file(output_file_path_4, output_files_4)\n"
      ],
      "metadata": {
        "id": "PKMEryr5LfFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-processing html file"
      ],
      "metadata": {
        "id": "PwAIg0gNh7Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def remove_tm_from_word(word, text):\n",
        "    pattern = re.compile(r'\\b' + re.escape(word) + r'\\s*™', re.IGNORECASE)\n",
        "    cleaned_text = pattern.sub(word, text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
        "    cleaned_text = re.sub(r'http[s]?://\\S+', '', cleaned_text)\n",
        "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
        "    cleaned_text = re.sub(r'(\\b\\w+\\b)\\s*™', r'\\1', cleaned_text)\n",
        "\n",
        "    # Remove {} (), [], @, #\n",
        "    cleaned_text = re.sub(r'[{}()\\[\\]@#]', '', cleaned_text)\n",
        "\n",
        "    return cleaned_text.strip()\n",
        "\n",
        "# Read HTML file\n",
        "input_file_path = \"/content/pg5200-images.html\"\n",
        "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Clean HTML content\n",
        "cleaned_content = clean_html(html_content)\n",
        "\n",
        "# Save cleaned text to a new file\n",
        "output_file_path = \"cleaned_output.txt\"\n",
        "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "    file.write(cleaned_content)\n",
        "\n",
        "print(\"Cleaned text saved to:\", output_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11n_bgq2cD0S",
        "outputId": "bdfc66ee-2517-433a-b3cc-e43810b1fa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text saved to: cleaned_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "\n",
        "def remove_tm_from_word(word, text):\n",
        "    pattern = re.compile(r'\\b' + re.escape(word) + r'\\s*™', re.IGNORECASE)\n",
        "    cleaned_text = pattern.sub(word, text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
        "    cleaned_text = re.sub(r'http[s]?://\\S+', '', cleaned_text)\n",
        "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
        "    cleaned_text = re.sub(r'(\\b\\w+\\b)\\s*™', r'\\1', cleaned_text)\n",
        "\n",
        "    # Remove {} (), [], @, #\n",
        "    cleaned_text = re.sub(r'[{}()\\[\\]@#]', '', cleaned_text)\n",
        "\n",
        "    return cleaned_text.strip()\n",
        "\n",
        "def clean_and_save_html(input_file_path):\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    # Clean HTML content\n",
        "    cleaned_content = clean_html(html_content)\n",
        "\n",
        "    # Generate output file path\n",
        "    output_file_path = os.path.splitext(input_file_path)[0] + \"_cleaned.txt\"\n",
        "\n",
        "    # Save cleaned text to a new file\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_content)\n",
        "\n",
        "    print(\"Cleaned text saved to:\", output_file_path)\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your HTML file: \")\n",
        "clean_and_save_html(input_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJSHH3Fowf4r",
        "outputId": "386ac162-b893-412c-9180-2d16622f4ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your HTML file: /content/pg5200-images.html\n",
            "Cleaned text saved to: /content/pg5200-images_cleaned.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove punctuation\n",
        "                doc = nlp(clean_line)\n",
        "                # Spell check and join tokens\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct and not token.text.startswith(('q', 'x'))]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '' or cleaned_line.lstrip().startswith(('qx', 'q', 'x')):\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user for input and output file paths\n",
        "input_file_path = input(\"Enter the path of the input file: \")\n",
        "output_file_path = input(\"Enter the path of the output file: \")\n",
        "\n",
        "clean_text(input_file_path, output_file_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDec6O2zYMDY",
        "outputId": "178a6a05-3f10-41f8-98d1-15e5678a3314"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path of the input file: /content/hasan_1.txt\n",
            "Enter the path of the output file: /content/newhasan.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with x, X, q, Q\n",
        "                if clean_line.lstrip().startswith(('x', 'X', 'q', 'Q')):\n",
        "                    continue\n",
        "                # Remove punctuation\n",
        "                doc = nlp(clean_line)\n",
        "                # Spell check and join tokens\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '').replace('!', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuL4r9Hem30N",
        "outputId": "15d9b9ef-af42-42dc-e8ba-b8d36f286845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/hasan_1.txt\n",
            "Preprocessed file saved as: /content/hasan_1.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#final"
      ],
      "metadata": {
        "id": "TBxobm4Msgwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def correct_spelling(token):\n",
        "    return str(TextBlob(token.text).correct())\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with x, X, q, Q\n",
        "                if clean_line.lstrip().startswith(('x', 'X', 'q', 'Q')):\n",
        "                    continue\n",
        "                # Remove punctuation and lines starting with 'q' or 'x'\n",
        "                doc = nlp(clean_line)\n",
        "                cleaned_tokens = [correct_spelling(token) for token in doc if not token.is_punct and not token.text.startswith(('q', 'x'))]\n",
        "                cleaned_line = \" \".join(cleaned_tokens)\n",
        "                # Remove specified characters\n",
        "                cleaned_line = cleaned_line.replace('?', '').replace('^', '').replace('¦', '').replace('[', '').replace(']', '').replace(',', '').replace('~', '').replace('!', '')\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_line = re.sub(r'[()\\[\\]{}]', '', cleaned_line)\n",
        "                # Remove non-ASCII characters\n",
        "                cleaned_line = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_line)\n",
        "                # Remove extra white space\n",
        "                cleaned_line = ' '.join(cleaned_line.split())\n",
        "                # Remove empty lines after the colon\n",
        "                if cleaned_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{cleaned_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfbx1MZbqwI0",
        "outputId": "18af73b7-07c4-41a1-a270-f97653c370b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ricky.txt\n",
            "Preprocessed file saved as: /content/ricky.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import os\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_file(input_file_path):\n",
        "    output_file_path = os.path.splitext(input_file_path)[0] + \"_cleaned.txt\"\n",
        "\n",
        "    with open(input_file_path, 'r', encoding='latin1') as file:\n",
        "        input_text = file.read()\n",
        "\n",
        "    doc = nlp(input_text)\n",
        "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 1 and not token.is_space]\n",
        "    unique_tokens = []\n",
        "    cleaned_tokens_no_repeat = []\n",
        "\n",
        "    for token in cleaned_tokens:\n",
        "        if token not in unique_tokens:\n",
        "            unique_tokens.append(token)\n",
        "            cleaned_tokens_no_repeat.append(token)\n",
        "\n",
        "    cleaned_text = \" \".join(cleaned_tokens_no_repeat)\n",
        "\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "clean_file(input_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJKrQzRfsJis",
        "outputId": "4fe9d570-1a94-428a-c56e-8633165cccda"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your file: /content/ricky.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove @ also"
      ],
      "metadata": {
        "id": "ezhOgldnx6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q or x, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b|\\bx\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_sAjlEDZx9w1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3745e349-916e-4fe0-c775-613abaf4c65b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q or x, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove {}[](), and words starting with x\n",
        "                clean_line = re.sub(r'[{}\\[\\]\\(\\)]|\\bx\\w*\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXQhRKGbH25I",
        "outputId": "7e0471d4-f35b-410c-e529-c27abc700bc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove {}[](), and standalone 'x'\n",
        "                clean_line = re.sub(r'[{}\\[\\]\\(\\)]|\\b(x)\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGmwa7iMIm-Z",
        "outputId": "f5fca1ce-d32e-4526-daff-6a220d28bf32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove ~, $, . . , and standalone 'x' from words\n",
        "                clean_line = re.sub(r'[~$]|\\.+|\\b(x)\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utBCb7ljJRrC",
        "outputId": "fed12c96-094a-4c13-ff0c-ea644b4faa0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove ~, $, and standalone 'x' from words\n",
        "                clean_line = re.sub(r'[~$]|\\.+|\\b(x)\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v8dJNl8J9Vb",
        "outputId": "1706f7ce-8879-44e3-c699-a797d66b8ca7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove ~, $, and standalone 'x' from words\n",
        "                clean_line = re.sub(r'[~$]|\\.+|\\b(x)\\b', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-oERMOcKX2m",
        "outputId": "8b7dde54-472a-42a8-c304-5e7adce4f18d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove ~, $, and standalone 'x' from words\n",
        "                clean_line = re.sub(r'[~$]|\\.+|\\b(x)\\b', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh3lqGqFLgP9",
        "outputId": "1b6231d9-2fd9-46d3-80b7-34888ce06541"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove 'x' or 'xn' from words\n",
        "                clean_line = re.sub(r'\\b(?:xn?|x)\\b', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjF2ipQL6e4",
        "outputId": "ca29ea52-5dbb-4deb-fb1a-b1195839e339"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    def remove_prefix_regex(text, pattern):\n",
        "        return re.sub(rf\"^{pattern}\", \"\", text)\n",
        "\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove 'x' or 'xn' from words\n",
        "                clean_line = remove_prefix_regex(clean_line, r'[x|xn]')\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EoT2GyoL6-H",
        "outputId": "f3c3d525-9bd8-4b96-c80c-f714b5ab2463"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    def remove_prefix_regex(text, pattern):\n",
        "        return re.sub(rf\"^{pattern}\", \"\", text)\n",
        "\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = clean_line.replace('~', '').replace('$', '')\n",
        "                # Remove 'x' from words like 'xladies'\n",
        "                clean_line = re.sub(r'x', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekEZGl7jOW2v",
        "outputId": "6abf0d60-8d40-4d00-d179-ca7d6bd87eaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = clean_line.replace('~', '').replace('$', '')\n",
        "                # Remove 'xn' and 'x' from words\n",
        "                clean_line = re.sub(r'\\b(?:xn|x)\\b', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1UsDtxTP3Sk",
        "outputId": "facc536a-f32a-4a50-e7ff-581e49c1f323"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = clean_line.replace('~', '').replace('$', '')\n",
        "                # Remove 'xn' and 'x' from words\n",
        "                clean_line = re.sub(r'\\b(?:xn|x)\\b', '', clean_line)\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "# Prompt user to upload file\n",
        "input_file_path = input(\"Upload your file: \")\n",
        "\n",
        "# Preprocess the uploaded file and save the preprocessed version automatically\n",
        "output_file_path = f\"{input_file_path}_preprocessed.txt\"\n",
        "clean_text(input_file_path, output_file_path)\n",
        "print(f\"Preprocessed file saved as: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6b-lPGcP4Wc",
        "outputId": "3ea740be-48ab-428f-eeba-34d9a40476e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your file: /content/ali.txt\n",
            "Preprocessed file saved as: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove lines starting with q, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # remove non-ASCII characters\n",
        "                clean_line = re.sub(r'[^\\x00-\\x7F]+', '', clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove '~' and '$' symbols\n",
        "                clean_line = clean_line.replace('~', '').replace('$', '')\n",
        "                # remove 'x' or 'xn' from the beginning of words\n",
        "                clean_line = re.sub(r'\\b(?:xn?|XN?)\\b', '', clean_line)\n",
        "                clean_line = re.sub(r'\\b(?:x?|X?)\\b', '', clean_line)\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "input_file = input(\"Upload file: \")\n",
        "\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file : {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YIMjKyFQNfz",
        "outputId": "46940f05-8d4a-442c-91a6-2e33538af986"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file : /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn?|XN?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "# Prompt user to input words separated by commas\n",
        "input_words = input(\"Enter words separated by commas: \")\n",
        "words_list = input_words.split(',')\n",
        "\n",
        "# Apply the function to each word and print the results\n",
        "for word in words_list:\n",
        "    cleaned_word = remove_x_prefix(word.strip())\n",
        "    print(f\"Original: {word}, Cleaned: {cleaned_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx2NbGeEWq53",
        "outputId": "b43fc02a-41af-4e96-cb6d-6f4ed06faf6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter words separated by commas: xnladies\n",
            "Original: xnladies, Cleaned: xnladies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove lines starting with x, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # remove 'x' or 'xn' from the beginning of words\n",
        "                clean_line = re.sub(r'\\b(?:xn?|XN?)\\b', '', clean_line)\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkO7YftJYt57",
        "outputId": "f7d42a01-9111-4e57-bd1d-41b2eb78c9a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "# Prompt user to input words separated by commas\n",
        "input_words = input(\"Enter words separated by commas: \")\n",
        "words_list = input_words.split(',')\n",
        "\n",
        "# Apply the function to each word and print the results\n",
        "for word in words_list:\n",
        "    cleaned_word = remove_x_prefix(word.strip())\n",
        "    print(f\"Original: {word}, Cleaned: {cleaned_word}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL10V_tkZx4c",
        "outputId": "85b805c7-062f-48d6-975c-83f9d5b75d9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter words separated by commas: xni\n",
            "Original: xni, Cleaned: i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove lines starting with x, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # apply remove_x_prefix function to each word\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reVJgTKLaLAg",
        "outputId": "4fac105c-8e5d-4c67-ff06-a5b6d8ce5613"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn?|XN?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove lines starting with x, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # apply remove_x_prefix function to each word\n",
        "                cleaned_words = [remove_x_prefix(word) for word in clean_line.split()]\n",
        "                # join cleaned words back into a line\n",
        "                clean_line = ' '.join(cleaned_words)\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NWu3HL1baJR",
        "outputId": "9ccb7f23-5a90-4f2b-cac0-6b7269e78bc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn?|XN?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    def remove_special_characters(text):\n",
        "        # Define a regex pattern to match special characters\n",
        "        pattern = r'[^\\w\\s]'\n",
        "        # Use regex substitution to remove special characters\n",
        "        cleaned_text = re.sub(pattern, '', text)\n",
        "        return cleaned_text\n",
        "\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove lines starting with x, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # apply remove_x_prefix function to each word\n",
        "                cleaned_words = [remove_x_prefix(word) for word in clean_line.split()]\n",
        "                # join cleaned words back into a line\n",
        "                clean_line = ' '.join(cleaned_words)\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj4hfDc5cBa2",
        "outputId": "ce773246-2049-4738-a5f7-5144c035e465"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove 'x' or 'xn' from the beginning of words\n",
        "                clean_line = re.sub(r'\\b(?:xn?|XN?)\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiIrZcvweC5x",
        "outputId": "cf62882b-0fbe-4fc0-b6b6-b933e7ff593b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove 'x', 'xi', 'xn', or 'qx' from the beginning of words\n",
        "                clean_line = re.sub(r'\\b(?:xi?|xn?|qx?)\\b', '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zNXiT2e3rk",
        "outputId": "552cbd0e-2d88-40e6-8fd4-6ac50e2c9daa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Remove lines starting with q, keeping meaningful words starting with q\n",
        "                clean_line = re.sub(r'\\bq(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove lines starting with x, keeping meaningful words starting with x\n",
        "                clean_line = re.sub(r'\\bx(?!u)\\w*\\b', '', clean_line)\n",
        "                # Remove specific phrase €?]q (X ?\n",
        "                clean_line = re.sub(r'€?\\?]q \\(X \\?', '', clean_line)\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Apply remove_x_prefix function to each word\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGi9bHVxe4bL",
        "outputId": "89ffa0d7-18bd-4a2c-e917-0b15c144f93b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove 'x', 'xi', 'xn', or 'qx' from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mTY6MYpgJul",
        "outputId": "40d4130e-6333-4eb2-fddf-a9c4c664c320"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove specific prefixes from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?|qx)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove specific prefixes from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87RIZ3yphMF_",
        "outputId": "abe85137-1741-4b1c-96ee-482038b2eb13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'qx' from words starting with 'q'\n",
        "    if word.startswith('q'):\n",
        "        cleaned_word = re.sub(r'\\bqx\\b', '', word)\n",
        "    # Use regex to remove 'xn' from words starting with 'x'\n",
        "    elif word.startswith('x'):\n",
        "        cleaned_word = re.sub(r'\\bxn\\b', '', word)\n",
        "    # Use regex to remove 'xmy' from any occurrence\n",
        "    else:\n",
        "        cleaned_word = re.sub(r'xmy', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove specified prefixes from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS9RLT1Yh8kT",
        "outputId": "c189053c-5414-47c4-851d-8155bffeb045"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt_preprocessed.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'qx' from words starting with 'q'\n",
        "    if word.startswith('q'):\n",
        "        cleaned_word = re.sub(r'\\bqx\\b', '', word)\n",
        "    # Use regex to remove 'xn' from words starting with 'x'\n",
        "    elif word.startswith('x'):\n",
        "        cleaned_word = re.sub(r'\\bxn\\b', '', word)\n",
        "    # Use regex to remove 'xmy' from any occurrence\n",
        "    else:\n",
        "        cleaned_word = re.sub(r'xmy', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove specified prefixes from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPrtQr8Tii0C",
        "outputId": "63b68fa1-ba56-4e59-c3f5-1768f6a1b862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'qx' from words starting with 'q'\n",
        "    if word.startswith('q'):\n",
        "        cleaned_word = re.sub(r'\\bqx\\b', '', word)\n",
        "    # Use regex to remove 'xn' from words starting with 'x'\n",
        "    elif word.startswith('x'):\n",
        "        cleaned_word = re.sub(r'\\bxn\\b', '', word)\n",
        "    # Use regex to remove 'xmy' from any occurrence\n",
        "    else:\n",
        "        cleaned_word = re.sub(r'\\bxmy\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove specified prefixes from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ5LT0qRjKrz",
        "outputId": "1ffc1d72-4558-4132-e0de-40de19e22e2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'qx' from words starting with 'q'\n",
        "    if word.startswith('q'):\n",
        "        cleaned_word = re.sub(r'\\bq[xX]\\b', '', word)\n",
        "    # Use regex to remove 'xn' from words starting with 'x'\n",
        "    elif word.startswith('x'):\n",
        "        cleaned_word = re.sub(r'\\bx[nN]\\b', '', word)\n",
        "    # Use regex to remove 'xmy' from any occurrence\n",
        "    else:\n",
        "        cleaned_word = re.sub(r'\\bxmy\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Remove specified prefixes from the beginning of words\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyLN0ai8rJz-",
        "outputId": "7f68f93e-d888-4a6d-f9b8-792111902df4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Define a regex pattern to match special characters excluding .,?'\n",
        "    pattern = r'[^\\w\\s.,?\\']'\n",
        "    # Use regex substitution to remove special characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    def remove_x_prefix(word):\n",
        "        # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "        cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "        return cleaned_word\n",
        "\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove special characters\n",
        "                clean_line = remove_special_characters(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove '~' and '$' symbols\n",
        "                clean_line = re.sub(r'[~$]', '', clean_line)\n",
        "                # Apply remove_x_prefix function to each word\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhtR1jkusQ89",
        "outputId": "237a7855-fcd0-43cc-8884-27ccebf9b220"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Define a regex pattern to match all punctuation characters\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    # Use regex substitution to remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_x_prefix(word):\n",
        "    # Use regex to remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = remove_punctuation(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Apply remove_x_prefix function to each word\n",
        "                clean_line = ' '.join(remove_x_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h8pjcKjszJt",
        "outputId": "86c6348e-fca7-475d-ce88-bac8b703d22c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "Preprocessed file: ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                #  remove prefix  to each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmIrAccst2_y",
        "outputId": "bf2ee75e-de5b-4b66-d8d7-0f7b6b42e8f9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'qx', 'xn', and 'x' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:qx|xn|x)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove prefix to each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsVXBkrnxcjW",
        "outputId": "95dfbfa5-0602-48d5-9d60-36a5a3478a2e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # remove prefix to each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOQ888fL1DIU",
        "outputId": "56d03879-57ff-450c-9a66-7feab0dfe1a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "Preprocessed file: ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final 1"
      ],
      "metadata": {
        "id": "zozf-b8RVZOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefix to each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()} \")  # Write line without newline character\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Upload file: \")\n",
        "    output_file = f\"{input_file}_preprocessed.txt\"\n",
        "    clean_text(input_file, output_file)\n",
        "    print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnIM0jQRUUMv",
        "outputId": "5721913c-dead-4be5-d6a3-64e00c2a0c63"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_prefixes(lines, prefixes):\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        for prefix in prefixes:\n",
        "            line = re.sub(f\"^{prefix}\", \"\", line)\n",
        "            line = re.sub(f\"{prefix}\\.$\", \"\", line)\n",
        "        cleaned_lines.append(line)\n",
        "    return cleaned_lines\n",
        "\n",
        "def process_file(input_file, prefixes):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = remove_prefixes(lines, prefixes)\n",
        "\n",
        "    with open(input_file, 'w') as f:\n",
        "        f.writelines(cleaned_lines)\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Enter the path to the text file: \")\n",
        "    prefixes = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\", \"qxø\", \"qxo\", \".qe.\",\"q\",\"aqxæ\",\"q .\",\".qxøso\",\"aqxæmy\",\"q xi\"]\n",
        "\n",
        "    process_file(input_file, prefixes)\n",
        "    print(\"Prefixes removed and file updated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iyWoAgpVXVm",
        "outputId": "82c18170-1624-4e63-a0ee-40a5cc1de56d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the text file: /content/ali.txt_preprocessed.txt\n",
            "Prefixes removed and file updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final 2"
      ],
      "metadata": {
        "id": "1mbi8l1wRCh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefix to each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ardDOWH2RRv",
        "outputId": "7e9db745-92da-499c-8966-18ee47a5bfff"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_prefixes_from_lines(lines, prefixes):\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        for prefix in prefixes:\n",
        "            line = re.sub(f\"^{prefix}\", \"\", line)\n",
        "        cleaned_lines.append(line)\n",
        "    return cleaned_lines\n",
        "\n",
        "def process_file(input_file, prefixes):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = remove_prefixes_from_lines(lines, prefixes)\n",
        "\n",
        "    with open(input_file, 'w') as f:\n",
        "        f.writelines(cleaned_lines)\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Enter the path to the text file: \")\n",
        "    prefixes = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\",\"qxø\",\"qxo\",\".qe.\",\"q xi\"]\n",
        "\n",
        "    process_file(input_file, prefixes)\n",
        "    print(\"Prefixes removed and file updated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGQJP-hE21hF",
        "outputId": "5f7768aa-93a0-474f-8cec-c590d2af195f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the text file: /content/ali.txt_preprocessed.txt\n",
            "Prefixes removed and file updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_prefixes(lines, prefixes):\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        for prefix in prefixes:\n",
        "            line = re.sub(f\"^{prefix}\", \"\", line)\n",
        "            line = re.sub(f\"{prefix}\\.$\", \"\", line)\n",
        "        cleaned_lines.append(line)\n",
        "    return cleaned_lines\n",
        "\n",
        "def process_file(input_file, prefixes):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = remove_prefixes(lines, prefixes)\n",
        "\n",
        "    with open(input_file, 'w') as f:\n",
        "        f.writelines(cleaned_lines)\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Enter the path to the text file: \")\n",
        "    prefixes = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\", \"qxø\", \"qxo\", \".qe.\",\"q\",\"aqxæ\",\"q .\",\".qxøso\",\"aqxæmy\",\"q xi\"]\n",
        "\n",
        "    process_file(input_file, prefixes)\n",
        "    print(\"Prefixes removed and file updated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XozaEKHdSVSN",
        "outputId": "93341844-7e43-4509-e64f-870eea2a2abf"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the text file: /content/ali.txt_preprocessed.txt\n",
            "Prefixes removed and file updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_prefixes(lines, prefixes):\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        for prefix in prefixes:\n",
        "            line = re.sub(f\"^{prefix}\", \"\", line)\n",
        "            line = re.sub(f\"{prefix}\\.$\", \"\", line)\n",
        "        cleaned_lines.append(line)\n",
        "    return cleaned_lines\n",
        "\n",
        "def process_file(input_file, prefixes):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = remove_prefixes_from_lines(lines, prefixes)\n",
        "\n",
        "    with open(input_file, 'w') as f:\n",
        "        f.writelines(cleaned_lines)\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Enter the path to the text file: \")\n",
        "    prefixes = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\",\"qxø\",\"qxo\",\".qe.\"]\n",
        "\n",
        "    process_file(input_file, prefixes)\n",
        "    print(\"Prefixes removed and file updated successfully.\")"
      ],
      "metadata": {
        "id": "1iPGOfzK5f4H"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:xn)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    clean_text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove URLs\n",
        "    clean_text = re.sub(r'https?://\\S+', '', clean_text)\n",
        "    # Remove non-printable characters\n",
        "    clean_text = ''.join(char for char in clean_text if char.isprintable())\n",
        "    # Normalize Unicode characters\n",
        "    clean_text = unicodedata.normalize('NFKD', clean_text)\n",
        "    # Remove punctuation characters\n",
        "    clean_text = rem_punc(clean_text)\n",
        "    # Remove extra white space\n",
        "    clean_text = ' '.join(clean_text.split())\n",
        "    # Remove brackets and parentheses\n",
        "    clean_text = re.sub(r'[()\\[\\]{}]', '', clean_text)\n",
        "    # Remove prefix to each word\n",
        "    clean_text = ' '.join(rem_prefix(word) for word in clean_text.split())\n",
        "    # Convert to lowercase\n",
        "    clean_text = clean_text.lower()\n",
        "    return clean_text\n",
        "\n",
        "def remove_prefixes_from_lines(lines, prefixes):\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        for prefix in prefixes:\n",
        "            # Remove prefix at the beginning\n",
        "            line = re.sub(f\"^{prefix}\", \"\", line)\n",
        "            # Remove prefix at the end followed by period\n",
        "            line = re.sub(f\"{prefix}\\.$\", \"\", line)\n",
        "        cleaned_lines.append(line)\n",
        "    return cleaned_lines\n",
        "\n",
        "def process_file(input_file, prefixes):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = remove_prefixes_from_lines(lines, prefixes)\n",
        "\n",
        "    with open(input_file, 'w') as f:\n",
        "        f.writelines(cleaned_lines)\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Enter the path to the text file: \")\n",
        "    prefixes = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\",\"qxø\",\"qxo\",\".qe.\"]\n",
        "\n",
        "    # Read the content of the input file\n",
        "    with open(input_file, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Clean the text\n",
        "    cleaned_text = clean_text(text)\n",
        "\n",
        "    # Write the cleaned text back to the file\n",
        "    with open(input_file, 'w') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "    process_file(input_file, prefixes)\n",
        "    print(f\"Preprocessed file: {input_file}\")"
      ],
      "metadata": {
        "id": "1ZV7_3Hn8k_W"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Upload file: \")\n",
        "    output_file = f\"{input_file}_preprocessed.txt\"\n",
        "    clean_text(input_file, output_file)\n",
        "    print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGUxZVsG_FBy",
        "outputId": "ab5bda9f-c273-48d6-8fc7-fee3e021cae3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Encode line to UTF-8\n",
        "                encoded_line = line.encode('latin1').decode('utf-8', 'ignore')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', encoded_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefix from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4uImVNIAxRf",
        "outputId": "cce9634c-0ad5-4f5a-da91-b63581a5de13"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import fileinput\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_files, output_file):\n",
        "    with fileinput.input(files=input_files, openhook=fileinput.hook_encoded(\"latin1\")) as f:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in f:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefix from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "def main():\n",
        "    input_files = input(\"Upload file: \").split()\n",
        "    output_file = f\"{input_files[0]}_preprocessed.txt\"  # Using the first file's name for the output\n",
        "    clean_text(input_files, output_file)\n",
        "    print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIyuDnUpBE2r",
        "outputId": "db05e489-4de2-4b48-e865-f4a03fa71dc0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "Preprocessed file: ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import fileinput\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s\\?\\.\\!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_files, output_file):\n",
        "    with fileinput.input(files=input_files, openhook=fileinput.hook_encoded(\"utf-8\", errors='replace')) as f:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in f:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()\\[\\]{}]', '', clean_line)\n",
        "                # Remove prefix from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "def main():\n",
        "    input_files = input(\"Upload file: \").split()\n",
        "    output_file = f\"{input_files[0]}_preprocessed.txt\"  # Using the first file's name for the output\n",
        "    clean_text(input_files, output_file)\n",
        "    print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF18iFyHB80C",
        "outputId": "aada3b11-2634-47cd-ab7f-9ffa370240ee"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file=\"/content/ali.txt\""
      ],
      "metadata": {
        "id": "jVmE5BfMFWzU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'x' or 'xn' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?)', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove unwanted character sequence €\u0003]q (X\t\u0001\n",
        "                clean_line = line.replace('€\u0003]q (X\t\u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefix from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikrMt_uFFaxJ",
        "outputId": "9a93d54b-cfc3-4e75-e063-02d14ef01ec2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove prefixes like 'x', 'xn', 'qx', 'qxn', 'qe', etc. from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:x[nN]?|q(?:x[nN]?|e)?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove unwanted character sequence €\u0003]q (X\t\u0001\n",
        "                clean_line = line.replace('€\u0003]q (X\t\u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz-g0GQaGJe0",
        "outputId": "ba39944c-540e-4368-f9ab-d69e6429c352"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove 'q', 'qx', 'xn', 'xe' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:q|x[nN]?|xe?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove unwanted character sequence €\u0003]q (X\t\u0001\n",
        "                clean_line = line.replace('€\u0003]q (X\t\u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwqf5cJnH_Wb",
        "outputId": "066f0da6-d935-4132-dfa7-4f6d08903a51"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove individual characters and prefixes like 'q', 'qx', 'xn', 'xe' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:q(?:x|e)?|x[nN]?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove unwanted character sequence €\u0003]q (X\t\u0001\n",
        "                clean_line = line.replace('€\u0003]q (X\t\u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                clean_line = ' '.join(rem_prefix(word) for word in clean_line.split())\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "clean_text(input_file, output_file)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIY2RFEcJt-W",
        "outputId": "b33d0c0a-885a-4e7b-abe1-5320ec0f3a55"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_prefix(word):\n",
        "    # Remove individual characters and prefixes like 'q', 'qx', 'xn', 'xe' from the beginning of words\n",
        "    cleaned_word = re.sub(r'\\b(?:q(?:x|e)?|x[nN]?)\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file, min_occurrence=1):\n",
        "    word_counts = Counter()\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        for line in file_in:\n",
        "            # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "            clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "            # Remove HTML tags\n",
        "            clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "            # Remove URLs\n",
        "            clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "            # Remove non-printable characters\n",
        "            clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "            # Normalize Unicode characters\n",
        "            clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "            # Remove punctuation characters\n",
        "            clean_line = rem_punc(clean_line)\n",
        "            # Remove extra white space\n",
        "            clean_line = ' '.join(clean_line.split())\n",
        "            # Remove brackets and parentheses\n",
        "            clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "            # Remove prefixes from each word\n",
        "            cleaned_words = [rem_prefix(word) for word in clean_line.split()]\n",
        "            word_counts.update(cleaned_words)\n",
        "\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file_out:\n",
        "            for line in file_in:\n",
        "                # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "                clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                cleaned_words = [rem_prefix(word) for word in clean_line.split()]\n",
        "                # Remove words based on occurrence count\n",
        "                cleaned_words = [word for word in cleaned_words if word_counts[word] >= min_occurrence]\n",
        "                # Remove empty lines\n",
        "                if cleaned_words:\n",
        "                    file_out.write(f\"{' '.join(cleaned_words).lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "min_occurrence = int(input(\"Enter minimum occurrence count: \"))\n",
        "clean_text(input_file, output_file, min_occurrence)\n",
        "print(f\"Preprocessed file: {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJSSLdb1JvHG",
        "outputId": "9ab9dd0a-efe6-4a9b-a559-e639d14d7cc2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "Enter minimum occurrence count: 2\n",
            "Preprocessed file: ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_q(word):\n",
        "    # Remove only the letter 'q' from words\n",
        "    cleaned_word = word.replace('q', '')\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file, min_occurrence=1):\n",
        "    word_counts = Counter()\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        for line in file_in:\n",
        "            # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "            clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "            # Remove HTML tags\n",
        "            clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "            # Remove URLs\n",
        "            clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "            # Remove non-printable characters\n",
        "            clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "            # Normalize Unicode characters\n",
        "            clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "            # Remove punctuation characters\n",
        "            clean_line = rem_punc(clean_line)\n",
        "            # Remove extra white space\n",
        "            clean_line = ' '.join(clean_line.split())\n",
        "            # Remove brackets and parentheses\n",
        "            clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "            # Remove prefixes from each word\n",
        "            cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "            word_counts.update(cleaned_words)\n",
        "\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file_out:\n",
        "            for line in file_in:\n",
        "                # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "                clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "                # Remove words based on occurrence count\n",
        "                cleaned_words = [word for word in cleaned_words if word_counts[word] >= min_occurrence]\n",
        "                # Remove empty lines\n",
        "                if cleaned_words:\n",
        "                    file_out.write(f\"{' '.join(cleaned_words).lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "min_occurrence = int(input(\"Enter minimum occurrence count: \"))\n",
        "clean_text(input_file, output_file, min_occurrence)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYKakZ9lKV3V",
        "outputId": "97f509fe-8aa7-46b3-a760-5d1b87ee2803"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "Enter minimum occurrence count: 5\n",
            "Preprocessed file: ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_q(word):\n",
        "    # Remove only the letter 'q' from words\n",
        "    cleaned_word = re.sub(r'\\bq\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file, min_occurrence=1):\n",
        "    word_counts = Counter()\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        for line in file_in:\n",
        "            # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "            clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "            # Remove HTML tags\n",
        "            clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "            # Remove URLs\n",
        "            clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "            # Remove non-printable characters\n",
        "            clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "            # Normalize Unicode characters\n",
        "            clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "            # Remove punctuation characters\n",
        "            clean_line = rem_punc(clean_line)\n",
        "            # Remove extra white space\n",
        "            clean_line = ' '.join(clean_line.split())\n",
        "            # Remove brackets and parentheses\n",
        "            clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "            # Remove prefixes from each word\n",
        "            cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "            word_counts.update(cleaned_words)\n",
        "\n",
        "    with open(input_file, 'r', encoding='latin1') as file_in:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file_out:\n",
        "            for line in file_in:\n",
        "                # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "                clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "                # Remove words based on occurrence count\n",
        "                cleaned_words = [word for word in cleaned_words if word_counts[word] >= min_occurrence]\n",
        "                # Remove empty lines\n",
        "                if cleaned_words:\n",
        "                    file_out.write(f\"{' '.join(cleaned_words).lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "min_occurrence = int(input(\"Enter minimum occurrence count: \"))\n",
        "clean_text(input_file, output_file, min_occurrence)\n",
        "print(f\"Preprocessed file: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fB1_vmpLSJ8",
        "outputId": "75a8a64d-56ad-4add-b37a-1fea9c52a563"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Enter minimum occurrence count: 8\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def rem_q(word):\n",
        "    # Remove only the letter 'q' from words\n",
        "    cleaned_word = re.sub(r'\\bq\\b', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "def clean_text(input_file, output_file, min_occurrence=1):\n",
        "    word_counts = Counter()\n",
        "    with open(input_file, 'r', encoding='utf-16le', errors='ignore') as file_in:\n",
        "        for line in file_in:\n",
        "            # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "            clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "            # Remove HTML tags\n",
        "            clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "            # Remove URLs\n",
        "            clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "            # Remove non-printable characters\n",
        "            clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "            # Normalize Unicode characters\n",
        "            clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "            # Remove punctuation characters\n",
        "            clean_line = rem_punc(clean_line)\n",
        "            # Remove extra white space\n",
        "            clean_line = ' '.join(clean_line.split())\n",
        "            # Remove brackets and parentheses\n",
        "            clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "            # Remove prefixes from each word\n",
        "            cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "            word_counts.update(cleaned_words)\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-16le', errors='ignore') as file_in:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file_out:\n",
        "            for line in file_in:\n",
        "                # Remove unwanted character sequence €\u0003]q (X    \u0001\n",
        "                clean_line = line.replace('€\u0003]q (X    \u0001', '')\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', clean_line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = rem_punc(clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove brackets and parentheses\n",
        "                clean_line = re.sub(r'[()[]{}]', '', clean_line)\n",
        "                # Remove prefixes from each word\n",
        "                cleaned_words = [rem_q(word) for word in clean_line.split()]\n",
        "                # Remove words based on occurrence count\n",
        "                cleaned_words = [word for word in cleaned_words if word_counts[word] >= min_occurrence]\n",
        "                # Remove empty lines\n",
        "                if cleaned_words:\n",
        "                    file_out.write(f\"{' '.join(cleaned_words).lower()}\\n\")\n",
        "\n",
        "input_file = input(\"Upload file: \")\n",
        "output_file = f\"{input_file}_preprocessed.txt\"\n",
        "min_occurrence = int(input(\"Enter minimum occurrence count: \"))\n",
        "clean_text(input_file, output_file, min_occurrence)\n",
        "print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGMkWAFqMcQM",
        "outputId": "b501a651-e96d-4e3c-f7de-31548e1fc340"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Enter minimum occurrence count: 4\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove unwanted character sequence €\u0003]q (X \u0001\n",
        "    cleaned_text = text.replace('€\u0003]q (X\t\u0001', '')\n",
        "    # Remove HTML tags\n",
        "    cleaned_text = re.sub(r'<.*?>', '', cleaned_text)\n",
        "    # Remove URLs\n",
        "    cleaned_text = re.sub(r'https?://\\S+', '', cleaned_text)\n",
        "    # Remove non-printable characters\n",
        "    cleaned_text = ''.join(char for char in cleaned_text if char.isprintable())\n",
        "    # Normalize Unicode characters\n",
        "    cleaned_text = unicodedata.normalize('NFKD', cleaned_text)\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = rem_punc(cleaned_text)\n",
        "    # Remove extra white space\n",
        "    cleaned_text = ' '.join(cleaned_text.split())\n",
        "    # Remove brackets and parentheses\n",
        "    cleaned_text = re.sub(r'[()[]{}]', '', cleaned_text)\n",
        "    return cleaned_text\n",
        "\n",
        "# Original text\n",
        "text = \"\"\"€\u0003]q (X\t\u0001  Ladies and gentlemen, please welcome to the stage: Ali Wong! Hi. Hello! Welcome! Thank you! Thank you for coming. Hello! Hello. We are gonna have to get this shit over with, â€™cause I have to pee in, like, ten minutes. But thank you, everybody, so much for coming.q\u0001Xg\u0007  Umâ€¦ Itâ€™s a very exciting day for me. Itâ€™s been a very exciting year for me. I turned 33 this year. Yes! Thank you, five people. I appreciate that. Uh, I can tell that Iâ€™m getting older, because, now, when I see an 18-year-old girl, my automatic thoughtâ€¦ is â€œFuck you.â€ â€œFuck you. I donâ€™t even know you, but fuck you!â€ â€˜Cause Iâ€™m straight up jealous. Iâ€™m jealous, first and foremost, of their metabolism. Because 18-year-old girls, they could just eat like shit, and then they take a shit and have a six-pack, right? They got that-that beautiful inner thigh clearance where they put their feet together and thereâ€™s that huge gap here with the light of potential just radiating through. And then, when they go to sleep, they just go to sleep. Right? They donâ€™t have insomnia yet. They donâ€™t know what itâ€™s like to have to take a Ambien or download a Meditation Oasis\"\"\"\n",
        "\n",
        "# Preprocessed text\n",
        "preprocessed_text = clean_text(text)\n",
        "print(preprocessed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uxW4CloOfuW",
        "outputId": "f534c283-3b39-4ea8-a164-3017efa285f4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ladies and gentlemen please welcome to the stage Ali Wong! Hi. Hello! Welcome! Thank you! Thank you for coming. Hello! Hello. We are gonna have to get this shit over with aTMcause I have to pee in like ten minutes. But thank you everybody so much for coming.qXg Uma ItaTMs a very exciting day for me. ItaTMs been a very exciting year for me. I turned 33 this year. Yes! Thank you five people. I appreciate that. Uh I can tell that IaTMm getting older because now when I see an 18yearold girl my automatic thoughta is aœFuck you.a aœFuck you. I donaTMt even know you but fuck you!a a Cause IaTMm straight up jealous. IaTMm jealous first and foremost of their metabolism. Because 18yearold girls they could just eat like shit and then they take a shit and have a sixpack right? They got thatthat beautiful inner thigh clearance where they put their feet together and thereaTMs that huge gap here with the light of potential just radiating through. And then when they go to sleep they just go to sleep. Right? They donaTMt have insomnia yet. They donaTMt know what itaTMs like to have to take a Ambien or download a Meditation Oasis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def rem_punc(text):\n",
        "    # Match all punctuation characters except '?', '.', and '!'\n",
        "    pattern = r'[^\\w\\s?.!]'\n",
        "    # Remove punctuation characters\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_text(input_file):\n",
        "    encodings = ['utf-8', 'latin-1', 'utf-16']\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(input_file, 'r', encoding=encoding) as file:\n",
        "                text = file.read()\n",
        "                # Remove unwanted character sequence €\u0003]q (X \u0001\n",
        "                cleaned_text = text.replace('€\u0003]q (X\t\u0001', '')\n",
        "                # Remove HTML tags\n",
        "                cleaned_text = re.sub(r'<.*?>', '', cleaned_text)\n",
        "                # Remove URLs\n",
        "                cleaned_text = re.sub(r'https?://\\S+', '', cleaned_text)\n",
        "                # Remove non-printable characters\n",
        "                cleaned_text = ''.join(char for char in cleaned_text if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                cleaned_text = unicodedata.normalize('NFKD', cleaned_text)\n",
        "                # Remove punctuation characters\n",
        "                cleaned_text = rem_punc(cleaned_text)\n",
        "                # Remove extra white space\n",
        "                cleaned_text = ' '.join(cleaned_text.split())\n",
        "                # Remove brackets and parentheses\n",
        "                cleaned_text = re.sub(r'[()[]{}]', '', cleaned_text)\n",
        "            return cleaned_text\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    raise ValueError(\"Unable to decode file using any available encoding.\")\n",
        "\n",
        "# Example usage with file upload\n",
        "input_file = input(\"Upload file: \")\n",
        "preprocessed_text = clean_text(input_file)\n",
        "print(preprocessed_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyWIMgQkOg8a",
        "outputId": "6153da79-595c-47b3-d298-d05a6d43b8e3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: ali.txt\n",
            "qXLadies and gentlemen please welcome to the stage Ali Wong! Hi. Hello! Welcome! Thank you! Thank you for coming. Hello! Hello. We are gonna have to get this shit over with acause I have to pee in like ten minutes. But thank you everybody so much for coming.qXgUma Itas a very exciting day for me. Itas been a very exciting year for me. I turned 33 this year. Yes! Thank you five people. I appreciate that. Uh I can tell that Iam getting older because now when I see an 18yearold girl my automatic thoughta is aFuck you.a aFuck you. I donat even know you but fuck you!a aCause Iam straight up jealous. Iam jealous first and foremost of their metabolism. Because 18yearold girls they could just eat like shit and then they take a shit and have a sixpack right? They got thatthat beautiful inner thigh clearance where they put their feet together and thereas that huge gap here with the light of potential just radiating through.And then when they go to sleep they just go to sleep. Right? They donat have insomnia yet. They donat know what itas like to have to take a Ambien or download a Meditation Oasis podcast to calm the chatter of regret and resentment towards your family just cluttering your mind. They have their whole lives ahead of them. They donat have HPV yet. They just go to sleep in peace at night. Everybody has HPV OK? Everybody has it. Itas OK. Come out already. Everybody has it. If you donat have it yet you go and get it. You go and get it. Itas coming. You donat have HPV yet youare a fucking loser all right? Thatas what that says about you. A lot of men donat know that they have HPV because itas undetectable in men. Itas really fucked up. HPV is a ghost that lives inside menas bodies and says aBoo!a in womenas bodies. My doctor told me that I have one of two strains of HPV. Either I have the kind thatas gonna turn into cervical cancera aor I have the kind where my body will heal itself. Very helpful this doctor right? So basically either Iam gonna diea or youare in the presence of Wolverine bitches. Weall find out.qXUm I can also tell that Iam getting older because my Kindle is turning into a selfhelp library. Iam not interested in books like Fifty Shades of Grey OK? Iam interested in The LifeChanging Magic of Tidying Up. Yes. Yes thatas right how to declutter my home to achieve inner peace and my optimum level of success. Thatas what your 30s is all about. How can I turn this shit around? Iam a horrible person Iam not happy with where I am how can I turn this shit around? Help me Tony Robbins help me!I have a hoarding problem which Iam hoping is the center of all of my other problems. Iam hoping that if the hoarding goes away the HPV will also disappear. I have a hoarding problem because my mom is from a third world country and she taught me that you can never throw away anything because you never know when a dictatoras gonna overtake the country and snatch all your wealth. So you better hold onto that retainer from the third grade acause it might come in handy as a shovel when youare busy stuffing gold up your butt and running away from the Communists.The last time I was at home in San Francisco I was trying to help her get rid of shit. Donat ever do that with your mom. It was like the worst experience of my life. It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI82a manual. The manual. She donat even knowa where the calculator is. Those of you under 25 probably donat know what that calculator is. It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like 200. And everybody thought it was like this Judy Jetsonas laptop from the future. All because what? It could graph. It was like the Tesla of my time. And my mom got so emotional about the manual and she was like aYou never know when you might need this.a And I was like aButa I do knowa that Iam gonna have to clean all this shit up when you die.a aAnd Iam not trying to be a procrastinator anymore. Because according to DeepakOprah thatas not the way for me to achieve my optimum level of success.aqXCI grew up a lot this past year. Uh this past year I also got married. Yeah. To a man who now has HPV. Very lucky guy. He gave me something. I gave him something. That will also last forever. No really. Iam the lucky girl because before him I dated a lot of losers. Lots of losers. A lot of skaters. You wanna be a grownass woman stop dating skaters. Stop dating skaters unless you wanna wake up on a mattress in a kitchen. Theyare sexy on the outside malt liquor on the inside. Horrible. But my husband I first met him at this wedding and uh heasa heas much better looking than me heas way out of my league and I saw him and I was like aOh my God who is that?a And the first thing I learned about him was that at the time he was attending Harvard Business School. And I was like aOh my God Iam gonna trap his ass.a aGoing to trap his ass!a And I trapped his ass initially by not kissing him until the fifth date which is a very unusual move on my part. But I did it on purpose because I knew that he was a catch. So I was like aAll right Ali you gotta make this dude believe that your body is a secret garden.a When really itas a public parka athat has hosted many reggae festsa aand has even accidentally leta two homeless people inside. I thought they were hipsters OK? That store Urban Outfitters has made things very confusinga for my generation. You homeless or you a hipster? Is that beard for fashion or for warmth? It happened toa It happened in San Francisco when I was living there and I saw this guy in broad daylight and we had like we hada We had so much chemistry. He was like aHey wassup?a I was like aWassup?a And wea The next thing I knew we were getting busy in the back of my Volvo. And then after we were done he was like aHey can you drop me off?a I was like aWhere?a He was like aAt the park.a And I dropped him off at Golden Gate Park and watched him run into the middle with all his other homeless friends and I was like aOh no!a aI just fucked a homeless dude! Again!aqXMy husband is Asian. Which a lot of people are shocked by because usually AsianAmerican women who like you know wear these kinda glasses and have a lot of opinions they like to date white dudes. You go to any hipster neighborhood in a major city in America and that shit is turning into a Yoko Ono factory. Itasa too much. I donat know whatas wrong with these bitches. I get it you know because being with a white dude you feel verya You feel very picturesque when youare with a white dude you know. You feel like youare in a Wes Anderson movie or something. And you know white dudes they teach you about a lot of cool stuff like voting and recycling and disturbing documentaries. They introduce you to cool stuff like that and itas very you know itas hot hookina up with a white dude. I mean nothing makes me feel more powerful than when a white dude eats my pussy. Oh my God. I just feel like Iam absorbing all of that privilege and all of that entitlementa ayou know just right there through the money hole and justa And then also heas so vulnerable down there. Iam like aI could just crush your head at any moment white man! I could just kill you right now! Crush those brains! Colonize the colonizer!a You know?But I think that for marriage it can be nice to be with somebody of your own race. The advantage is that you get to go homea and be racist together. You get to say whatever you like! You donat gotta explain shit. My husband halfFilipino halfJapanese. Iam halfChinese and halfVietnamese. And we spend 100 percent of our time shitting on Korean people. Itasa amazing. Itas what love is built on you know?My last boyfriend was Cuban and his family would shit on Mexican people all the time. And I was like aHold it. You guys arenat Mexican?a AsianAmerican men are very underrated. I donat know why people donat go for them. Theyare the sexiest. Asian men are the sexiest. They got no body hair from the neck down. Itas like making love to a dolphin. Oh my God. Itas so smooth just like a slip and slide. Just black fish Tilikum all up in my bed every night you know? Oohwee. You mess with a Jewish dude and your body is all fucked up afterwards. Itas all red and inflamed and youare like aI did not ask to be exfoliated today.a aThis is the last time I go on Jdate more like loofah date. Thanks for the rug burn Avi.a And then Asian men no body odor. None. They just smell like responsibility. Thatas where the umami flavor comes from.I think my husband and I have a huge unspoken understanding uh between each other because heas halfFilipino and halfJapanese and Iam halfChinese and halfVietnamese. So weare both halffancy Asiana aand halfjungle Asian. Yeah! You guys know the difference. The fancy Asians are the Chinese the Japanese. They get to do fancy things like host Olympics. Jungle Asians host diseases. Itasa Itas different. But he grew up on the East Coast going to private school playing lacrosse uh you know learning Latin and playing chess and rugby. He grew up like Filipino Carlton OK? So he didnat know anything about Vietnamese people until he met me. And on one of our first dates he took me to this restaurant on the west side of Los Angeles called Pho Show. He was like aItas authentic Vietnamese. I read about it on Yelp!a I was like aItas not authentic OK?a You can tell first and foremost by the name acause it donat got a number in it. Second of all you can tell by the bathroom. If it was legit the bathroom would double as a supply closet. When I pee I need to see ten gallons of bleach an ATM machine and a grandma with glaucoma napping in the corner. And the wait staff here is too nice. We need to leave this restaurant deaf and emotionally abused.qXI grew up going to private school too. Him and I are both total like private school Asians. We both are big hippies too. We like to backpack through Southeast Asia. We like to do yoga. We do ayahuasca ceremonies. We do silent meditation retreats. Thatas right we pay 800 to shut up for a weekend. We do shit like that. Uh we eat glutenfree which means we eat all that bread that tastes like freerange Chewbacca. We eat that lesbian bread thatas likea aa thousand percent of your daily fibera and 20 percent spoken word poetry. When you eat it you queef a shitty poem abouta asupporting Caitlyn Jenner or whatever. And so itas funny right because heas Asian too. But sometimes all of this hippydippy shit we doa makes me feel like we are white people doing an impression of Asian people. Like we have these Chinese scrolls up on the walla and neither of us know what the fuck they mean. Weare like aOh that seems to go very well with our Buddha piggy bank from Pier 1 Imports. That seems to be providing some good feng shui for the house.qXHim and I had been dating for four years and Ia I just had this sneaking suspicion that he was gonna proposea becausea I had been pressuring him to do it. So you know I just had this wacky womenas intuition. Thatas how proposals really work OK? A woman has to incept the idea into the manas head. First passively and then if he doesnat get the message extremely aggressively. You gotta threaten to leave without ever actually leaving because you know that youare too old and itas too late to go back out there and find a new man and start the whole manipulation cycle all over again. So youare like aIam just gonna stick with this dude focus on trapping this dude and just nag the shit outta him until he becomes weak and caves in and gets fed up and is like aShut the fuck up! Fine will you marry me?a And then afterwards the woman is always like aOh my God! He proposed!a aIt came outta nowhere. And look he got me the exact ring I wanted. How did he know? Maybe he saw it on my Pinterest page or somethinga that I sent to my best friend that I told her to send to him every day.a Let me tell you something. If a man has a Pinterest pagea heas probably Pinterested in men. We got engaged on a Saturday. I bought my wedding dress the following Tuesdaya because I had tried it on in 2012. I was ready. I was ripe. I was rotten. I need to be made into banana bread. Thatas how rotten I was.qXPeople are always very surprised at how offstage with my husband Iam a completely different person. Youa Like you would not recognize my personality at all with him. With him Iam very soft and like very nurturing and very domestic. Weave been together now for five years and for five years Iave packed his lunch every single day. Yeah. Yes. Yes. Yes. I did that so that head become dependent on me. aCause he graduated from Harvard Business School and I donat wanna work anymore. I donat. I straight up donat wanna work anymore. I donat feed him out of the goodness of my heart. I do it as an investment in my financial future. aCause I donat wanna work anymore. Iave been reading that book by Sheryl Sandberg sheas the C.O.O. of Facebook and she wrote that book that got women all riled up about our careers. Talking about how we as women should challenge ourselves to sit at the table and rise to the top. And her book is called Lean In. Well I donat wanna lean in OK? I wanna lie down. I want to lie the fuck down. I think feminism is the worst thing that ever happened to women. Our job used to be no job. We had it so good. We could have done the smart thing which would have been to continue playing dumb for the next century and be like aWeare dumb women. We donat know how to do anything. So I guess we better just stay at home all day and eat snacks and watch Ellen.a aaCause weare too stupid to have any real responsibility.a And then all these women had to show off and be like aWe could do it! We could do anything.a aBitch shut up!a aDonat tell them the secret.a They ruined it for us and now weare expected to work. When I hear the phrase aDoubleincome householda I wanna throw up. A lot of women get very upset with me about those comments. And theyare like aBut Ali we have so many more options now.a Oh you donat think we had a lot of options when our day was free? Unscheduled unsupervised and most importantly sponsored? Do you know how much shittier food tastes when you know you have to earn it?A lot of my friends when we walk around together theyall get very judgmental about housewives that weall see on the street. And theyall be like aLook at that fucking housewife. Not doing anything. Look at that housewife just walking around all day getting massages in her Lululemon pants.a Iam like aThat bitch is a genius.a aSheas not a housewife sheas retired.aI do write for Fresh Off the Boat on ABC. Yeah. Which isa Itas a great show. I love it a lot. I love my coworkers. Itas a great writing staff and in terms of day jobs itas probably one of the best you could ask for but I still gotta work at a office every day. Which means I gotta shit in a office every day. Housewives they donat gotta shit in a office. Housewives get to shit in their house. Skin to seat. They donat gotta use that horrible toilet paper cover. They donat gottaa aten times a day every daya like youare about to eat a sadass meal. They donat gotta do that. They donat gotta use that oneply toilet paper that office toilet paper that they purposely make difficult to pull out. They try to ration me with their communist toilet paper thatas not even effective. It basically just dehydrates your butt hole. Itas basically like wiping your butt with the desert. I literally spat on my toilet paper two days ago to try to make a MacGyver baby wipe to moisten it and then it backfired acause my fingers broke through and digitally stimulated more doo doo to come out and then I had to start all over again. And you can never finish wiping at work because you always feel rushed acause youare paranoid that your coworkeras gonna recognize your shoes underneath the stall. And youare like aOh no! Courtneyas listening. Sheas waiting. Sheas timing me.a And then you hurry hurry hurry and then you never finish wiping and then your butt hole feels caked in doo doo all day long. And then if you dare scratch yourself your underwear at the end of the day looks like itas been run over by the Goonies. Housewives they donat gotta muffle their shit too. They donat gotta worry about the velocity with which their doo doo comes out. They donat gotta try to you know squeeze the butt cheeks together to make sure that the doo doo comes out at a slow and steady pace so that no unpredictable noise suddenly escapes and brings you deep deep shame. Housewives are free to just blow ass into the toilet and let it echo and reverberate to the ends of their hallways while watching as much Netflix on their iPad as they want. They donat gotta take these boring repressed shits. They can listen to podcasts. Planet Money. They can do whatever they want.You know itasa itas very distracting for me when I hear my coworkers blow ass into the toilet. I lose respect for them. Nothing they say to me anymore holds any sort of credence. I heard one of my coworkers blow ass into the toilet the other day. This bitch had the nerve to come up to me and say aYou need to get to work on time.a I was like aYou need to eat bananas.a aI saw those green ballet flats. I know that shit was you. Donat try to tell me to get my shit together when I heard you not have your shit together.aqXæMy fatherinlaw had this huge sitdown with me and my husband recently. Um and he was like aHey I wanna talk to you guys about money. You guys need to make a lot more money if you wanna provide your children with the same kind of privileged childhood that you guys had.a I was like aWhy you telling me this shit? I should not be a part of this conversation. You tell you son that. Donat your understand that I trapped your son for his earning potential? Why else would I choose to fuck one person for the rest of my life? I chose to marry him on the promise of early retirement and when I said aI doa what I really meant was aOh Iam done.a Iam done. I donat wanna work anymore and Iam not dieting anymore. Since I got married last year Iave been eating fried chicken skin every day since. Thatas right. And just fulfilling my destiny. Which is to turn into a circle with eyelashes. Like Mrs. Pacman justa Letas redecorate.I gave up a lot of myself when I got married. Iam aa Iam a disgusting pervert. Iam a pervert. Iam a gross filthy animal. And I think itas because I started watching porn at a very young age. And what happens when you start watching porn at a young age is thata yyou get sicker and sicker and sicker. The images you crave get sicker and sicker and sicker but itas OK because the Internet will always catch up to you.I broke up with my last boyfriend because he refused to put it in the back. I was like aUh youare a idiot dude. Do you realize that if I went on Craigslista and posted aTiny Asian female seeking analaa the Internet would crash.a aAnd all the Jewish male heads in the universe would simultaneously explode.a They would explode. A lot of women get really you knowa freaked out about anal. And theyare like aOh I donat wanna do that. Iam scared ofa of the pain.a You ainat scared of the pain. Women they wax their eyebrows they do all sorts of crazy shit. Youare not scared of the pain. What youare really scared of is doo doo on the dick. Youare scared that heas gonna see that and thatas gonna be all of your shame your inner evil all your secrets and lies. Sephora canat help you now. But donat worry acause when he puts it in the butt all heas thinking about is aI just put it in her butt.a aI gotta go call my mom my dad Dave my grandma.a Youarea If youare married youare gonna have to do anal eventually OK? You have to because you gotta change it up. You gotta change it up so that you donat cheat on each other. You gotta keep it interesting. If you put it in different holes maybe youall feel like youare fucking different people. I was very sexually active in my 20s and as a result Iam a little bita astretched out down there OK? So when I finally did anal I just felt like I got a second chance at life you know? I was like aOh my God! Itas like Iam going back in time!a aa A whole new world aa It was magical.qXeA big fantasy of mine before I got married was to help as many men as possible discover their prostate. Yeah like a conqueror. I just wanted toa Now if you havenat done it before ladies go home and treat yourself. Do it tonight. You only live once. YOLO. Just sneak youra Just give your man a littlea a little pushpush in the tushtush. Just give him a little Atari you know and youall get a lot of resistance from the man at first. Youall get a lot of aNo! No! No! No please! No really I donata No! I donat! I donat! No!a They get all squirmy wormy becausea theyare scared. Theyare scared that if you stick your thumb up there and succeed and they like it that then it might mean that theyare gay. And I like that fear. That shit turns me on you know? Especially when that fear metamorphosizes into pleasure. Oh my God! And you just see the look in the manas eye like heas discovered nirvana. And itas like youare the first lady to show him that he had a magical clit in his butt hole. And then you as the woman in his eyes just become the Lord of the Rim you know?qXNMy husband is unfortunately just not as freaky as me. Whena When Iave asked him to spank me this is what he does. aHey. Hey are you OK? Are you all right? You know I respect you right?a Iam like aYes I know you respect me and thatas why you need to abuse me. OK?a aCause itas the most strongheaded loudmouthed women who like to be abused the most in bed. Women who are C.E.O.s they just wanna be roughed around. They just want theira Glasses always means the woman wants somea Itas because weare so in control all the time that we just wanna experience some risk and be out of control you know? Like aI donat wanna die! Donat kill me! I donat wanna die!a But I also donat want to be sure that Iam gonna live. You know? I just wanna be out of control for once. Justa Just choke me enough so that I canat talk. aCause if I can talk Iam gonna tell you what to do. And Iam tired of being the boss. Iam the boss all the time so in the bedroom you be the boss. Yes. Because Iam the real boss. And I told you so motherfucker so do it.qXESheryl Sandberg that woman who wrote Lean In has had such a big impact that now because of her there is a ban on the word abossya in elementary schools because according to her itas sexist to use the word abossya because boys are never called bossy. So now instead of saying aYouare bossya youare supposed to say aYou have executive leadership skills.a Which is a very roundabout way of saying aYouare a little cunt.aqXßIam just waiting for the right moment to like become a housewife financially you know? I want my husband to get us to like a certain point financially. I wanna get to the point as a couple where I can comfortably afford sliced mango. Know what Iam talking about? Iam talking about that Whole Foods mango. That 10abox Whole Foods mango that was sliced by white people. Thatas the kind of income bracket Iam striving for. Thatas when you know youave made it when youare eating mango that was sliced by a dude named Noah. I want Noah mangoa aRebecca kiwi Danielle pineapple. You know what else I want? I wanna be able to take a stroll on a sidewalk see a quarter and just keep on walking. Like a princess.qXI have some useful advice for all my AsianAmerican brothers and sisters. Yeah! Never go paintballing with a Vietnam veteran.qXSo I donat know if you guys can tell but I am seven and a half months pregnant. Yeah. Itas very rare and unusual to see a female comic perform pregnant because female comicsa donat get pregnant. Just try to think of one. I dare you. Thereasa None of them. Once they do get pregnant they generally disappear. Thatas not the case with male comics. Once they have a baby theyall get up on stage a week afterwards and theyall be like aGuys I just had this fucking baby. That babyas a little piece of shit. Itas so annoying and boring.a And all these other shitty dads in the audience are like aThatas hilarious. I identify.a And their fame just swells because they become this relatable family funny man all of a sudden. Meanwhile the mom is at home chapping her nipples feeding the fucking baby and wearing a frozen diaper acause her pussy needs to heal from the babyas head shredding it up. Sheas busy. So I donat know whatas gonna happen to me. You know a lot of my female standup comic friends who are a lot more successful and famous than me discouraged me from having a kid. And they were like aAli why are you gonna have a kid? You just gonna becomea Youare gonna disappear and youare gonna become some lame stayathome mom.a I was like aYeah thatas the dream.a Thatas the point. This is the ultimate trap. I won you know?Another thing a lot of my friends said to me when they were discouraging me from having a kid they were like aWhy are you gonna have a kid? Why donat you just travel the world with your husband and just do whatever you want for the rest of your lives with no kid attached.a I was like aYeah thatas coola until my husband dies.a Which heas definitely gonna before me. Because Iam a Asian woman and therefore guaranteed to live until Iam a billion. Iam guaranteed like a turtle from the Galapagos OK? We all know the phrase ablack donat crack.a Well Asian donat die. We donat die. Especially the women we live forever. And you know why weare such bad drivers? Because weare trying to die. Weare like aYeah! Let me see how invincible I really am!a aImma make this left hand turn signal and ignore this red light completely.a aIam gonna make a right turna I changed my mind itas a Uturn!a aI changed my mind again. Itas a Oturn!a Every time I get into a car accidenta aIam like aOh my God not again!a I need to hide my face so that everybody doesnat see that itas what everybody thought it was gonna be. So embarrassing. My Toyota Corolla is a mess. Thereas this huge bear claw scratch on the side from this aggressive brick wall that came out of nowhere. And then on the hood thereas multiple hand prints from pedestrians who have had to alert me of their existence. I donat know whatas wrong with me but Iam still here you know?qXI need to have children to keep me company when I get older. Itas lonely. My mom is 80 going through a full blown midlife crisis. aCause she knows that sheas got a century more to go. And she is so lonely. All of her white friends dead. Her Mexican friends dead. Black friends dead. Iam just kidding. She doesnat have any black friends. Life is not Rush Hour the movie OK? I need children to be there for me when Iam older when I get as old as her. And when I say be there for me I mean pay for me when my husband isnat around to support me anymore. Iam not trying to be one of those old Chinese ladies who recycles for a living. Thatas not my destiny OK? Old Chinese ladies they donat give a fuck. They got no shame. Theyare like aIam just gonna recyclea go balda go to the park do this shit.a They do that acause itas a free activity. For them. They do it in theira their bigass V. Stiviano visor their Darth VaderTomb Raider Boba Fett helmet. They wear that to protect themselves from their archnemesis the sun. Their in a contest to see whoas gonna burn out first. Old Asian ladies and the sun are like the Tupac and Biggie of longevity.qXII also decided to have a kid because uh Iam only 33 which I know is not technically highrisk but my body was starting to show signs of change. And ita And it scared me. Like Iam only 33 anda amy pussy is not as wet as it used to be. Itas very demoralizing OK? Do you remember when you were 18 years old and your pussy was just sopping wet all the time? All the time you just took it for granted that you could just reach your hand down your pants at any given moment you throw up the peace sign afterwards and there would be that snailtrail in between your fingers. Oh my God it was so juicy. You could just blow a bubble wand with it justa aI slime you I slime you. Ghostbusters!aqXI donat know what kind of mother Iam gonna be. Iama Iam 33 and I did have to get a little bit of science involved when trying to get pregnant. And a lot of thata is most likely my fault. Because when I was in my 20s I ate Plan B like skittles. So my uterus probably looked like a smokeras lung. And I found out that my progesterone levels were alarmingly low. So then I had to take these hormone pills that were suppositories and Push Pop them up myself every single night. And then at my writing job at Fresh Off The Boat I would be storyboarding in front of my coworkers and then at some point the pill would inevitably dissolve and melt into my underwear and I had to act like everything was OK when everything was clearly not OK. And then a side effect of the progesterone was that it made me extremely itchy. So then I had to find ways to discretely scratch myself underneath the conference table and then resist the urge to immediately smell my fingers afterwards. I want to be able to smell my fingers when I wanna smell my own goddamn fingers. Housewives they can just scratch and sniff all day long. They just vacuum scratch sniff. They make a sandwich. aUh mmm.a They watch Property Brothers scratch aWhatas crackina? Mmm.a Every time you scratch yourself all you can think about is aWhen can I smell my fingers? When can I smell my fingers? When can I discretely find a way toaa aasmell my fingers?a Nature made you urgently curious to protect you acause you gotta check that itas all good in the hood. If itas too funky you need to see a doctor. Your fingers are your first WebMD.qXWhen my husband and I were trying to have a kid a lot of people were like aOh my God thatas so hot. You guys doina a lot of fuckina?a No dude. Thatasa Thatas shit you do in your 20s OK? When ina When youare in your 30s and youave been trying to get pregnant for a while it gets very clinical. You pee on these ovulation strips that tell you when the eggs are droppina. It tells you when itas Easter time. And I would only fuck him when it was Easter time. It was like only four days out of the month and outside of that I would be like aWeare not fuckina. I need you to save it. I want your sperm to be as pentup and as angry and rapey as possible. So that when they come out itas like aRelease the Kraken!a And they just come out like a bunch of angry refugees escaping a dictatorship you know? And uma yeah and most of the time like we wouldnat even have sex acause I was so tired when I would come home and see the smiley face on the ovulation strip and Iad be like aOK itas go timea and I would just give my husband a hand job most of the time and he would close his eyes immediately. I know what that means OK? When somebody closes their eyes during sex itas not because theyare in such ecstasy with you thata that they need to close their eyes. When somebody closes their eyes during sex itas because theyare literally trying to shut the image of your face out of their head and instead project two Latina lesbians that they saw earlier that day on RedTube onto the back of their eyelids. Which is fine by me because then he doesnat have to see the expression on my face that says aPlease hurry the fuck up.a And then when he was about to finish I could always tell because the indication is very universal when a man is about to finish. Itas when they get thata that stupidass look on their facea awhere they look like they just got bit by a zombie justa And then because weare hippies Iad be like aHey hey! Please look me in the eye and remember to come with intention OK?a And then I would jump on him and hold onto his neck and I would just twerk twerk twerk the shit out of hima and do some of this shit that I learned in Atlanta. And then I would turn upside down immediately afterwardsa to make sure all of that Harvard nectar would just drain inside of me. Thatas right. aCause I donat wanna work anymore.qXOIam very grateful to be pregnant and to bea this far along to be seven and a half months pregnant because last year I had a miscarriage which is very common. And a lot of women who are in their 20s flip out when they hear that. Theyare like aOh my God. Thatas so dark and terrible. I canat believe that.a Iam 33. Girl when youare 33 youall know plenty of women who have had a miscarriage. Itas super common and I wish more women would talk about it so they wouldnat feel so bad when they go through it. When I told my moma Sheas from a third world country and when I told her I had one she was like aUh yeah. Where Iam from thatas like losing a pair of shoes. Itas whatevs OK?a And everything happens for a reason. I found out at my sixweek sonogram which is very early. And the doctor says to me aOh my God I see two sacks which means youare having twins.a And I was like aNo!a And then she said aBut what I donat see is a heartbeat.a And I was like aYes!a aThe Lord is mysterious!a Donat feel bad OK? They were the size of poppy seeds. Iave picked boogers larger than the twins that I lost. And most women wonat let their husbands watch when theyare going through a miscarriage. I sat my husband down in front of me while I sat on the toilet and I was like aYou look.a aYou watch the whole thing.a And he felt so bad for me. And I used it as leverage and held that shit over his head for a month and got him to do whatever the fuck I wanted him to do for 30 days. He took me to see BeyoncA. He bought me a bike off of Craigslist. Thatas my miscarriage bike and I love it very much. For 30 days I finally had the marriage I always wanted.qXUIam scared about giving childbirth though. Iama Iam very very scared of childbirth. Thatas why Iam going to hire a doula. You know what that is? You know what a doula is? Thatas a white hippie witcha athat blows quinoa into your pussy to Keyser SAze all the pain away. A lot of women tried to freak me out. They tried to freak me out about childbirth by saying aAli did you know that youare gonna poop on the table?a I was like aYeah I look forward to it.a Iam all backed up from holding in my shit at work. I canat wait to cleanse. It makes sense like that youa that that happens because when youare in labor you push you push you push and your husband will be asked to assist in the labor by lifting up your leg which subsequently turns into a soft serve lever. You just shit on the floor in front of the love of your life. And just when you think thatas enough to make him finally leave you boom a baby comes out and he gotta stay. Thatas the real miracle of life right there. I can already see how a child can really take its toll on a marriage because the baby hasnat even come out yet and I am already so resentful towards my husband. So much resentment especially when he asks me to do shit around the house. aHey can you wash the dishes?a aNo!a aCan you water the plants?a aI am not doing jack shit anymore. Iam busy makina a eyeball OK? Are you makina a foot? I didnat think so. You change the channel.aqXI can already see how thereas like this crazy double standard in our society of how it takes so little to be considered a great dad. And it also takes so little to be considered a shitty mom. People praise my husband for coming to all of my doctoras appointments with me. aOh my God. I canat believe he comes to all your doctoras appointments. He is so supportive.a Guess who else has to go to those doctor appointments. Me! Iam the star of the show. Thereas nothing for the camera to see if Iam not there. But heas the hero for playing Candy Crush while I get my blood drawn. Meanwhile if I do mushrooms seven months pregnant Iam a bad mommy.qXYou know Ia Ia I like I berate my husband on like a daily basis. Partially because I really am mad at him. But mostly out of survival because if he leaves me Iam fucked. So I have to chip away at his selfesteem on a daily basisa to keep him down so that he doesnat believe that heas worthy of another womanas affection and leaves me. I gotta keep him around by keeping him down. People donat tell you about all this shit that goes down with your body when you get pregnant you know? Your nipples get huge and dark. I didnat know that. I didnat know that they get dark so that the baby can see like a bullseye. So that the baby can find it easier. And then you know they get biga they get big like fingers. Like aYou you. You owe me money you.a My nipples look like Whoppers now and naked I look like a Minion. But Iam not gonna be one of those crazy pregnant ladies who tries to get all back in shape right after they get pregnant. No. Hopefully if you see me in a year I will have the kind of body where if I do a nude scene on television people will commend me for being courageous. For doing it.qXNow that Iam seven and a half months pregnant my pussyas all wet again. But itas different. Itas not like when I was 18 years old when it was like really hot you know? And I was like aWhy is it different?a And I looked it up and my pussyas all wet again because mya my bodyas secreting mucus to protect the baby from bacteria attacking it. Thatas not the same. When itas straight up soldier glue when itas Neosporin.qXØSo you know Ia I ina previously before I met my husband I had dated a bunch of losers. And then I meet this dream guy whoas like way more handsome than me out of my league graduated from Harvard Business School. Worked hard to trap his ass. Got him to propose to me. Oh my God then we got married all my dreams coming true and then we got pregnant and recently we bought our first home together. And uh two weeks into the escrow process I discovered that my beautiful Harvardeducated husband was 70000 in debt. And me with my hardearned TV money paid it all off. So as it turns out heas the one who trapped me. How did he do it? How did he bamboozle me? Oh! Maybe because he went to Harvard Business School the epicenter of whitecollar crime. He Enronad my ass. And now if I donat work we die. Why else do you think Iam performing seven and a half months pregnant? All right Iave been Ali Wong. Have a good night everybody. Thank you.qe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = re.sub(r'[^\\w\\s]', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove specified words from beginning or end of line\n",
        "                pattern = r'\\b(?:qx|qn|qe|xi|xn|xe|qxø|qxo|\\.qe\\.|q|aqxæ|q \\.|\\.qxøso|aqxæmy|q xi|aqx14)\\b'\n",
        "                clean_line = re.sub(pattern, '', clean_line)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()} \")\n",
        "\n",
        "def main():\n",
        "    input_file = input(\"Upload file: \")\n",
        "    output_file = f\"{input_file}_preprocessed.txt\"\n",
        "    clean_text(input_file, output_file)\n",
        "    print(f\"Preprocessed file: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_-3EcfYBdx",
        "outputId": "4af010b0-3928-474d-8117-1fc50ca94d81"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/ali.txt\n",
            "Preprocessed file: /content/ali.txt_preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unwanted_words(line, unwanted_words):\n",
        "    words = line.split()\n",
        "    cleaned_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word not in unwanted_words:\n",
        "            cleaned_words.append(word)\n",
        "\n",
        "    # Reconstruct the line without unwanted words\n",
        "    cleaned_line = ' '.join(cleaned_words)\n",
        "    return cleaned_line\n",
        "\n",
        "def clean_text(input_file, output_file):\n",
        "    unwanted_words = [\"qx\", \"qn\", \"qe\", \"xi\", \"xn\", \"xe\", \"qxø\", \"qxo\", \".qe.\", \"q\", \"aqxæ\", \"q .\", \".qxøso\", \"aqxæmy\", \"q xi\", \"aqx14\"]\n",
        "\n",
        "    with open(input_file, 'r', encoding='latin1') as input_file:\n",
        "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
        "            for line in input_file:\n",
        "                # Remove HTML tags\n",
        "                clean_line = re.sub(r'<.*?>', '', line)\n",
        "                # Remove URLs\n",
        "                clean_line = re.sub(r'https?://\\S+', '', clean_line)\n",
        "                # Remove non-printable characters\n",
        "                clean_line = ''.join(char for char in clean_line if char.isprintable())\n",
        "                # Normalize Unicode characters\n",
        "                clean_line = unicodedata.normalize('NFKD', clean_line)\n",
        "                # Remove punctuation characters\n",
        "                clean_line = re.sub(r'[^\\w\\s]', '', clean_line)\n",
        "                # Remove extra white space\n",
        "                clean_line = ' '.join(clean_line.split())\n",
        "                # Remove unwanted words from beginning or end of line\n",
        "                clean_line = remove_unwanted_words(clean_line, unwanted_words)\n",
        "                # Remove empty lines\n",
        "                if clean_line.strip() == '':\n",
        "                    continue\n",
        "                output_file.write(f\"{clean_line.lower()} \")\n"
      ],
      "metadata": {
        "id": "gZJ-ZWcSYcyw"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a function for preprocessing the text file using nltk and regex\n",
        "def preprocess_with_nltk(path, truncation = \"lemma\", remove_stop_words = True):\n",
        "\n",
        "  \"\"\"\n",
        "  preprocess_with_nltk(path:->str, truncation: -> str [\"stem\" | \"lemma\"], remove_stop_words:-> boolean):\n",
        "\n",
        "  path : string value of location of file.\n",
        "  truncation : string value [\"stem\" | \"lemma\"] wheather to use the lemmatation or stemming process.\n",
        "  remove_stop_words : boolean value [True | False] weather to remove stop words form text or not.\"\"\"\n",
        "\n",
        "  ## Reading the file in \"utf-8\" encoding format\n",
        "  with open(path, \"r\", encoding = \"utf8\", errors = \"ignore\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "  ## Removing the url links present in the document\n",
        "  text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
        "\n",
        "  ## Removing special characters form text using regex\n",
        "  text = re.sub(r\"[^a-zA-Z0-9\\?\\.\\-!] | ^\\b\\w*'\\w*\\b\"  , \" \", text)\n",
        "  text = re.sub(r\"(?<!\\[)\\[|\\](?!\\])\", \" \", text)\n",
        "\n",
        "\n",
        "  ## Normalizing the data.\n",
        "  text = text.lower()\n",
        "\n",
        "  text = \" \".join([token for token in text.split() if token.isprintable()]) # and not len(token.strip())<=2])\n",
        "\n",
        "  words = text.split()\n",
        "  ## removing stop words from text if remove_stop_words is true\n",
        "  if remove_stop_words:\n",
        "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  ## Applying stemming if trunction is stem\n",
        "  if truncation == \"stem\":\n",
        "    stemmer = PorterStemmer()\n",
        "    text = \" \".join([stemmer.stem(token) for token in words])\n",
        "\n",
        "  ## Applying Lemmatizer if truncation is lemma\n",
        "  elif truncation == \"lemma\":\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = \" \".join([lemmatizer.lemmatize(token) for token in words])\n",
        "\n",
        "  ## Removing extra spaces or extra blank lines from text using regex\n",
        "  patten = r'\\s+'\n",
        "  text = re.sub(patten, \" \", text)\n",
        "\n",
        "  return text.strip()\n",
        "\n",
        "\n",
        "text_temp= preprocess_with_nltk(\"/content/drive/MyDrive/Lead_sem/task/dataset/ali.txt\",)\n",
        "\n",
        "with open(\"ali_clean.txt\", \"w\") as f:\n",
        "  f.write(text_temp)"
      ],
      "metadata": {
        "id": "6ZQHl-y4y9u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def try_utf8_decoding(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = f.read()\n",
        "        print(\"Decoding successful with encoding: UTF-8\")\n",
        "    except UnicodeDecodeError:\n",
        "        print(\"Decoding failed with UTF-8 encoding\")\n",
        "\n",
        "def main():\n",
        "    file_path = input(\"Upload file: \")\n",
        "    try_utf8_decoding(file_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7az-7ByQNiJ",
        "outputId": "bcd77b6e-538c-4e5f-8ed5-2dc8609c3f94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file: /content/bill.txt\n",
            "Decoding failed with UTF-8 encoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            decoded_text = f.read()\n",
        "        return decoded_text\n",
        "    except UnicodeDecodeError:\n",
        "        print(\"Decoding failed. The file may not be UTF-8 encoded or contains invalid characters.\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    file_path = input(\"Enter the path to the file: \")\n",
        "    decoded_text = decode_file(file_path)\n",
        "    if decoded_text:\n",
        "        print(\"Decoding successful:\")\n",
        "        print(decoded_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE3oBsagQeZq",
        "outputId": "93701ece-b473-4e88-91ab-41bcdc967b4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the file: /content/ali.txt\n",
            "Decoding failed. The file may not be UTF-8 encoded or contains invalid characters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "X3jwH00QSnVC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a function for preprocessing the text file using nltk and regex\n",
        "def preprocess_with_nltk(path, truncation = \"lemma\", remove_stop_words = True):\n",
        "\n",
        "  \"\"\"\n",
        "  preprocess_with_nltk(path:->str, truncation: -> str [\"stem\" | \"lemma\"], remove_stop_words:-> boolean):\n",
        "\n",
        "  path : string value of location of file.\n",
        "  truncation : string value [\"stem\" | \"lemma\"] wheather to use the lemmatation or stemming process.\n",
        "  remove_stop_words : boolean value [True | False] weather to remove stop words form text or not.\"\"\"\n",
        "\n",
        "  ## Reading the file in \"utf-8\" encoding format\n",
        "  with open(path, \"r\", encoding = \"utf8\", errors = \"ignore\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "  ## Removing the url links present in the document\n",
        "  text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
        "\n",
        "  ## Removing special characters form text using regex\n",
        "  text = re.sub(r\"[^a-zA-Z0-9\\?\\.\\-!] | ^\\b\\w*'\\w*\\b\"  , \" \", text)\n",
        "  text = re.sub(r\"(?<!\\[)\\[|\\](?!\\])\", \" \", text)\n",
        "\n",
        "\n",
        "  ## Normalizing the data.\n",
        "  text = text.lower()\n",
        "\n",
        "  text = \" \".join([token for token in text.split() if token.isprintable()]) # and not len(token.strip())<=2])\n",
        "\n",
        "  words = text.split()\n",
        "  ## removing stop words from text if remove_stop_words is true\n",
        "  if remove_stop_words:\n",
        "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  ## Applying stemming if trunction is stem\n",
        "  if truncation == \"stem\":\n",
        "    stemmer = PorterStemmer()\n",
        "    text = \" \".join([stemmer.stem(token) for token in words])\n",
        "\n",
        "  ## Applying Lemmatizer if truncation is lemma\n",
        "  elif truncation == \"lemma\":\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = \" \".join([lemmatizer.lemmatize(token) for token in words])\n",
        "\n",
        "  ## Removing extra spaces or extra blank lines from text using regex\n",
        "  patten = r'\\s+'\n",
        "  text = re.sub(patten, \" \", text)\n",
        "\n",
        "  return text.strip()\n",
        "\n",
        "\n",
        "text_temp= preprocess_with_nltk(\"/content/ali.txt\",)\n",
        "\n",
        "with open(\"ali_clean.txt\", \"w\") as f:\n",
        "  f.write(text_temp)"
      ],
      "metadata": {
        "id": "WsJ0m8MFSa5p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize a word\n",
        "word = 'running'\n",
        "lemmatized_word = lemmatizer.lemmatize(word)\n",
        "\n",
        "print(\"Original Word:\", word)\n",
        "print(\"Lemmatized Word:\", lemmatized_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqs7dtF1TjGe",
        "outputId": "ec1b3eeb-c0ec-4cbd-a326-2fd37abd07a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: running\n",
            "Lemmatized Word: running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ZI-UszTm8C",
        "outputId": "6ec19a5f-445b-4044-a90d-712702edf291"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkmNysEsTVuq",
        "outputId": "5acd9d85-633f-4cba-9393-47502701b913"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Get English stopwords\n",
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "print(english_stopwords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qehh-lPqS0Yy",
        "outputId": "e597d4bc-9f11-4d37-c532-b086a1b04608"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "\n",
        "def read_and_preprocess_text(filename, encodings=['utf-8', 'latin-1', 'windows-1252'], preprocessing_steps=None):\n",
        "    try:\n",
        "        with open(filename, 'rb') as file:\n",
        "            content = file.read()\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    decoded_content = codecs.encode(str(content), encoding).decode(\"utf-8\")\n",
        "                    preprocessed_content = decoded_content\n",
        "                    if preprocessing_steps:\n",
        "                        for step in preprocessing_steps:\n",
        "                            preprocessed_content = step(preprocessed_content)\n",
        "                    return preprocessed_content\n",
        "                except UnicodeDecodeError:\n",
        "                    print(f\"Failed to decode with encoding '{encoding}'. Trying next encoding...\")\n",
        "            print(\"Failed to read the file with all specified encodings.\")\n",
        "            return None\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{filename}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Example preprocessing steps\n",
        "def lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text):\n",
        "    return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "# Example usage:\n",
        "filename = \"/content/ali.txt\"\n",
        "preprocessing_steps = [lowercase, remove_numbers]\n",
        "preprocessed_text = read_and_preprocess_text(filename, preprocessing_steps=preprocessing_steps)\n",
        "if preprocessed_text is not None:\n",
        "    print(preprocessed_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VRFJ3FfVu5p",
        "outputId": "ce3dc6b8-304a-40ae-a470-7f37b7c6bd67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"\\x\\x]q\\x(x\\t\\x\\x\\xladies and gentlemen, please welcome to the stage: ali wong! hi. hello! welcome! thank you! thank you for coming. hello! hello. we are gonna have to get this shit over with, \\xe\\x\\xcause i have to pee in, like, ten minutes. but thank you, everybody, so much for coming.q\\xxg\\x\\x\\xum\\xe\\x\\xa it\\xe\\x\\xs a very exciting day for me. it\\xe\\x\\xs been a very exciting year for me. i turned  this year. yes! thank you, five people. i appreciate that. uh, i can tell that i\\xe\\x\\xm getting older, because, now, when i see an -year-old girl, my automatic thought\\xe\\x\\xa is \\xe\\x\\xcfuck you.\\xe\\x\\xd \\xe\\x\\xcfuck you. i don\\xe\\x\\xt even know you, but fuck you!\\xe\\x\\xd \\xe\\x\\xcause i\\xe\\x\\xm straight up jealous. i\\xe\\x\\xm jealous, first and foremost, of their metabolism. because -year-old girls, they could just eat like shit, and then they take a shit and have a six-pack, right? they got that-that beautiful inner thigh clearance where they put their feet together and there\\xe\\x\\xs that huge gap here with the light of potential just radiating through.\\nand then, when they go to sleep, they just go to sleep. right? they don\\xe\\x\\xt have insomnia yet. they don\\xe\\x\\xt know what it\\xe\\x\\xs like to have to take a ambien or download a meditation oasis podcast to calm the chatter of regret and resentment towards your family just cluttering your mind. they have their whole lives ahead of them. they don\\xe\\x\\xt have hpv yet. they just go to sleep in peace at night. everybody has hpv, ok? everybody has it. it\\xe\\x\\xs ok. come out already. everybody has it. if you don\\xe\\x\\xt have it yet, you go and get it. you go and get it. it\\xe\\x\\xs coming. you don\\xe\\x\\xt have hpv yet, you\\xe\\x\\xre a fucking loser, all right? that\\xe\\x\\xs what that says about you. a lot of men don\\xe\\x\\xt know that they have hpv, because it\\xe\\x\\xs undetectable in men. it\\xe\\x\\xs really fucked up. hpv is a ghost that lives inside men\\xe\\x\\xs bodies and says, \\xe\\x\\xcboo!\\xe\\x\\xd in women\\xe\\x\\xs bodies. my doctor told me that i have one of two strains of hpv. either i have the kind that\\xe\\x\\xs gonna turn into cervical cancer\\xe\\x\\xa \\xe\\x\\xaor i have the kind where my body will heal itself. very helpful, this doctor, right? so, basically, either i\\xe\\x\\xm gonna die\\xe\\x\\xa or you\\xe\\x\\xre in the presence of wolverine, bitches. we\\xe\\x\\xll find out.q\\xx\\xa\\x\\x\\xum, i can also tell that i\\xe\\x\\xm getting older, because my kindle is turning into a self-help library. i\\xe\\x\\xm not interested in books like fifty shades of grey, ok? i\\xe\\x\\xm interested in the life-changing magic of tidying up. yes. yes, that\\xe\\x\\xs right, how to declutter my home to achieve inner peace and my optimum level of success. that\\xe\\x\\xs what your s is all about. how can i turn this shit around? i\\xe\\x\\xm a horrible person, i\\xe\\x\\xm not happy with where i am, how can i turn this shit around? help me, tony robbins, help me!\\ni have a hoarding problem, which i\\xe\\x\\xm hoping is the center of all of my other problems. i\\xe\\x\\xm hoping that if the hoarding goes away, the hpv will also disappear. i have a hoarding problem because my mom is from a third world country and she taught me that you can never throw away anything, because you never know when a dictator\\xe\\x\\xs gonna overtake the country and snatch all your wealth. so, you better hold onto that retainer from the third grade, \\xe\\x\\xcause it might come in handy as a shovel when you\\xe\\x\\xre busy stuffing gold up your butt and running away from the communists.\\nthe last time i was at home in san francisco, i was trying to help her get rid of shit. don\\xe\\x\\xt ever do that with your mom. it was like the worst experience of my life. it was so emotional. we were screaming and fighting and yelling and it all came to a climax when she refused to let go of a texas instruments ti-\\xe\\x\\xa manual. the manual. she don\\xe\\x\\xt even know\\xe\\x\\xa where the calculator is. those of you under  probably don\\xe\\x\\xt know what that calculator is. it was this calculator that bamboozled my generation. we were all required to buy it when we were in eight grade. it cost like $. and everybody thought it was like this judy jetson\\xe\\x\\xs laptop from the future. all because what? it could graph. it was like the tesla of my time. and my mom got so emotional about the manual and she was like, \\xe\\x\\xcyou never know when you might need this.\\xe\\x\\xd and i was like, \\xe\\x\\xcbut\\xe\\x\\xa i do know\\xe\\x\\xa that i\\xe\\x\\xm gonna have to clean all this shit up when you die.\\xe\\x\\xd \\xe\\x\\xcand i\\xe\\x\\xm not trying to be a procrastinator anymore. because according to deepak-oprah, that\\xe\\x\\xs not the way for me to achieve my optimum level of success.\\xe\\x\\xdq\\xxc\\x\\x\\xi grew up a lot this past year. uh, this past year i also got married. yeah. to a man who now has hpv. very lucky guy. he gave me something. i gave him something. that will also last forever. no, really. i\\xe\\x\\xm the lucky girl, because before him, i dated a lot of losers. lots of losers. a lot of skaters. you wanna be a grown-ass woman, stop dating skaters. stop dating skaters unless you wanna wake up on a mattress in a kitchen. they\\xe\\x\\xre sexy on the outside, malt liquor on the inside. horrible. but my husband, i first met him at this wedding and, uh, he\\xe\\x\\xs\\xe\\x\\x he\\xe\\x\\xs much better looking than me, he\\xe\\x\\xs way out of my league, and i saw him and i was like, \\xe\\x\\xcoh, my god, who is that?\\xe\\x\\xd and the first thing i learned about him was that, at the time, he was attending harvard business school. and i was like, \\xe\\x\\xcoh, my god, i\\xe\\x\\xm gonna trap his ass.\\xe\\x\\xd \\xe\\x\\xcgoing to trap his ass!\\xe\\x\\xd and i trapped his ass initially by not kissing him until the fifth date, which is a very unusual move on my part. but i did it on purpose, because i knew that he was a catch. so i was like, \\xe\\x\\xcall right, ali, you gotta make this dude believe that your body is a secret garden.\\xe\\x\\xd when, really, it\\xe\\x\\xs a public park\\xe\\x\\xa \\xe\\x\\xathat has hosted many reggae fests\\xe\\x\\xa \\xe\\x\\xaand has even accidentally let\\xe\\x\\xa two homeless people inside. i thought they were hipsters, ok? that store urban outfitters has made things very confusing\\xe\\x\\xa for my generation. you homeless or you a hipster? is that beard for fashion or for warmth? it happened to\\xe\\x\\xa it happened in san francisco, when i was living there, and i saw this guy in broad daylight and we had, like, we had\\xe\\x\\xa we had so much chemistry. he was like, \\xe\\x\\xchey, wassup?\\xe\\x\\xd i was like, \\xe\\x\\xcwassup?\\xe\\x\\xd and we\\xe\\x\\x the next thing i knew, we were getting busy in the back of my volvo. and then after we were done, he was like, \\xe\\x\\xchey, can you drop me off?\\xe\\x\\xd i was like, \\xe\\x\\xcwhere?\\xe\\x\\xd he was like, \\xe\\x\\xcat the park.\\xe\\x\\xd and i dropped him off at golden gate park and watched him run into the middle with all his other homeless friends, and i was like, \\xe\\x\\xcoh, no!\\xe\\x\\xd \\xe\\x\\xci just fucked a homeless dude! again!\\xe\\x\\xdq\\xx)\\xf\\x\\xmy husband is asian. which a lot of people are shocked by, because, usually, asian-american women who, like, you know, wear these kinda glasses and have a lot of opinions, they like to date white dudes. you go to any hipster neighborhood in a major city in america and that shit is turning into a yoko ono factory. it\\xe\\x\\xs\\xe\\x\\xa too much. i don\\xe\\x\\xt know what\\xe\\x\\xs wrong with these bitches. i get it, you know, because being with a white dude you feel very\\xe\\x\\xa you feel very picturesque when you\\xe\\x\\xre with a white dude, you know. you feel like you\\xe\\x\\xre in a wes anderson movie or something. and you know, white dudes, they teach you about a lot of cool stuff like voting and recycling, and disturbing documentaries. they introduce you to cool stuff like that and it\\xe\\x\\xs very, you know, it\\xe\\x\\xs hot hookin\\xe\\x\\x up with a white dude. i mean, nothing makes me feel more powerful than when a white dude eats my pussy. oh, my god. i just feel like i\\xe\\x\\xm absorbing all of that privilege and all of that entitlement\\xe\\x\\xa \\xe\\x\\xayou know, just right there, through the money hole and just\\xe\\x\\xa and then also, he\\xe\\x\\xs so vulnerable down there. i\\xe\\x\\xm, like, \\xe\\x\\xci could just crush your head at any moment, white man! i could just kill you right now! crush those brains! colonize the colonizer!\\xe\\x\\xd you know?\\nbut i think that for marriage, it can be nice to be with somebody of your own race. the advantage is that you get to go home\\xe\\x\\xa and be racist together. you get to say whatever you like! you don\\xe\\x\\xt gotta explain shit. my husband, half-filipino, half-japanese. i\\xe\\x\\xm half-chinese and half-vietnamese. and we spend  percent of our time shitting on korean people. it\\xe\\x\\xs\\xe\\x\\xa amazing. it\\xe\\x\\xs what love is built on, you know?\\nmy last boyfriend was cuban and his family would shit on mexican people all the time. and i was like, \\xe\\x\\xchold it. you guys aren\\xe\\x\\xt mexican?\\xe\\x\\xd asian-american men are very underrated. i don\\xe\\x\\xt know why people don\\xe\\x\\xt go for them. they\\xe\\x\\xre the sexiest. asian men are the sexiest. they got no body hair from the neck down. it\\xe\\x\\xs like making love to a dolphin. oh, my god. it\\xe\\x\\xs so smooth, just like a slip and slide. just black fish, tilikum, all up in my bed every night, you know? ooh-wee. you mess with a jewish dude and your body is all fucked up afterwards. it\\xe\\x\\xs all red and inflamed and you\\xe\\x\\xre like, \\xe\\x\\xci did not ask to be exfoliated today.\\xe\\x\\xd \\xe\\x\\xcthis is the last time i go on j-date, more like loofah date. thanks for the rug burn, avi.\\xe\\x\\xd and then asian men, no body odor. none. they just smell like responsibility. that\\xe\\x\\xs where the umami flavor comes from.\\ni think my husband and i have a huge unspoken understanding, uh, between each other, because he\\xe\\x\\xs half-filipino and half-japanese and i\\xe\\x\\xm half-chinese and half-vietnamese. so, we\\xe\\x\\xre both half-fancy asian\\xe\\x\\xa \\xe\\x\\xaand half-jungle asian. yeah! you guys know the difference. the fancy asians are the chinese, the japanese. they get to do fancy things like host olympics. jungle asians host diseases. it\\xe\\x\\xs\\xe\\x\\xa it\\xe\\x\\xs different. but he grew up on the east coast, going to private school, playing lacrosse, uh, you know, learning latin and playing chess and rugby. he grew up like filipino carlton, ok? so, he didn\\xe\\x\\xt know anything about vietnamese people until he met me. and on one of our first dates, he took me to this restaurant on the west side of los angeles called pho show. he was like, \\xe\\x\\xcit\\xe\\x\\xs authentic vietnamese. i read about it on yelp!\\xe\\x\\xd i was like, \\xe\\x\\xcit\\xe\\x\\xs not authentic, ok?\\xe\\x\\xd you can tell, first and foremost, by the name, \\xe\\x\\xcause it don\\xe\\x\\xt got a number in it. second of all, you can tell by the bathroom. if it was legit, the bathroom would double as a supply closet. when i pee, i need to see ten gallons of bleach, an atm machine and a grandma with glaucoma napping in the corner. and the wait staff here is too nice. we need to leave this restaurant deaf and emotionally abused.q\\xx;\\x\\x\\xi grew up going to private school, too. him and i are both total, like, private school asians. we both are big hippies, too. we like to backpack through southeast asia. we like to do yoga. we do ayahuasca ceremonies. we do silent meditation retreats. that\\xe\\x\\xs right, we pay $ to shut up for a weekend. we do shit like that. uh, we eat gluten-free, which means we eat all that bread that tastes like free-range chewbacca. we eat that lesbian bread that\\xe\\x\\xs like\\xe\\x\\xa \\xe\\x\\xaa thousand percent of your daily fiber\\xe\\x\\xa and  percent spoken word poetry. when you eat it, you queef a shitty poem about\\xe\\x\\xa \\xe\\x\\xasupporting caitlyn jenner or whatever. and so, it\\xe\\x\\xs funny, right, because he\\xe\\x\\xs asian, too. but sometimes, all of this hippy-dippy shit we do\\xe\\x\\xa makes me feel like we are white people doing an impression of asian people. like, we have these chinese scrolls up on the wall\\xe\\x\\xa and neither of us know what the fuck they mean. we\\xe\\x\\xre like, \\xe\\x\\xcoh, that seems to go very well with our buddha piggy bank from pier  imports. that seems to be providing some good feng shui for the house.q\\xx\\xac\\x\\x\\xhim and i had been dating for four years and i\\xe\\x\\x i just had this sneaking suspicion that he was gonna propose\\xe\\x\\xa because\\xe\\x\\xa i had been pressuring him to do it. so, you know, i just had this wacky women\\xe\\x\\xs intuition. that\\xe\\x\\xs how proposals really work, ok? a woman has to incept the idea into the man\\xe\\x\\xs head. first passively and then if he doesn\\xe\\x\\xt get the message, extremely aggressively. you gotta threaten to leave without ever actually leaving, because you know that you\\xe\\x\\xre too old and it\\xe\\x\\xs too late to go back out there and find a new man and start the whole manipulation cycle all over again. so, you\\xe\\x\\xre like, \\xe\\x\\xci\\xe\\x\\xm just gonna stick with this dude, focus on trapping this dude, and just nag the shit outta him until he becomes weak and caves in and gets fed up and is like, \\xe\\x\\xcshut the fuck up! fine, will you marry me?\\xe\\x\\xd and then afterwards, the woman is always, like, \\xe\\x\\xcoh, my god! he proposed!\\xe\\x\\xd \\xe\\x\\xcit came outta nowhere. and look, he got me the exact ring i wanted. how did he know? maybe he saw it on my pinterest page or something\\xe\\x\\xa that i sent to my best friend, that i told her to send to him every day.\\xe\\x\\xd let me tell you something. if a man has a pinterest page\\xe\\x\\xa he\\xe\\x\\xs probably pinterested in men. we got engaged on a saturday. i bought my wedding dress the following tuesday\\xe\\x\\xa because i had tried it on in . i was ready. i was ripe. i was rotten. i need to be made into banana bread. that\\xe\\x\\xs how rotten i was.q\\xx\\xb\\x\\x\\xpeople are always very surprised at how, off-stage, with my husband, i\\xe\\x\\xm a completely different person. you\\xe\\x\\x like, you would not recognize my personality at all with him. with him, i\\xe\\x\\xm very soft, and, like, very nurturing and very domestic. we\\xe\\x\\xve been together now for five years, and for five years, i\\xe\\x\\xve packed his lunch every single day. yeah. yes. yes. yes. i did that so that he\\xe\\x\\xd become dependent on me. \\xe\\x\\xcause he graduated from harvard business school, and i don\\xe\\x\\xt wanna work anymore. i don\\xe\\x\\xt. i straight up don\\xe\\x\\xt wanna work anymore. i don\\xe\\x\\xt feed him out of the goodness of my heart. i do it as an investment in my financial future. \\xe\\x\\xcause i don\\xe\\x\\xt wanna work anymore. i\\xe\\x\\xve been reading that book by sheryl sandberg, she\\xe\\x\\xs the c.o.o. of facebook, and she wrote that book that got women all riled up about our careers. talking about how we as women should challenge ourselves to sit at the table and rise to the top. and her book is called lean in. well, i don\\xe\\x\\xt wanna lean in, ok? i wanna lie down. i want to lie the fuck down. i think feminism is the worst thing that ever happened to women. our job used to be no job. we had it so good. we could have done the smart thing, which would have been to continue playing dumb for the next century and be like, \\xe\\x\\xcwe\\xe\\x\\xre dumb women. we don\\xe\\x\\xt know how to do anything. so, i guess we better just stay at home all day and eat snacks and watch ellen.\\xe\\x\\xd \\xe\\x\\xc\\xe\\x\\xcause we\\xe\\x\\xre too stupid to have any real responsibility.\\xe\\x\\xd and then, all these women had to show off and be like, \\xe\\x\\xcwe could do it! we could do anything.\\xe\\x\\xd \\xe\\x\\xcbitch, shut up!\\xe\\x\\xd \\xe\\x\\xcdon\\xe\\x\\xt tell them the secret.\\xe\\x\\xd they ruined it for us, and now we\\xe\\x\\xre expected to work. when i hear the phrase, \\xe\\x\\xcdouble-income household,\\xe\\x\\xd i wanna throw up. a lot of women get very upset with me about those comments. and they\\xe\\x\\xre like, \\xe\\x\\xcbut, ali, we have so many more options now.\\xe\\x\\xd oh, you don\\xe\\x\\xt think we had a lot of options when our day was free? unscheduled, unsupervised, and most importantly, sponsored? do you know how much shittier food tastes when you know you have to earn it?\\na lot of my friends, when we walk around together, they\\xe\\x\\xll get very judgmental about housewives that we\\xe\\x\\xll see on the street. and they\\xe\\x\\xll be like, \\xe\\x\\xclook at that fucking housewife. not doing anything. look at that housewife, just walking around all day, getting massages in her lululemon pants.\\xe\\x\\xd i\\xe\\x\\xm like, \\xe\\x\\xcthat bitch is a genius.\\xe\\x\\xd \\xe\\x\\xcshe\\xe\\x\\xs not a housewife, she\\xe\\x\\xs retired.\\xe\\x\\xd\\ni do write for fresh off the boat on abc. yeah. which is\\xe\\x\\xa it\\xe\\x\\xs a great show. i love it a lot. i love my co-workers. it\\xe\\x\\xs a great writing staff and in terms of day jobs, it\\xe\\x\\xs probably one of the best you could ask for, but i still gotta work at a office every day. which means i gotta shit in a office every day. housewives, they don\\xe\\x\\xt gotta shit in a office. housewives get to shit in their house. skin to seat. they don\\xe\\x\\xt gotta use that horrible toilet paper cover. they don\\xe\\x\\xt gotta\\xe\\x\\xa \\xe\\x\\xaten times a day, every day\\xe\\x\\xa like you\\xe\\x\\xre about to eat a sad-ass meal. they don\\xe\\x\\xt gotta do that. they don\\xe\\x\\xt gotta use that one-ply toilet paper, that office toilet paper, that they purposely make difficult to pull out. they try to ration me with their communist toilet paper that\\xe\\x\\xs not even effective. it basically just dehydrates your butt hole. it\\xe\\x\\xs basically like wiping your butt with the desert. i literally spat on my toilet paper two days ago, to try to make a macgyver baby wipe, to moisten it, and then it backfired \\xe\\x\\xcause my fingers broke through and digitally stimulated more doo doo to come out, and then i had to start all over again. and you can never finish wiping at work because you always feel rushed \\xe\\x\\xcause you\\xe\\x\\xre paranoid that your co-worker\\xe\\x\\xs gonna recognize your shoes underneath the stall. and you\\xe\\x\\xre like, \\xe\\x\\xcoh, no! courtney\\xe\\x\\xs listening. she\\xe\\x\\xs waiting. she\\xe\\x\\xs timing me.\\xe\\x\\xd and then you hurry, hurry, hurry, and then you never finish wiping and then your butt hole feels caked in doo doo all day long. and then if you dare scratch yourself, your underwear at the end of the day looks like it\\xe\\x\\xs been run over by the goonies. housewives, they don\\xe\\x\\xt gotta muffle their shit, too. they don\\xe\\x\\xt gotta worry about the velocity with which their doo doo comes out. they don\\xe\\x\\xt gotta try to, you know, squeeze the butt cheeks together to make sure that the doo doo comes out at a slow and steady pace, so that no unpredictable noise suddenly escapes and brings you deep, deep shame. housewives are free to just blow ass into the toilet and let it echo and reverberate to the ends of their hallways while watching as much netflix on their ipad as they want. they don\\xe\\x\\xt gotta take these boring, repressed shits. they can listen to podcasts. planet money. they can do whatever they want.\\nyou know, it\\xe\\x\\xs\\xe\\x\\x it\\xe\\x\\xs very distracting for me when i hear my co-workers blow ass into the toilet. i lose respect for them. nothing they say to me anymore holds any sort of credence. i heard one of my co-workers blow ass into the toilet the other day. this bitch had the nerve to come up to me and say, \\xe\\x\\xcyou need to get to work on time.\\xe\\x\\xd i was like, \\xe\\x\\xcyou need to eat bananas.\\xe\\x\\xd \\xe\\x\\xci saw those green ballet flats. i know that shit was you. don\\xe\\x\\xt try to tell me to get my shit together when i heard you not have your shit together.\\xe\\x\\xdq\\xx\\xe\\xb\\x\\xmy father-in-law had this huge sit-down with me and my husband recently. um, and he was like, \\xe\\x\\xchey, i wanna talk to you guys about money. you guys need to make a lot more money if you wanna provide your children with the same kind of privileged childhood that you guys had.\\xe\\x\\xd i was like, \\xe\\x\\xcwhy you telling me this shit? i should not be a part of this conversation. you tell you son that. don\\xe\\x\\xt your understand that i trapped your son for his earning potential? why else would i choose to fuck one person for the rest of my life? i chose to marry him on the promise of early retirement, and when i said, \\xe\\x\\xi do,\\xe\\x\\x what i really meant was, \\xe\\x\\xoh, i\\xe\\x\\xm done.'\\xe\\x\\xd i\\xe\\x\\xm done. i don\\xe\\x\\xt wanna work anymore and i\\xe\\x\\xm not dieting anymore. since i got married last year, i\\xe\\x\\xve been eating fried chicken skin every day since. that\\xe\\x\\xs right. and just fulfilling my destiny. which is to turn into a circle with eyelashes. like mrs. pacman, just\\xe\\x\\xa let\\xe\\x\\xs redecorate.\\ni gave up a lot of myself when i got married. i\\xe\\x\\xm a\\xe\\x\\x i\\xe\\x\\xm a disgusting pervert. i\\xe\\x\\xm a pervert. i\\xe\\x\\xm a gross filthy animal. and i think it\\xe\\x\\xs because i started watching porn at a very young age. and what happens when you start watching porn at a young age is that\\xe\\x\\xa y-you get sicker, and sicker, and sicker. the images you crave get sicker, and sicker, and sicker, but it\\xe\\x\\xs ok, because the internet will always catch up to you.\\ni broke up with my last boyfriend because he refused to put it in the back. i was like, \\xe\\x\\xcuh, you\\xe\\x\\xre a idiot, dude. do you realize that if i went on craigslist\\xe\\x\\xa and posted \\xe\\x\\xtiny asian female seeking anal\\xe\\x\\xa\\xe\\x\\x the internet would crash.\\xe\\x\\xd \\xe\\x\\xcand all the jewish male heads in the universe would simultaneously explode.\\xe\\x\\xd they would explode. a lot of women get really, you know\\xe\\x\\xa freaked out about anal. and they\\xe\\x\\xre like, \\xe\\x\\xcoh, i don\\xe\\x\\xt wanna do that. i\\xe\\x\\xm scared of\\xe\\x\\x of the pain.\\xe\\x\\xd you ain\\xe\\x\\xt scared of the pain. women, they wax their eyebrows, they do all sorts of crazy shit. you\\xe\\x\\xre not scared of the pain. what you\\xe\\x\\xre really scared of is doo doo on the dick. you\\xe\\x\\xre scared that he\\xe\\x\\xs gonna see that and that\\xe\\x\\xs gonna be all of your shame, your inner evil, all your secrets and lies. sephora can\\xe\\x\\xt help you now. but don\\xe\\x\\xt worry, \\xe\\x\\xcause when he puts it in the butt, all he\\xe\\x\\xs thinking about is, \\xe\\x\\xci just put it in her butt.\\xe\\x\\xd \\xe\\x\\xci gotta go call my mom, my dad, dave, my grandma.\\xe\\x\\xd you\\xe\\x\\xre\\xe\\x\\x if you\\xe\\x\\xre married, you\\xe\\x\\xre gonna have to do anal eventually, ok? you have to, because you gotta change it up. you gotta change it up, so that you don\\xe\\x\\xt cheat on each other. you gotta keep it interesting. if you put it in different holes, maybe you\\xe\\x\\xll feel like you\\xe\\x\\xre fucking different people. i was very sexually active in my s, and as a result, i\\xe\\x\\xm a little bit\\xe\\x\\xa \\xe\\x\\xastretched out down there, ok? so, when i finally did anal, i just felt like i got a second chance at life, you know? i was, like, \\xe\\x\\xcoh, my god! it\\xe\\x\\xs like i\\xe\\x\\xm going back in time!\\xe\\x\\xd \\xe\\x\\xaa a whole new world \\xe\\x\\xaa it was magical.q\\txe\\x\\x\\xa big fantasy of mine before i got married was to help as many men as possible discover their prostate. yeah, like a conqueror. i just wanted to\\xe\\x\\xa now, if you haven\\xe\\x\\xt done it before, ladies, go home and treat yourself. do it tonight. you only live once. yolo. just sneak your\\xe\\x\\x just give your man a little\\xe\\x\\x a little push-push in the tush-tush. just give him a little atari, you know, and you\\xe\\x\\xll get a lot of resistance from the man at first. you\\xe\\x\\xll get a lot of \\xe\\x\\xcno! no! no! no, please! no, really, i don\\xe\\x\\xt\\xe\\x\\x no! i don\\xe\\x\\xt! i don\\xe\\x\\xt! no!\\xe\\x\\xd they get all squirmy wormy because\\xe\\x\\xa they\\xe\\x\\xre scared. they\\xe\\x\\xre scared that if you stick your thumb up there and succeed, and they like it, that then, it might mean that they\\xe\\x\\xre gay. and i like that fear. that shit turns me on, you know? especially when that fear metamorphosizes into pleasure. oh, my god! and you just see the look in the man\\xe\\x\\xs eye like he\\xe\\x\\xs discovered nirvana. and it\\xe\\x\\xs like you\\xe\\x\\xre the first lady to show him that he had a magical clit in his butt hole. and then, you as the woman, in his eyes, just become the lord of the rim, you know?q\\nxn\\x\\x\\xmy husband is unfortunately just not as freaky as me. when\\xe\\x\\x when i\\xe\\x\\xve asked him to spank me, this is what he does. \\xe\\x\\xchey. hey, are you ok? are you all right? you know i respect you, right?\\xe\\x\\xd i\\xe\\x\\xm, like, \\xe\\x\\xcyes, i know you respect me and that\\xe\\x\\xs why you need to abuse me. ok?\\xe\\x\\xd \\xe\\x\\xcause it\\xe\\x\\xs the most strong-headed, loud-mouthed women who like to be abused the most in bed. women who are c.e.o.s, they just wanna be roughed around. they just want their\\xe\\x\\x glasses always means the woman wants some\\xe\\x\\x it\\xe\\x\\xs because we\\xe\\x\\xre so in control all the time, that we just wanna experience some risk and be out of control, you know? like, \\xe\\x\\xci don\\xe\\x\\xt wanna die! don\\xe\\x\\xt kill me! i don\\xe\\x\\xt wanna die!\\xe\\x\\xd but i also don\\xe\\x\\xt want to be sure that i\\xe\\x\\xm gonna live. you know? i just wanna be out of control for once. just\\xe\\x\\x just choke me enough so that i can\\xe\\x\\xt talk. \\xe\\x\\xcause if i can talk, i\\xe\\x\\xm gonna tell you what to do. and i\\xe\\x\\xm tired of being the boss. i\\xe\\x\\xm the boss all the time, so, in the bedroom, you be the boss. yes. because i\\xe\\x\\xm the real boss. and i told you so, motherfucker, so do it.q\\xbx\\xca\\x\\x\\xsheryl sandberg, that woman who wrote lean in, has had such a big impact that now, because of her, there is a ban on the word \\xe\\x\\xcbossy\\xe\\x\\xd in elementary schools, because according to her, it\\xe\\x\\xs sexist to use the word \\xe\\x\\xcbossy,\\xe\\x\\xd because boys are never called bossy. so, now, instead of saying, \\xe\\x\\xcyou\\xe\\x\\xre bossy,\\xe\\x\\xd you\\xe\\x\\xre supposed to say, \\xe\\x\\xcyou have executive leadership skills.\\xe\\x\\xd which is a very roundabout way of saying: \\xe\\x\\xcyou\\xe\\x\\xre a little cunt.\\xe\\x\\xdq\\xcx\\xdf\\x\\x\\xi\\xe\\x\\xm just waiting for the right moment to, like, become a housewife, financially, you know? i want my husband to get us to, like, a certain point financially. i wanna get to the point as a couple where i can comfortably afford sliced mango. know what i\\xe\\x\\xm talking about? i\\xe\\x\\xm talking about that whole foods mango. that $-a-box whole foods mango that was sliced by white people. that\\xe\\x\\xs the kind of income bracket i\\xe\\x\\xm striving for. that\\xe\\x\\xs when you know you\\xe\\x\\xve made it, when you\\xe\\x\\xre eating mango that was sliced by a dude named noah. i want noah mango\\xe\\x\\xa \\xe\\x\\xarebecca kiwi, danielle pineapple. you know what else i want? i wanna be able to take a stroll on a sidewalk, see a quarter, and just keep on walking. like a princess.q\\rx}\\x\\x\\xi have some useful advice for all my asian-american brothers and sisters. yeah! never go paintballing with a vietnam veteran.q\\xex~\\xb\\x\\xso, i don\\xe\\x\\xt know if you guys can tell, but i am seven and a half months pregnant. yeah. it\\xe\\x\\xs very rare and unusual to see a female comic perform pregnant, because female comics\\xe\\x\\xa don\\xe\\x\\xt get pregnant. just try to think of one. i dare you. there\\xe\\x\\xs\\xe\\x\\x none of them. once they do get pregnant, they generally disappear. that\\xe\\x\\xs not the case with male comics. once they have a baby, they\\xe\\x\\xll get up on stage a week afterwards and they\\xe\\x\\xll be like, \\xe\\x\\xcguys, i just had this fucking baby. that baby\\xe\\x\\xs a little piece of shit. it\\xe\\x\\xs so annoying and boring.\\xe\\x\\xd and all these other shitty dads in the audience are, like, \\xe\\x\\xcthat\\xe\\x\\xs hilarious. i identify.\\xe\\x\\xd and their fame just swells because they become this relatable family funny man all of a sudden. meanwhile, the mom is at home, chapping her nipples, feeding the fucking baby, and wearing a frozen diaper \\xe\\x\\xcause her pussy needs to heal from the baby\\xe\\x\\xs head shredding it up. she\\xe\\x\\xs busy. so, i don\\xe\\x\\xt know what\\xe\\x\\xs gonna happen to me. you know, a lot of my female stand-up comic friends who are a lot more successful and famous than me discouraged me from having a kid. and they were like, \\xe\\x\\xcali, why are you gonna have a kid? you just gonna become\\xe\\x\\x you\\xe\\x\\xre gonna disappear, and you\\xe\\x\\xre gonna become some lame stay-at-home mom.\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, that\\xe\\x\\xs the dream.\\xe\\x\\xd that\\xe\\x\\xs the point. this is the ultimate trap. i won, you know?\\nanother thing a lot of my friends said to me when they were discouraging me from having a kid, they were like, \\xe\\x\\xcwhy are you gonna have a kid? why don\\xe\\x\\xt you just travel the world with your husband and just do whatever you want for the rest of your lives with no kid attached.\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, that\\xe\\x\\xs cool\\xe\\x\\xa until my husband dies.\\xe\\x\\xd which he\\xe\\x\\xs definitely gonna before me. because i\\xe\\x\\xm a asian woman, and therefore, guaranteed to live until i\\xe\\x\\xm a billion. i\\xe\\x\\xm guaranteed, like a turtle from the galapagos, ok? we all know the phrase \\xe\\x\\xcblack don\\xe\\x\\xt crack.\\xe\\x\\xd well, asian don\\xe\\x\\xt die. we don\\xe\\x\\xt die. especially the women, we live forever. and you know why we\\xe\\x\\xre such bad drivers? because we\\xe\\x\\xre trying to die. we\\xe\\x\\xre like, \\xe\\x\\xcyeah! let me see how invincible i really am!\\xe\\x\\xd \\xe\\x\\xcimma make this left hand turn signal and ignore this red light completely.\\xe\\x\\xd \\xe\\x\\xci\\xe\\x\\xm gonna make a right turn\\xe\\x\\x i changed my mind, it\\xe\\x\\xs a u-turn!\\xe\\x\\xd \\xe\\x\\xci changed my mind again. it\\xe\\x\\xs a o-turn!\\xe\\x\\xd every time i get into a car accident\\xe\\x\\xa \\xe\\x\\xai\\xe\\x\\xm like, \\xe\\x\\xcoh, my god, not again!\\xe\\x\\xd i need to hide my face so that everybody doesn\\xe\\x\\xt see that it\\xe\\x\\xs what everybody thought it was gonna be. so embarrassing. my toyota corolla is a mess. there\\xe\\x\\xs this huge bear claw scratch on the side from this aggressive brick wall that came out of nowhere. and then, on the hood, there\\xe\\x\\xs multiple hand prints from pedestrians who have had to alert me of their existence. i don\\xe\\x\\xt know what\\xe\\x\\xs wrong with me, but i\\xe\\x\\xm still here, you know?q\\xfx\\xb\\x\\x\\xi need to have children to keep me company when i get older. it\\xe\\x\\xs lonely. my mom is , going through a full blown mid-life crisis. \\xe\\x\\xcause she knows that she\\xe\\x\\xs got a century more to go. and she is so lonely. all of her white friends, dead. her mexican friends, dead. black friends, dead. i\\xe\\x\\xm just kidding. she doesn\\xe\\x\\xt have any black friends. life is not rush hour, the movie, ok? i need children to be there for me when i\\xe\\x\\xm older, when i get as old as her. and when i say be there for me, i mean pay for me when my husband isn\\xe\\x\\xt around to support me anymore. i\\xe\\x\\xm not trying to be one of those old chinese ladies who recycles for a living. that\\xe\\x\\xs not my destiny, ok? old chinese ladies, they don\\xe\\x\\xt give a fuck. they got no shame. they\\xe\\x\\xre like, \\xe\\x\\xci\\xe\\x\\xm just gonna recycle\\xe\\x\\xa go bald\\xe\\x\\xa go to the park, do this shit.\\xe\\x\\xd they do that \\xe\\x\\xcause it\\xe\\x\\xs a free activity. for them. they do it in their\\xe\\x\\x their big-ass v. stiviano visor, their darth vader-tomb raider- boba fett helmet. they wear that to protect themselves from their arch-nemesis, the sun. their in a contest to see who\\xe\\x\\xs gonna burn out first. old asian ladies and the sun are like the tupac and biggie of longevity.q\\xx\\xcc\\x\\x\\xi also decided to have a kid because uh, i\\xe\\x\\xm only , which, i know, is not technically high-risk, but my body was starting to show signs of change. and it\\xe\\x\\x and it scared me. like, i\\xe\\x\\xm only  and\\xe\\x\\xa \\xe\\x\\xamy pussy is not as wet as it used to be. it\\xe\\x\\xs very demoralizing, ok? do you remember when you were  years old, and your pussy was just sopping wet all the time? all the time, you just took it for granted that you could just reach your hand down your pants at any given moment, you throw up the peace sign afterwards, and there would be that snail-trail in between your fingers. oh, my god, it was so juicy. you could just blow a bubble wand with it, just\\xe\\x\\xa \\xe\\x\\xci slime you, i slime you. ghostbusters!\\xe\\x\\xdq\\xx\\x\\x\\x\\xi don\\xe\\x\\xt know what kind of mother i\\xe\\x\\xm gonna be. i\\xe\\x\\xm\\xe\\x\\x i\\xe\\x\\xm , and i did have to get a little bit of science involved when trying to get pregnant. and a lot of that\\xe\\x\\xa is most likely my fault. because, when i was in my s, i ate plan b like skittles. so, my uterus probably looked like a smoker\\xe\\x\\xs lung. and i found out that my progesterone levels were alarmingly low. so, then i had to take these hormone pills that were suppositories, and push pop them up myself every single night. and then, at my writing job, at fresh off the boat, i would be storyboarding in front of my co-workers, and then, at some point, the pill would inevitably dissolve and melt into my underwear, and i had to act like everything was ok, when everything was clearly not ok. and then, a side effect of the progesterone was that it made me extremely itchy. so, then i had to find ways to discretely scratch myself underneath the conference table, and then resist the urge to immediately smell my fingers afterwards. i want to be able to smell my fingers when i wanna smell my own goddamn fingers. housewives, they can just scratch and sniff all day long. they just vacuum, scratch, sniff. they make a sandwich. \\xe\\x\\xcuh, mmm.\\xe\\x\\xd they watch property brothers, scratch, \\xe\\x\\xcwhat\\xe\\x\\xs crackin\\xe\\x\\x? mmm.\\xe\\x\\xd every time you scratch yourself, all you can think about is, \\xe\\x\\xcwhen can i smell my fingers? when can i smell my fingers? when can i discretely find a way to\\xe\\x\\xa\\xe\\x\\xd \\xe\\x\\xc\\xe\\x\\xasmell my fingers?\\xe\\x\\xd nature made you urgently curious to protect you, \\xe\\x\\xcause you gotta check that it\\xe\\x\\xs all good in the hood. if it\\xe\\x\\xs too funky, you need to see a doctor. your fingers are your first webmd.q\\xx\\xa\\t\\x\\xwhen my husband and i were trying to have a kid, a lot of people were like, \\xe\\x\\xcoh, my god, that\\xe\\x\\xs so hot. you guys doin\\xe\\x\\x a lot of fuckin\\xe\\x\\x?\\xe\\x\\xd no, dude. that\\xe\\x\\xs\\xe\\x\\x that\\xe\\x\\xs shit you do in your s, ok? when in\\xe\\x\\x when you\\xe\\x\\xre in your s, and you\\xe\\x\\xve been trying to get pregnant for a while, it gets very clinical. you pee on these ovulation strips that tell you when the eggs are droppin\\xe\\x\\x. it tells you when it\\xe\\x\\xs easter time. and i would only fuck him when it was easter time. it was, like, only four days out of the month, and outside of that, i would be like, \\xe\\x\\xcwe\\xe\\x\\xre not fuckin\\xe\\x\\x. i need you to save it. i want your sperm to be as pent-up, and as angry and rapey as possible. so that, when they come out, it\\xe\\x\\xs like, \\xe\\x\\xrelease the kraken!'\\xe\\x\\xd and they just come out like a bunch of angry refugees escaping a dictatorship, you know? and, um\\xe\\x\\xa yeah, and most of the time, like, we wouldn\\xe\\x\\xt even have sex, \\xe\\x\\xcause i was so tired when i would come home, and see the smiley face on the ovulation strip, and i\\xe\\x\\xd be like, \\xe\\x\\xcok, it\\xe\\x\\xs go time,\\xe\\x\\xd and i would just give my husband a hand job most of the time, and he would close his eyes immediately. i know what that means, ok? when somebody closes their eyes during sex, it\\xe\\x\\xs not because they\\xe\\x\\xre in such ecstasy with you that\\xe\\x\\x that they need to close their eyes. when somebody closes their eyes during sex, it\\xe\\x\\xs because they\\xe\\x\\xre literally trying to shut the image of your face out of their head and instead project two latina lesbians that they saw earlier that day on redtube onto the back of their eyelids. which is fine by me, because then he doesn\\xe\\x\\xt have to see the expression on my face that says, \\xe\\x\\xcplease, hurry the fuck up.\\xe\\x\\xd and then, when he was about to finish, i could always tell because the indication is very universal when a man is about to finish. it\\xe\\x\\xs when they get that\\xe\\x\\xa that stupid-ass look on their face\\xe\\x\\xa \\xe\\x\\xawhere they look like they just got bit by a zombie, just\\xe\\x\\xa and then, because we\\xe\\x\\xre hippies, i\\xe\\x\\xd be like, \\xe\\x\\xchey, hey! please look me in the eye and remember to come with intention, ok?\\xe\\x\\xd and then, i would jump on him, and hold onto his neck, and i would just twerk, twerk, twerk the shit out of him\\xe\\x\\xa and do some of this shit that i learned in atlanta. and then i would turn upside down immediately afterwards\\xe\\x\\xa to make sure all of that harvard nectar would just drain inside of me. that\\xe\\x\\xs right. \\xe\\x\\xcause i don\\xe\\x\\xt wanna work anymore.q\\xx\\xd\\x\\x\\xi\\xe\\x\\xm very grateful to be pregnant and to be\\xe\\x\\xa this far along, to be seven and a half months pregnant, because, last year, i had a miscarriage, which is very common. and a lot of women who are in their s flip out when they hear that. they\\xe\\x\\xre like, \\xe\\x\\xcoh, my god. that\\xe\\x\\xs so dark and terrible. i can\\xe\\x\\xt believe that.\\xe\\x\\xd i\\xe\\x\\xm . girl, when you\\xe\\x\\xre , you\\xe\\x\\xll know plenty of women who have had a miscarriage. it\\xe\\x\\xs super common, and i wish more women would talk about it so they wouldn\\xe\\x\\xt feel so bad when they go through it. when i told my mom\\xe\\x\\x she\\xe\\x\\xs from a third world country, and when i told her i had one, she was like, \\xe\\x\\xcuh, yeah. where i\\xe\\x\\xm from, that\\xe\\x\\xs like losing a pair of shoes. it\\xe\\x\\xs whatevs, ok?\\xe\\x\\xd and everything happens for a reason. i found out at my six-week sonogram, which is very early. and the doctor says to me, \\xe\\x\\xcoh, my god, i see two sacks, which means you\\xe\\x\\xre having twins.\\xe\\x\\xd and i was like, \\xe\\x\\xcno!\\xe\\x\\xd and then she said, \\xe\\x\\xcbut what i don\\xe\\x\\xt see is a heartbeat.\\xe\\x\\xd and i was like, \\xe\\x\\xcyes!\\xe\\x\\xd \\xe\\x\\xcthe lord is mysterious!\\xe\\x\\xd don\\xe\\x\\xt feel bad, ok? they were the size of poppy seeds. i\\xe\\x\\xve picked boogers larger than the twins that i lost. and most women won\\xe\\x\\xt let their husbands watch when they\\xe\\x\\xre going through a miscarriage. i sat my husband down in front of me while i sat on the toilet, and i was like, \\xe\\x\\xcyou look.\\xe\\x\\xd \\xe\\x\\xcyou watch the whole thing.\\xe\\x\\xd and he felt so bad for me. and i used it as leverage and held that shit over his head for a month and got him to do whatever the fuck i wanted him to do for  days. he took me to see beyonc\\xc\\xa. he bought me a bike off of craigslist. that\\xe\\x\\xs my miscarriage bike, and i love it very much. for  days, i finally had the marriage i always wanted.q\\xx\\xdc\\x\\x\\xi\\xe\\x\\xm scared about giving childbirth, though. i\\xe\\x\\xm\\xe\\x\\x i\\xe\\x\\xm very, very scared of childbirth. that\\xe\\x\\xs why i\\xe\\x\\xm going to hire a doula. you know what that is? you know what a doula is? that\\xe\\x\\xs a white hippie witch\\xe\\x\\xa \\xe\\x\\xathat blows quinoa into your pussy to keyser s\\xc\\xbze all the pain away. a lot of women tried to freak me out. they tried to freak me out about childbirth by saying, \\xe\\x\\xcali, did you know that you\\xe\\x\\xre gonna poop on the table?\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, i look forward to it.\\xe\\x\\xd i\\xe\\x\\xm all backed up from holding in my shit at work. i can\\xe\\x\\xt wait to cleanse. it makes sense, like, that you\\xe\\x\\x that that happens because when you\\xe\\x\\xre in labor, you push, you push, you push, and your husband will be asked to assist in the labor by lifting up your leg, which subsequently turns into a soft serve lever. you just shit on the floor in front of the love of your life. and just when you think that\\xe\\x\\xs enough to make him finally leave you, boom, a baby comes out, and he gotta stay. that\\xe\\x\\xs the real miracle of life, right there. i can already see how a child can really take its toll on a marriage, because the baby hasn\\xe\\x\\xt even come out yet and i am already so resentful towards my husband. so much resentment, especially when he asks me to do shit around the house. \\xe\\x\\xchey, can you wash the dishes?\\xe\\x\\xd \\xe\\x\\xcno!\\xe\\x\\xd \\xe\\x\\xccan you water the plants?\\xe\\x\\xd \\xe\\x\\xci am not doing jack shit anymore. i\\xe\\x\\xm busy makin\\xe\\x\\x a eyeball, ok? are you makin\\xe\\x\\x a foot? i didn\\xe\\x\\xt think so. you change the channel.\\xe\\x\\xdq\\xx\\xe\\x\\x\\xi can already see how there\\xe\\x\\xs, like, this crazy double standard in our society of how it takes so little to be considered a great dad. and it also takes so little to be considered a shitty mom. people praise my husband for coming to all of my doctor\\xe\\x\\xs appointments with me. \\xe\\x\\xcoh, my god. i can\\xe\\x\\xt believe he comes to all your doctor\\xe\\x\\xs appointments. he is so supportive.\\xe\\x\\xd guess who else has to go to those doctor appointments. me! i\\xe\\x\\xm the star of the show. there\\xe\\x\\xs nothing for the camera to see if i\\xe\\x\\xm not there. but he\\xe\\x\\xs the hero for playing candy crush while i get my blood drawn. meanwhile, if i do mushrooms seven months pregnant, i\\xe\\x\\xm a bad mommy.q\\xx~\\x\\x\\xyou know, i\\xe\\x\\x i\\xe\\x\\x i, like, i berate my husband on, like, a daily basis. partially because i really am mad at him. but mostly out of survival, because if he leaves me, i\\xe\\x\\xm fucked. so, i have to chip away at his self-esteem on a daily basis\\xe\\x\\xa to keep him down so that he doesn\\xe\\x\\xt believe that he\\xe\\x\\xs worthy of another woman\\xe\\x\\xs affection and leaves me. i gotta keep him around by keeping him down. people don\\xe\\x\\xt tell you about all this shit that goes down with your body when you get pregnant, you know? your nipples get huge and dark. i didn\\xe\\x\\xt know that. i didn\\xe\\x\\xt know that they get dark so that the baby can see, like, a bullseye. so that the baby can find it easier. and then, you know, they get big\\xe\\x\\x they get big, like fingers. like, \\xe\\x\\xcyou, you. you owe me money, you.\\xe\\x\\xd my nipples look like whoppers now, and naked, i look like a minion. but i\\xe\\x\\xm not gonna be one of those crazy pregnant ladies who tries to get all back in shape right after they get pregnant. no. hopefully, if you see me in a year, i will have the kind of body where, if i do a nude scene on television, people will commend me for being courageous. for doing it.q\\xx\\xbf\\x\\x\\xnow that i\\xe\\x\\xm seven and a half months pregnant, my pussy\\xe\\x\\xs all wet again. but it\\xe\\x\\xs different. it\\xe\\x\\xs not like when i was  years old, when it was like, really hot, you know? and i was like, \\xe\\x\\xcwhy is it different?\\xe\\x\\xd and i looked it up, and my pussy\\xe\\x\\xs all wet again because my\\xe\\x\\x my body\\xe\\x\\xs secreting mucus to protect the baby from bacteria attacking it. that\\xe\\x\\xs not the same. when it\\xe\\x\\xs straight up soldier glue, when it\\xe\\x\\xs neosporin.q\\xx\\xd\\x\\x\\xso, you know, i\\xe\\x\\x i, in\\xe\\x\\x previously, before i met my husband, i had dated a bunch of losers. and then, i meet this dream guy, who\\xe\\x\\xs, like, way more handsome than me, out of my league, graduated from harvard business school. worked hard to trap his ass. got him to propose to me. oh, my god, then we got married, all my dreams coming true, and then we got pregnant, and recently we bought our first home together. and, uh, two weeks into the escrow process, i discovered that my beautiful, harvard-educated husband was $, in debt. and me, with my hard-earned tv money, paid it all off. so, as it turns out, he\\xe\\x\\xs the one who trapped me. how did he do it? how did he bamboozle me? oh! maybe because he went to harvard business school, the epicenter of white-collar crime. he enron\\xe\\x\\xd my ass. and now, if i don\\xe\\x\\xt work, we die. why else do you think i\\xe\\x\\xm performing seven and a half months pregnant? all right, i\\xe\\x\\xve been ali wong. have a good night, everybody. thank you.q\\xe.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "\n",
        "def read_and_preprocess_text(filename, encodings=['utf-8', 'latin-1', 'windows-1252'], preprocessing_steps=None):\n",
        "    try:\n",
        "        with open(filename, 'rb') as file:\n",
        "            content = file.read()\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    decoded_content = codecs.decode(content, encoding)\n",
        "                    preprocessed_content = decoded_content\n",
        "                    if preprocessing_steps:\n",
        "                        for step in preprocessing_steps:\n",
        "                            preprocessed_content = step(preprocessed_content)\n",
        "                    return preprocessed_content\n",
        "                except UnicodeDecodeError:\n",
        "                    print(f\"Failed to decode with encoding '{encoding}'. Trying next encoding...\")\n",
        "            print(\"Failed to read the file with all specified encodings.\")\n",
        "            return None\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{filename}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Example preprocessing steps\n",
        "def lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text):\n",
        "    return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "# Function to save text to a file\n",
        "def save_text_to_file(text, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "# Example usage:\n",
        "filename = \"/content/ali.txt\"\n",
        "preprocessing_steps = [lowercase, remove_numbers]\n",
        "preprocessed_text = read_and_preprocess_text(filename, preprocessing_steps=preprocessing_steps)\n",
        "if preprocessed_text is not None:\n",
        "    print(preprocessed_text)\n",
        "    output_filename = \"preprocessed_ali.txt\"\n",
        "    save_text_to_file(preprocessed_text, output_filename)\n",
        "    print(f\"Preprocessed text saved to '{output_filename}'\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNXexn1Xbd2",
        "outputId": "2da0102c-00f3-4a99-8f2e-a2723065fb61"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to decode with encoding 'utf-8'. Trying next encoding...\n",
            "\u0003]q\u0000(x\t\u0001\u0000\u0000ladies and gentlemen, please welcome to the stage: ali wong! hi. hello! welcome! thank you! thank you for coming. hello! hello. we are gonna have to get this shit over with, âcause i have to pee in, like, ten minutes. but thank you, everybody, so much for coming.q\u0001xg\u0007\u0000\u0000umâ¦ itâs a very exciting day for me. itâs been a very exciting year for me. i turned  this year. yes! thank you, five people. i appreciate that. uh, i can tell that iâm getting older, because, now, when i see an -year-old girl, my automatic thoughtâ¦ is âfuck you.â âfuck you. i donât even know you, but fuck you!â âcause iâm straight up jealous. iâm jealous, first and foremost, of their metabolism. because -year-old girls, they could just eat like shit, and then they take a shit and have a six-pack, right? they got that-that beautiful inner thigh clearance where they put their feet together and thereâs that huge gap here with the light of potential just radiating through.\n",
            "and then, when they go to sleep, they just go to sleep. right? they donât have insomnia yet. they donât know what itâs like to have to take a ambien or download a meditation oasis podcast to calm the chatter of regret and resentment towards your family just cluttering your mind. they have their whole lives ahead of them. they donât have hpv yet. they just go to sleep in peace at night. everybody has hpv, ok? everybody has it. itâs ok. come out already. everybody has it. if you donât have it yet, you go and get it. you go and get it. itâs coming. you donât have hpv yet, youâre a fucking loser, all right? thatâs what that says about you. a lot of men donât know that they have hpv, because itâs undetectable in men. itâs really fucked up. hpv is a ghost that lives inside menâs bodies and says, âboo!â in womenâs bodies. my doctor told me that i have one of two strains of hpv. either i have the kind thatâs gonna turn into cervical cancerâ¦ â¦or i have the kind where my body will heal itself. very helpful, this doctor, right? so, basically, either iâm gonna dieâ¦ or youâre in the presence of wolverine, bitches. weâll find out.q\u0002x¦\b\u0000\u0000um, i can also tell that iâm getting older, because my kindle is turning into a self-help library. iâm not interested in books like fifty shades of grey, ok? iâm interested in the life-changing magic of tidying up. yes. yes, thatâs right, how to declutter my home to achieve inner peace and my optimum level of success. thatâs what your s is all about. how can i turn this shit around? iâm a horrible person, iâm not happy with where i am, how can i turn this shit around? help me, tony robbins, help me!\n",
            "i have a hoarding problem, which iâm hoping is the center of all of my other problems. iâm hoping that if the hoarding goes away, the hpv will also disappear. i have a hoarding problem because my mom is from a third world country and she taught me that you can never throw away anything, because you never know when a dictatorâs gonna overtake the country and snatch all your wealth. so, you better hold onto that retainer from the third grade, âcause it might come in handy as a shovel when youâre busy stuffing gold up your butt and running away from the communists.\n",
            "the last time i was at home in san francisco, i was trying to help her get rid of shit. donât ever do that with your mom. it was like the worst experience of my life. it was so emotional. we were screaming and fighting and yelling and it all came to a climax when she refused to let go of a texas instruments ti-â¦ manual. the manual. she donât even knowâ¦ where the calculator is. those of you under  probably donât know what that calculator is. it was this calculator that bamboozled my generation. we were all required to buy it when we were in eight grade. it cost like $. and everybody thought it was like this judy jetsonâs laptop from the future. all because what? it could graph. it was like the tesla of my time. and my mom got so emotional about the manual and she was like, âyou never know when you might need this.â and i was like, âbutâ¦ i do knowâ¦ that iâm gonna have to clean all this shit up when you die.â âand iâm not trying to be a procrastinator anymore. because according to deepak-oprah, thatâs not the way for me to achieve my optimum level of success.âq\u0003xc\b\u0000\u0000i grew up a lot this past year. uh, this past year i also got married. yeah. to a man who now has hpv. very lucky guy. he gave me something. i gave him something. that will also last forever. no, really. iâm the lucky girl, because before him, i dated a lot of losers. lots of losers. a lot of skaters. you wanna be a grown-ass woman, stop dating skaters. stop dating skaters unless you wanna wake up on a mattress in a kitchen. theyâre sexy on the outside, malt liquor on the inside. horrible. but my husband, i first met him at this wedding and, uh, heâsâ heâs much better looking than me, heâs way out of my league, and i saw him and i was like, âoh, my god, who is that?â and the first thing i learned about him was that, at the time, he was attending harvard business school. and i was like, âoh, my god, iâm gonna trap his ass.â âgoing to trap his ass!â and i trapped his ass initially by not kissing him until the fifth date, which is a very unusual move on my part. but i did it on purpose, because i knew that he was a catch. so i was like, âall right, ali, you gotta make this dude believe that your body is a secret garden.â when, really, itâs a public parkâ¦ â¦that has hosted many reggae festsâ¦ â¦and has even accidentally letâ¦ two homeless people inside. i thought they were hipsters, ok? that store urban outfitters has made things very confusingâ¦ for my generation. you homeless or you a hipster? is that beard for fashion or for warmth? it happened toâ¦ it happened in san francisco, when i was living there, and i saw this guy in broad daylight and we had, like, we hadâ¦ we had so much chemistry. he was like, âhey, wassup?â i was like, âwassup?â and weâ the next thing i knew, we were getting busy in the back of my volvo. and then after we were done, he was like, âhey, can you drop me off?â i was like, âwhere?â he was like, âat the park.â and i dropped him off at golden gate park and watched him run into the middle with all his other homeless friends, and i was like, âoh, no!â âi just fucked a homeless dude! again!âq\u0004x)\u000f\u0000\u0000my husband is asian. which a lot of people are shocked by, because, usually, asian-american women who, like, you know, wear these kinda glasses and have a lot of opinions, they like to date white dudes. you go to any hipster neighborhood in a major city in america and that shit is turning into a yoko ono factory. itâsâ¦ too much. i donât know whatâs wrong with these bitches. i get it, you know, because being with a white dude you feel veryâ¦ you feel very picturesque when youâre with a white dude, you know. you feel like youâre in a wes anderson movie or something. and you know, white dudes, they teach you about a lot of cool stuff like voting and recycling, and disturbing documentaries. they introduce you to cool stuff like that and itâs very, you know, itâs hot hookinâ up with a white dude. i mean, nothing makes me feel more powerful than when a white dude eats my pussy. oh, my god. i just feel like iâm absorbing all of that privilege and all of that entitlementâ¦ â¦you know, just right there, through the money hole and justâ¦ and then also, heâs so vulnerable down there. iâm, like, âi could just crush your head at any moment, white man! i could just kill you right now! crush those brains! colonize the colonizer!â you know?\n",
            "but i think that for marriage, it can be nice to be with somebody of your own race. the advantage is that you get to go homeâ¦ and be racist together. you get to say whatever you like! you donât gotta explain shit. my husband, half-filipino, half-japanese. iâm half-chinese and half-vietnamese. and we spend  percent of our time shitting on korean people. itâsâ¦ amazing. itâs what love is built on, you know?\n",
            "my last boyfriend was cuban and his family would shit on mexican people all the time. and i was like, âhold it. you guys arenât mexican?â asian-american men are very underrated. i donât know why people donât go for them. theyâre the sexiest. asian men are the sexiest. they got no body hair from the neck down. itâs like making love to a dolphin. oh, my god. itâs so smooth, just like a slip and slide. just black fish, tilikum, all up in my bed every night, you know? ooh-wee. you mess with a jewish dude and your body is all fucked up afterwards. itâs all red and inflamed and youâre like, âi did not ask to be exfoliated today.â âthis is the last time i go on j-date, more like loofah date. thanks for the rug burn, avi.â and then asian men, no body odor. none. they just smell like responsibility. thatâs where the umami flavor comes from.\n",
            "i think my husband and i have a huge unspoken understanding, uh, between each other, because heâs half-filipino and half-japanese and iâm half-chinese and half-vietnamese. so, weâre both half-fancy asianâ¦ â¦and half-jungle asian. yeah! you guys know the difference. the fancy asians are the chinese, the japanese. they get to do fancy things like host olympics. jungle asians host diseases. itâsâ¦ itâs different. but he grew up on the east coast, going to private school, playing lacrosse, uh, you know, learning latin and playing chess and rugby. he grew up like filipino carlton, ok? so, he didnât know anything about vietnamese people until he met me. and on one of our first dates, he took me to this restaurant on the west side of los angeles called pho show. he was like, âitâs authentic vietnamese. i read about it on yelp!â i was like, âitâs not authentic, ok?â you can tell, first and foremost, by the name, âcause it donât got a number in it. second of all, you can tell by the bathroom. if it was legit, the bathroom would double as a supply closet. when i pee, i need to see ten gallons of bleach, an atm machine and a grandma with glaucoma napping in the corner. and the wait staff here is too nice. we need to leave this restaurant deaf and emotionally abused.q\u0005x;\u0004\u0000\u0000i grew up going to private school, too. him and i are both total, like, private school asians. we both are big hippies, too. we like to backpack through southeast asia. we like to do yoga. we do ayahuasca ceremonies. we do silent meditation retreats. thatâs right, we pay $ to shut up for a weekend. we do shit like that. uh, we eat gluten-free, which means we eat all that bread that tastes like free-range chewbacca. we eat that lesbian bread thatâs likeâ¦ â¦a thousand percent of your daily fiberâ¦ and  percent spoken word poetry. when you eat it, you queef a shitty poem aboutâ¦ â¦supporting caitlyn jenner or whatever. and so, itâs funny, right, because heâs asian, too. but sometimes, all of this hippy-dippy shit we doâ¦ makes me feel like we are white people doing an impression of asian people. like, we have these chinese scrolls up on the wallâ¦ and neither of us know what the fuck they mean. weâre like, âoh, that seems to go very well with our buddha piggy bank from pier  imports. that seems to be providing some good feng shui for the house.q\u0006x¬\u0005\u0000\u0000him and i had been dating for four years and iâ i just had this sneaking suspicion that he was gonna proposeâ¦ becauseâ¦ i had been pressuring him to do it. so, you know, i just had this wacky womenâs intuition. thatâs how proposals really work, ok? a woman has to incept the idea into the manâs head. first passively and then if he doesnât get the message, extremely aggressively. you gotta threaten to leave without ever actually leaving, because you know that youâre too old and itâs too late to go back out there and find a new man and start the whole manipulation cycle all over again. so, youâre like, âiâm just gonna stick with this dude, focus on trapping this dude, and just nag the shit outta him until he becomes weak and caves in and gets fed up and is like, âshut the fuck up! fine, will you marry me?â and then afterwards, the woman is always, like, âoh, my god! he proposed!â âit came outta nowhere. and look, he got me the exact ring i wanted. how did he know? maybe he saw it on my pinterest page or somethingâ¦ that i sent to my best friend, that i told her to send to him every day.â let me tell you something. if a man has a pinterest pageâ¦ heâs probably pinterested in men. we got engaged on a saturday. i bought my wedding dress the following tuesdayâ¦ because i had tried it on in . i was ready. i was ripe. i was rotten. i need to be made into banana bread. thatâs how rotten i was.q\u0007x\u001b\u0015\u0000\u0000people are always very surprised at how, off-stage, with my husband, iâm a completely different person. youâ like, you would not recognize my personality at all with him. with him, iâm very soft, and, like, very nurturing and very domestic. weâve been together now for five years, and for five years, iâve packed his lunch every single day. yeah. yes. yes. yes. i did that so that heâd become dependent on me. âcause he graduated from harvard business school, and i donât wanna work anymore. i donât. i straight up donât wanna work anymore. i donât feed him out of the goodness of my heart. i do it as an investment in my financial future. âcause i donât wanna work anymore. iâve been reading that book by sheryl sandberg, sheâs the c.o.o. of facebook, and she wrote that book that got women all riled up about our careers. talking about how we as women should challenge ourselves to sit at the table and rise to the top. and her book is called lean in. well, i donât wanna lean in, ok? i wanna lie down. i want to lie the fuck down. i think feminism is the worst thing that ever happened to women. our job used to be no job. we had it so good. we could have done the smart thing, which would have been to continue playing dumb for the next century and be like, âweâre dumb women. we donât know how to do anything. so, i guess we better just stay at home all day and eat snacks and watch ellen.â ââcause weâre too stupid to have any real responsibility.â and then, all these women had to show off and be like, âwe could do it! we could do anything.â âbitch, shut up!â âdonât tell them the secret.â they ruined it for us, and now weâre expected to work. when i hear the phrase, âdouble-income household,â i wanna throw up. a lot of women get very upset with me about those comments. and theyâre like, âbut, ali, we have so many more options now.â oh, you donât think we had a lot of options when our day was free? unscheduled, unsupervised, and most importantly, sponsored? do you know how much shittier food tastes when you know you have to earn it?\n",
            "a lot of my friends, when we walk around together, theyâll get very judgmental about housewives that weâll see on the street. and theyâll be like, âlook at that fucking housewife. not doing anything. look at that housewife, just walking around all day, getting massages in her lululemon pants.â iâm like, âthat bitch is a genius.â âsheâs not a housewife, sheâs retired.â\n",
            "i do write for fresh off the boat on abc. yeah. which isâ¦ itâs a great show. i love it a lot. i love my co-workers. itâs a great writing staff and in terms of day jobs, itâs probably one of the best you could ask for, but i still gotta work at a office every day. which means i gotta shit in a office every day. housewives, they donât gotta shit in a office. housewives get to shit in their house. skin to seat. they donât gotta use that horrible toilet paper cover. they donât gottaâ¦ â¦ten times a day, every dayâ¦ like youâre about to eat a sad-ass meal. they donât gotta do that. they donât gotta use that one-ply toilet paper, that office toilet paper, that they purposely make difficult to pull out. they try to ration me with their communist toilet paper thatâs not even effective. it basically just dehydrates your butt hole. itâs basically like wiping your butt with the desert. i literally spat on my toilet paper two days ago, to try to make a macgyver baby wipe, to moisten it, and then it backfired âcause my fingers broke through and digitally stimulated more doo doo to come out, and then i had to start all over again. and you can never finish wiping at work because you always feel rushed âcause youâre paranoid that your co-workerâs gonna recognize your shoes underneath the stall. and youâre like, âoh, no! courtneyâs listening. sheâs waiting. sheâs timing me.â and then you hurry, hurry, hurry, and then you never finish wiping and then your butt hole feels caked in doo doo all day long. and then if you dare scratch yourself, your underwear at the end of the day looks like itâs been run over by the goonies. housewives, they donât gotta muffle their shit, too. they donât gotta worry about the velocity with which their doo doo comes out. they donât gotta try to, you know, squeeze the butt cheeks together to make sure that the doo doo comes out at a slow and steady pace, so that no unpredictable noise suddenly escapes and brings you deep, deep shame. housewives are free to just blow ass into the toilet and let it echo and reverberate to the ends of their hallways while watching as much netflix on their ipad as they want. they donât gotta take these boring, repressed shits. they can listen to podcasts. planet money. they can do whatever they want.\n",
            "you know, itâsâ itâs very distracting for me when i hear my co-workers blow ass into the toilet. i lose respect for them. nothing they say to me anymore holds any sort of credence. i heard one of my co-workers blow ass into the toilet the other day. this bitch had the nerve to come up to me and say, âyou need to get to work on time.â i was like, âyou need to eat bananas.â âi saw those green ballet flats. i know that shit was you. donât try to tell me to get my shit together when i heard you not have your shit together.âq\bxæ\u000b\u0000\u0000my father-in-law had this huge sit-down with me and my husband recently. um, and he was like, âhey, i wanna talk to you guys about money. you guys need to make a lot more money if you wanna provide your children with the same kind of privileged childhood that you guys had.â i was like, âwhy you telling me this shit? i should not be a part of this conversation. you tell you son that. donât your understand that i trapped your son for his earning potential? why else would i choose to fuck one person for the rest of my life? i chose to marry him on the promise of early retirement, and when i said, âi do,â what i really meant was, âoh, iâm done.'â iâm done. i donât wanna work anymore and iâm not dieting anymore. since i got married last year, iâve been eating fried chicken skin every day since. thatâs right. and just fulfilling my destiny. which is to turn into a circle with eyelashes. like mrs. pacman, justâ¦ letâs redecorate.\n",
            "i gave up a lot of myself when i got married. iâm aâ iâm a disgusting pervert. iâm a pervert. iâm a gross filthy animal. and i think itâs because i started watching porn at a very young age. and what happens when you start watching porn at a young age is thatâ¦ y-you get sicker, and sicker, and sicker. the images you crave get sicker, and sicker, and sicker, but itâs ok, because the internet will always catch up to you.\n",
            "i broke up with my last boyfriend because he refused to put it in the back. i was like, âuh, youâre a idiot, dude. do you realize that if i went on craigslistâ¦ and posted âtiny asian female seeking analâ¦â the internet would crash.â âand all the jewish male heads in the universe would simultaneously explode.â they would explode. a lot of women get really, you knowâ¦ freaked out about anal. and theyâre like, âoh, i donât wanna do that. iâm scared ofâ of the pain.â you ainât scared of the pain. women, they wax their eyebrows, they do all sorts of crazy shit. youâre not scared of the pain. what youâre really scared of is doo doo on the dick. youâre scared that heâs gonna see that and thatâs gonna be all of your shame, your inner evil, all your secrets and lies. sephora canât help you now. but donât worry, âcause when he puts it in the butt, all heâs thinking about is, âi just put it in her butt.â âi gotta go call my mom, my dad, dave, my grandma.â youâreâ if youâre married, youâre gonna have to do anal eventually, ok? you have to, because you gotta change it up. you gotta change it up, so that you donât cheat on each other. you gotta keep it interesting. if you put it in different holes, maybe youâll feel like youâre fucking different people. i was very sexually active in my s, and as a result, iâm a little bitâ¦ â¦stretched out down there, ok? so, when i finally did anal, i just felt like i got a second chance at life, you know? i was, like, âoh, my god! itâs like iâm going back in time!â âª a whole new world âª it was magical.q\txe\u0004\u0000\u0000a big fantasy of mine before i got married was to help as many men as possible discover their prostate. yeah, like a conqueror. i just wanted toâ¦ now, if you havenât done it before, ladies, go home and treat yourself. do it tonight. you only live once. yolo. just sneak yourâ just give your man a littleâ a little push-push in the tush-tush. just give him a little atari, you know, and youâll get a lot of resistance from the man at first. youâll get a lot of âno! no! no! no, please! no, really, i donâtâ no! i donât! i donât! no!â they get all squirmy wormy becauseâ¦ theyâre scared. theyâre scared that if you stick your thumb up there and succeed, and they like it, that then, it might mean that theyâre gay. and i like that fear. that shit turns me on, you know? especially when that fear metamorphosizes into pleasure. oh, my god! and you just see the look in the manâs eye like heâs discovered nirvana. and itâs like youâre the first lady to show him that he had a magical clit in his butt hole. and then, you as the woman, in his eyes, just become the lord of the rim, you know?q\n",
            "xn\u0004\u0000\u0000my husband is unfortunately just not as freaky as me. whenâ when iâve asked him to spank me, this is what he does. âhey. hey, are you ok? are you all right? you know i respect you, right?â iâm, like, âyes, i know you respect me and thatâs why you need to abuse me. ok?â âcause itâs the most strong-headed, loud-mouthed women who like to be abused the most in bed. women who are c.e.o.s, they just wanna be roughed around. they just want theirâ glasses always means the woman wants someâ itâs because weâre so in control all the time, that we just wanna experience some risk and be out of control, you know? like, âi donât wanna die! donât kill me! i donât wanna die!â but i also donât want to be sure that iâm gonna live. you know? i just wanna be out of control for once. justâ just choke me enough so that i canât talk. âcause if i can talk, iâm gonna tell you what to do. and iâm tired of being the boss. iâm the boss all the time, so, in the bedroom, you be the boss. yes. because iâm the real boss. and i told you so, motherfucker, so do it.q\u000bxê\u0001\u0000\u0000sheryl sandberg, that woman who wrote lean in, has had such a big impact that now, because of her, there is a ban on the word âbossyâ in elementary schools, because according to her, itâs sexist to use the word âbossy,â because boys are never called bossy. so, now, instead of saying, âyouâre bossy,â youâre supposed to say, âyou have executive leadership skills.â which is a very roundabout way of saying: âyouâre a little cunt.âq\fxß\u0002\u0000\u0000iâm just waiting for the right moment to, like, become a housewife, financially, you know? i want my husband to get us to, like, a certain point financially. i wanna get to the point as a couple where i can comfortably afford sliced mango. know what iâm talking about? iâm talking about that whole foods mango. that $-a-box whole foods mango that was sliced by white people. thatâs the kind of income bracket iâm striving for. thatâs when you know youâve made it, when youâre eating mango that was sliced by a dude named noah. i want noah mangoâ¦ â¦rebecca kiwi, danielle pineapple. you know what else i want? i wanna be able to take a stroll on a sidewalk, see a quarter, and just keep on walking. like a princess.q\rx}\u0000\u0000\u0000i have some useful advice for all my asian-american brothers and sisters. yeah! never go paintballing with a vietnam veteran.q\u000ex~\u000b\u0000\u0000so, i donât know if you guys can tell, but i am seven and a half months pregnant. yeah. itâs very rare and unusual to see a female comic perform pregnant, because female comicsâ¦ donât get pregnant. just try to think of one. i dare you. thereâsâ none of them. once they do get pregnant, they generally disappear. thatâs not the case with male comics. once they have a baby, theyâll get up on stage a week afterwards and theyâll be like, âguys, i just had this fucking baby. that babyâs a little piece of shit. itâs so annoying and boring.â and all these other shitty dads in the audience are, like, âthatâs hilarious. i identify.â and their fame just swells because they become this relatable family funny man all of a sudden. meanwhile, the mom is at home, chapping her nipples, feeding the fucking baby, and wearing a frozen diaper âcause her pussy needs to heal from the babyâs head shredding it up. sheâs busy. so, i donât know whatâs gonna happen to me. you know, a lot of my female stand-up comic friends who are a lot more successful and famous than me discouraged me from having a kid. and they were like, âali, why are you gonna have a kid? you just gonna becomeâ youâre gonna disappear, and youâre gonna become some lame stay-at-home mom.â i was like, âyeah, thatâs the dream.â thatâs the point. this is the ultimate trap. i won, you know?\n",
            "another thing a lot of my friends said to me when they were discouraging me from having a kid, they were like, âwhy are you gonna have a kid? why donât you just travel the world with your husband and just do whatever you want for the rest of your lives with no kid attached.â i was like, âyeah, thatâs coolâ¦ until my husband dies.â which heâs definitely gonna before me. because iâm a asian woman, and therefore, guaranteed to live until iâm a billion. iâm guaranteed, like a turtle from the galapagos, ok? we all know the phrase âblack donât crack.â well, asian donât die. we donât die. especially the women, we live forever. and you know why weâre such bad drivers? because weâre trying to die. weâre like, âyeah! let me see how invincible i really am!â âimma make this left hand turn signal and ignore this red light completely.â âiâm gonna make a right turnâ i changed my mind, itâs a u-turn!â âi changed my mind again. itâs a o-turn!â every time i get into a car accidentâ¦ â¦iâm like, âoh, my god, not again!â i need to hide my face so that everybody doesnât see that itâs what everybody thought it was gonna be. so embarrassing. my toyota corolla is a mess. thereâs this huge bear claw scratch on the side from this aggressive brick wall that came out of nowhere. and then, on the hood, thereâs multiple hand prints from pedestrians who have had to alert me of their existence. i donât know whatâs wrong with me, but iâm still here, you know?q\u000fx°\u0004\u0000\u0000i need to have children to keep me company when i get older. itâs lonely. my mom is , going through a full blown mid-life crisis. âcause she knows that sheâs got a century more to go. and she is so lonely. all of her white friends, dead. her mexican friends, dead. black friends, dead. iâm just kidding. she doesnât have any black friends. life is not rush hour, the movie, ok? i need children to be there for me when iâm older, when i get as old as her. and when i say be there for me, i mean pay for me when my husband isnât around to support me anymore. iâm not trying to be one of those old chinese ladies who recycles for a living. thatâs not my destiny, ok? old chinese ladies, they donât give a fuck. they got no shame. theyâre like, âiâm just gonna recycleâ¦ go baldâ¦ go to the park, do this shit.â they do that âcause itâs a free activity. for them. they do it in theirâ their big-ass v. stiviano visor, their darth vader-tomb raider- boba fett helmet. they wear that to protect themselves from their arch-nemesis, the sun. their in a contest to see whoâs gonna burn out first. old asian ladies and the sun are like the tupac and biggie of longevity.q\u0010xì\u0002\u0000\u0000i also decided to have a kid because uh, iâm only , which, i know, is not technically high-risk, but my body was starting to show signs of change. and itâ and it scared me. like, iâm only  andâ¦ â¦my pussy is not as wet as it used to be. itâs very demoralizing, ok? do you remember when you were  years old, and your pussy was just sopping wet all the time? all the time, you just took it for granted that you could just reach your hand down your pants at any given moment, you throw up the peace sign afterwards, and there would be that snail-trail in between your fingers. oh, my god, it was so juicy. you could just blow a bubble wand with it, justâ¦ âi slime you, i slime you. ghostbusters!âq\u0011x\u0006\u0000\u0000i donât know what kind of mother iâm gonna be. iâmâ iâm , and i did have to get a little bit of science involved when trying to get pregnant. and a lot of thatâ¦ is most likely my fault. because, when i was in my s, i ate plan b like skittles. so, my uterus probably looked like a smokerâs lung. and i found out that my progesterone levels were alarmingly low. so, then i had to take these hormone pills that were suppositories, and push pop them up myself every single night. and then, at my writing job, at fresh off the boat, i would be storyboarding in front of my co-workers, and then, at some point, the pill would inevitably dissolve and melt into my underwear, and i had to act like everything was ok, when everything was clearly not ok. and then, a side effect of the progesterone was that it made me extremely itchy. so, then i had to find ways to discretely scratch myself underneath the conference table, and then resist the urge to immediately smell my fingers afterwards. i want to be able to smell my fingers when i wanna smell my own goddamn fingers. housewives, they can just scratch and sniff all day long. they just vacuum, scratch, sniff. they make a sandwich. âuh, mmm.â they watch property brothers, scratch, âwhatâs crackinâ? mmm.â every time you scratch yourself, all you can think about is, âwhen can i smell my fingers? when can i smell my fingers? when can i discretely find a way toâ¦â ââ¦smell my fingers?â nature made you urgently curious to protect you, âcause you gotta check that itâs all good in the hood. if itâs too funky, you need to see a doctor. your fingers are your first webmd.q\u0012x¢\t\u0000\u0000when my husband and i were trying to have a kid, a lot of people were like, âoh, my god, thatâs so hot. you guys doinâ a lot of fuckinâ?â no, dude. thatâsâ thatâs shit you do in your s, ok? when inâ when youâre in your s, and youâve been trying to get pregnant for a while, it gets very clinical. you pee on these ovulation strips that tell you when the eggs are droppinâ. it tells you when itâs easter time. and i would only fuck him when it was easter time. it was, like, only four days out of the month, and outside of that, i would be like, âweâre not fuckinâ. i need you to save it. i want your sperm to be as pent-up, and as angry and rapey as possible. so that, when they come out, itâs like, ârelease the kraken!'â and they just come out like a bunch of angry refugees escaping a dictatorship, you know? and, umâ¦ yeah, and most of the time, like, we wouldnât even have sex, âcause i was so tired when i would come home, and see the smiley face on the ovulation strip, and iâd be like, âok, itâs go time,â and i would just give my husband a hand job most of the time, and he would close his eyes immediately. i know what that means, ok? when somebody closes their eyes during sex, itâs not because theyâre in such ecstasy with you thatâ that they need to close their eyes. when somebody closes their eyes during sex, itâs because theyâre literally trying to shut the image of your face out of their head and instead project two latina lesbians that they saw earlier that day on redtube onto the back of their eyelids. which is fine by me, because then he doesnât have to see the expression on my face that says, âplease, hurry the fuck up.â and then, when he was about to finish, i could always tell because the indication is very universal when a man is about to finish. itâs when they get thatâ¦ that stupid-ass look on their faceâ¦ â¦where they look like they just got bit by a zombie, justâ¦ and then, because weâre hippies, iâd be like, âhey, hey! please look me in the eye and remember to come with intention, ok?â and then, i would jump on him, and hold onto his neck, and i would just twerk, twerk, twerk the shit out of himâ¦ and do some of this shit that i learned in atlanta. and then i would turn upside down immediately afterwardsâ¦ to make sure all of that harvard nectar would just drain inside of me. thatâs right. âcause i donât wanna work anymore.q\u0013xö\u0006\u0000\u0000iâm very grateful to be pregnant and to beâ¦ this far along, to be seven and a half months pregnant, because, last year, i had a miscarriage, which is very common. and a lot of women who are in their s flip out when they hear that. theyâre like, âoh, my god. thatâs so dark and terrible. i canât believe that.â iâm . girl, when youâre , youâll know plenty of women who have had a miscarriage. itâs super common, and i wish more women would talk about it so they wouldnât feel so bad when they go through it. when i told my momâ sheâs from a third world country, and when i told her i had one, she was like, âuh, yeah. where iâm from, thatâs like losing a pair of shoes. itâs whatevs, ok?â and everything happens for a reason. i found out at my six-week sonogram, which is very early. and the doctor says to me, âoh, my god, i see two sacks, which means youâre having twins.â and i was like, âno!â and then she said, âbut what i donât see is a heartbeat.â and i was like, âyes!â âthe lord is mysterious!â donât feel bad, ok? they were the size of poppy seeds. iâve picked boogers larger than the twins that i lost. and most women wonât let their husbands watch when theyâre going through a miscarriage. i sat my husband down in front of me while i sat on the toilet, and i was like, âyou look.â âyou watch the whole thing.â and he felt so bad for me. and i used it as leverage and held that shit over his head for a month and got him to do whatever the fuck i wanted him to do for  days. he took me to see beyoncã©. he bought me a bike off of craigslist. thatâs my miscarriage bike, and i love it very much. for  days, i finally had the marriage i always wanted.q\u0014xü\u0005\u0000\u0000iâm scared about giving childbirth, though. iâmâ iâm very, very scared of childbirth. thatâs why iâm going to hire a doula. you know what that is? you know what a doula is? thatâs a white hippie witchâ¦ â¦that blows quinoa into your pussy to keyser sã¶ze all the pain away. a lot of women tried to freak me out. they tried to freak me out about childbirth by saying, âali, did you know that youâre gonna poop on the table?â i was like, âyeah, i look forward to it.â iâm all backed up from holding in my shit at work. i canât wait to cleanse. it makes sense, like, that youâ that that happens because when youâre in labor, you push, you push, you push, and your husband will be asked to assist in the labor by lifting up your leg, which subsequently turns into a soft serve lever. you just shit on the floor in front of the love of your life. and just when you think thatâs enough to make him finally leave you, boom, a baby comes out, and he gotta stay. thatâs the real miracle of life, right there. i can already see how a child can really take its toll on a marriage, because the baby hasnât even come out yet and i am already so resentful towards my husband. so much resentment, especially when he asks me to do shit around the house. âhey, can you wash the dishes?â âno!â âcan you water the plants?â âi am not doing jack shit anymore. iâm busy makinâ a eyeball, ok? are you makinâ a foot? i didnât think so. you change the channel.âq\u0015x\u0002\u0000\u0000i can already see how thereâs, like, this crazy double standard in our society of how it takes so little to be considered a great dad. and it also takes so little to be considered a shitty mom. people praise my husband for coming to all of my doctorâs appointments with me. âoh, my god. i canât believe he comes to all your doctorâs appointments. he is so supportive.â guess who else has to go to those doctor appointments. me! iâm the star of the show. thereâs nothing for the camera to see if iâm not there. but heâs the hero for playing candy crush while i get my blood drawn. meanwhile, if i do mushrooms seven months pregnant, iâm a bad mommy.q\u0016x~\u0004\u0000\u0000you know, iâ iâ i, like, i berate my husband on, like, a daily basis. partially because i really am mad at him. but mostly out of survival, because if he leaves me, iâm fucked. so, i have to chip away at his self-esteem on a daily basisâ¦ to keep him down so that he doesnât believe that heâs worthy of another womanâs affection and leaves me. i gotta keep him around by keeping him down. people donât tell you about all this shit that goes down with your body when you get pregnant, you know? your nipples get huge and dark. i didnât know that. i didnât know that they get dark so that the baby can see, like, a bullseye. so that the baby can find it easier. and then, you know, they get bigâ they get big, like fingers. like, âyou, you. you owe me money, you.â my nipples look like whoppers now, and naked, i look like a minion. but iâm not gonna be one of those crazy pregnant ladies who tries to get all back in shape right after they get pregnant. no. hopefully, if you see me in a year, i will have the kind of body where, if i do a nude scene on television, people will commend me for being courageous. for doing it.q\u0017x¿\u0001\u0000\u0000now that iâm seven and a half months pregnant, my pussyâs all wet again. but itâs different. itâs not like when i was  years old, when it was like, really hot, you know? and i was like, âwhy is it different?â and i looked it up, and my pussyâs all wet again because myâ my bodyâs secreting mucus to protect the baby from bacteria attacking it. thatâs not the same. when itâs straight up soldier glue, when itâs neosporin.q\u0018xø\u0003\u0000\u0000so, you know, iâ i, inâ previously, before i met my husband, i had dated a bunch of losers. and then, i meet this dream guy, whoâs, like, way more handsome than me, out of my league, graduated from harvard business school. worked hard to trap his ass. got him to propose to me. oh, my god, then we got married, all my dreams coming true, and then we got pregnant, and recently we bought our first home together. and, uh, two weeks into the escrow process, i discovered that my beautiful, harvard-educated husband was $, in debt. and me, with my hard-earned tv money, paid it all off. so, as it turns out, heâs the one who trapped me. how did he do it? how did he bamboozle me? oh! maybe because he went to harvard business school, the epicenter of white-collar crime. he enronâd my ass. and now, if i donât work, we die. why else do you think iâm performing seven and a half months pregnant? all right, iâve been ali wong. have a good night, everybody. thank you.q\u0019e.\n",
            "Preprocessed text saved to 'preprocessed_ali.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs  # Import the codecs module for handling text encodings\n",
        "\n",
        "def read_and_preprocess_text(filename, encodings=['utf-8', 'latin-1', 'windows-1252'], preprocessing_steps=None):\n",
        "    try:\n",
        "        with open(filename, 'rb') as file:  # Open the file in binary mode\n",
        "            content = file.read()  # Read the content of the file\n",
        "            for encoding in encodings:  # Iterate over the specified encodings\n",
        "                try:\n",
        "                    # Decode the content using the current encoding\n",
        "                    decoded_content = codecs.encode(str(content), encoding).decode(\"utf-8\")\n",
        "                    preprocessed_content = decoded_content  # Assign the decoded content to the preprocessed content variable\n",
        "                    if preprocessing_steps:  # Check if preprocessing steps are provided\n",
        "                        for step in preprocessing_steps:  # Iterate over the preprocessing steps\n",
        "                            preprocessed_content = step(preprocessed_content)  # Apply each preprocessing step\n",
        "                    return preprocessed_content  # Return the preprocessed content\n",
        "                except UnicodeDecodeError:  # Handle decoding errors\n",
        "                    print(f\"Failed to decode with encoding '{encoding}'. Trying next encoding...\")\n",
        "            print(\"Failed to read the file with all specified encodings.\")  # Print a message if all encodings fail\n",
        "            return None  # Return None if file cannot be read\n",
        "    except FileNotFoundError:  # Handle file not found error\n",
        "        print(f\"File '{filename}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Define preprocessing steps as functions\n",
        "def lowercase(text):\n",
        "    return text.lower()  # Convert text to lowercase\n",
        "\n",
        "def remove_numbers(text):\n",
        "    return ''.join([char for char in text if not char.isdigit()])  # Remove numbers from text\n",
        "\n",
        "# Example usage:\n",
        "filename = \"/content/ali.txt\"  # Specify the filename\n",
        "preprocessing_steps = [lowercase, remove_numbers]  # Define preprocessing steps to apply\n",
        "preprocessed_text = read_and_preprocess_text(filename, preprocessing_steps=preprocessing_steps)  # Preprocess the text\n",
        "if preprocessed_text is not None:  # Check if preprocessing was successful\n",
        "    print(preprocessed_text)  # Print the preprocessed text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZGBF2IOcux1",
        "outputId": "6f053587-0ee8-4ec4-a332-f786e03a00c6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"\\x\\x]q\\x(x\\t\\x\\x\\xladies and gentlemen, please welcome to the stage: ali wong! hi. hello! welcome! thank you! thank you for coming. hello! hello. we are gonna have to get this shit over with, \\xe\\x\\xcause i have to pee in, like, ten minutes. but thank you, everybody, so much for coming.q\\xxg\\x\\x\\xum\\xe\\x\\xa it\\xe\\x\\xs a very exciting day for me. it\\xe\\x\\xs been a very exciting year for me. i turned  this year. yes! thank you, five people. i appreciate that. uh, i can tell that i\\xe\\x\\xm getting older, because, now, when i see an -year-old girl, my automatic thought\\xe\\x\\xa is \\xe\\x\\xcfuck you.\\xe\\x\\xd \\xe\\x\\xcfuck you. i don\\xe\\x\\xt even know you, but fuck you!\\xe\\x\\xd \\xe\\x\\xcause i\\xe\\x\\xm straight up jealous. i\\xe\\x\\xm jealous, first and foremost, of their metabolism. because -year-old girls, they could just eat like shit, and then they take a shit and have a six-pack, right? they got that-that beautiful inner thigh clearance where they put their feet together and there\\xe\\x\\xs that huge gap here with the light of potential just radiating through.\\nand then, when they go to sleep, they just go to sleep. right? they don\\xe\\x\\xt have insomnia yet. they don\\xe\\x\\xt know what it\\xe\\x\\xs like to have to take a ambien or download a meditation oasis podcast to calm the chatter of regret and resentment towards your family just cluttering your mind. they have their whole lives ahead of them. they don\\xe\\x\\xt have hpv yet. they just go to sleep in peace at night. everybody has hpv, ok? everybody has it. it\\xe\\x\\xs ok. come out already. everybody has it. if you don\\xe\\x\\xt have it yet, you go and get it. you go and get it. it\\xe\\x\\xs coming. you don\\xe\\x\\xt have hpv yet, you\\xe\\x\\xre a fucking loser, all right? that\\xe\\x\\xs what that says about you. a lot of men don\\xe\\x\\xt know that they have hpv, because it\\xe\\x\\xs undetectable in men. it\\xe\\x\\xs really fucked up. hpv is a ghost that lives inside men\\xe\\x\\xs bodies and says, \\xe\\x\\xcboo!\\xe\\x\\xd in women\\xe\\x\\xs bodies. my doctor told me that i have one of two strains of hpv. either i have the kind that\\xe\\x\\xs gonna turn into cervical cancer\\xe\\x\\xa \\xe\\x\\xaor i have the kind where my body will heal itself. very helpful, this doctor, right? so, basically, either i\\xe\\x\\xm gonna die\\xe\\x\\xa or you\\xe\\x\\xre in the presence of wolverine, bitches. we\\xe\\x\\xll find out.q\\xx\\xa\\x\\x\\xum, i can also tell that i\\xe\\x\\xm getting older, because my kindle is turning into a self-help library. i\\xe\\x\\xm not interested in books like fifty shades of grey, ok? i\\xe\\x\\xm interested in the life-changing magic of tidying up. yes. yes, that\\xe\\x\\xs right, how to declutter my home to achieve inner peace and my optimum level of success. that\\xe\\x\\xs what your s is all about. how can i turn this shit around? i\\xe\\x\\xm a horrible person, i\\xe\\x\\xm not happy with where i am, how can i turn this shit around? help me, tony robbins, help me!\\ni have a hoarding problem, which i\\xe\\x\\xm hoping is the center of all of my other problems. i\\xe\\x\\xm hoping that if the hoarding goes away, the hpv will also disappear. i have a hoarding problem because my mom is from a third world country and she taught me that you can never throw away anything, because you never know when a dictator\\xe\\x\\xs gonna overtake the country and snatch all your wealth. so, you better hold onto that retainer from the third grade, \\xe\\x\\xcause it might come in handy as a shovel when you\\xe\\x\\xre busy stuffing gold up your butt and running away from the communists.\\nthe last time i was at home in san francisco, i was trying to help her get rid of shit. don\\xe\\x\\xt ever do that with your mom. it was like the worst experience of my life. it was so emotional. we were screaming and fighting and yelling and it all came to a climax when she refused to let go of a texas instruments ti-\\xe\\x\\xa manual. the manual. she don\\xe\\x\\xt even know\\xe\\x\\xa where the calculator is. those of you under  probably don\\xe\\x\\xt know what that calculator is. it was this calculator that bamboozled my generation. we were all required to buy it when we were in eight grade. it cost like $. and everybody thought it was like this judy jetson\\xe\\x\\xs laptop from the future. all because what? it could graph. it was like the tesla of my time. and my mom got so emotional about the manual and she was like, \\xe\\x\\xcyou never know when you might need this.\\xe\\x\\xd and i was like, \\xe\\x\\xcbut\\xe\\x\\xa i do know\\xe\\x\\xa that i\\xe\\x\\xm gonna have to clean all this shit up when you die.\\xe\\x\\xd \\xe\\x\\xcand i\\xe\\x\\xm not trying to be a procrastinator anymore. because according to deepak-oprah, that\\xe\\x\\xs not the way for me to achieve my optimum level of success.\\xe\\x\\xdq\\xxc\\x\\x\\xi grew up a lot this past year. uh, this past year i also got married. yeah. to a man who now has hpv. very lucky guy. he gave me something. i gave him something. that will also last forever. no, really. i\\xe\\x\\xm the lucky girl, because before him, i dated a lot of losers. lots of losers. a lot of skaters. you wanna be a grown-ass woman, stop dating skaters. stop dating skaters unless you wanna wake up on a mattress in a kitchen. they\\xe\\x\\xre sexy on the outside, malt liquor on the inside. horrible. but my husband, i first met him at this wedding and, uh, he\\xe\\x\\xs\\xe\\x\\x he\\xe\\x\\xs much better looking than me, he\\xe\\x\\xs way out of my league, and i saw him and i was like, \\xe\\x\\xcoh, my god, who is that?\\xe\\x\\xd and the first thing i learned about him was that, at the time, he was attending harvard business school. and i was like, \\xe\\x\\xcoh, my god, i\\xe\\x\\xm gonna trap his ass.\\xe\\x\\xd \\xe\\x\\xcgoing to trap his ass!\\xe\\x\\xd and i trapped his ass initially by not kissing him until the fifth date, which is a very unusual move on my part. but i did it on purpose, because i knew that he was a catch. so i was like, \\xe\\x\\xcall right, ali, you gotta make this dude believe that your body is a secret garden.\\xe\\x\\xd when, really, it\\xe\\x\\xs a public park\\xe\\x\\xa \\xe\\x\\xathat has hosted many reggae fests\\xe\\x\\xa \\xe\\x\\xaand has even accidentally let\\xe\\x\\xa two homeless people inside. i thought they were hipsters, ok? that store urban outfitters has made things very confusing\\xe\\x\\xa for my generation. you homeless or you a hipster? is that beard for fashion or for warmth? it happened to\\xe\\x\\xa it happened in san francisco, when i was living there, and i saw this guy in broad daylight and we had, like, we had\\xe\\x\\xa we had so much chemistry. he was like, \\xe\\x\\xchey, wassup?\\xe\\x\\xd i was like, \\xe\\x\\xcwassup?\\xe\\x\\xd and we\\xe\\x\\x the next thing i knew, we were getting busy in the back of my volvo. and then after we were done, he was like, \\xe\\x\\xchey, can you drop me off?\\xe\\x\\xd i was like, \\xe\\x\\xcwhere?\\xe\\x\\xd he was like, \\xe\\x\\xcat the park.\\xe\\x\\xd and i dropped him off at golden gate park and watched him run into the middle with all his other homeless friends, and i was like, \\xe\\x\\xcoh, no!\\xe\\x\\xd \\xe\\x\\xci just fucked a homeless dude! again!\\xe\\x\\xdq\\xx)\\xf\\x\\xmy husband is asian. which a lot of people are shocked by, because, usually, asian-american women who, like, you know, wear these kinda glasses and have a lot of opinions, they like to date white dudes. you go to any hipster neighborhood in a major city in america and that shit is turning into a yoko ono factory. it\\xe\\x\\xs\\xe\\x\\xa too much. i don\\xe\\x\\xt know what\\xe\\x\\xs wrong with these bitches. i get it, you know, because being with a white dude you feel very\\xe\\x\\xa you feel very picturesque when you\\xe\\x\\xre with a white dude, you know. you feel like you\\xe\\x\\xre in a wes anderson movie or something. and you know, white dudes, they teach you about a lot of cool stuff like voting and recycling, and disturbing documentaries. they introduce you to cool stuff like that and it\\xe\\x\\xs very, you know, it\\xe\\x\\xs hot hookin\\xe\\x\\x up with a white dude. i mean, nothing makes me feel more powerful than when a white dude eats my pussy. oh, my god. i just feel like i\\xe\\x\\xm absorbing all of that privilege and all of that entitlement\\xe\\x\\xa \\xe\\x\\xayou know, just right there, through the money hole and just\\xe\\x\\xa and then also, he\\xe\\x\\xs so vulnerable down there. i\\xe\\x\\xm, like, \\xe\\x\\xci could just crush your head at any moment, white man! i could just kill you right now! crush those brains! colonize the colonizer!\\xe\\x\\xd you know?\\nbut i think that for marriage, it can be nice to be with somebody of your own race. the advantage is that you get to go home\\xe\\x\\xa and be racist together. you get to say whatever you like! you don\\xe\\x\\xt gotta explain shit. my husband, half-filipino, half-japanese. i\\xe\\x\\xm half-chinese and half-vietnamese. and we spend  percent of our time shitting on korean people. it\\xe\\x\\xs\\xe\\x\\xa amazing. it\\xe\\x\\xs what love is built on, you know?\\nmy last boyfriend was cuban and his family would shit on mexican people all the time. and i was like, \\xe\\x\\xchold it. you guys aren\\xe\\x\\xt mexican?\\xe\\x\\xd asian-american men are very underrated. i don\\xe\\x\\xt know why people don\\xe\\x\\xt go for them. they\\xe\\x\\xre the sexiest. asian men are the sexiest. they got no body hair from the neck down. it\\xe\\x\\xs like making love to a dolphin. oh, my god. it\\xe\\x\\xs so smooth, just like a slip and slide. just black fish, tilikum, all up in my bed every night, you know? ooh-wee. you mess with a jewish dude and your body is all fucked up afterwards. it\\xe\\x\\xs all red and inflamed and you\\xe\\x\\xre like, \\xe\\x\\xci did not ask to be exfoliated today.\\xe\\x\\xd \\xe\\x\\xcthis is the last time i go on j-date, more like loofah date. thanks for the rug burn, avi.\\xe\\x\\xd and then asian men, no body odor. none. they just smell like responsibility. that\\xe\\x\\xs where the umami flavor comes from.\\ni think my husband and i have a huge unspoken understanding, uh, between each other, because he\\xe\\x\\xs half-filipino and half-japanese and i\\xe\\x\\xm half-chinese and half-vietnamese. so, we\\xe\\x\\xre both half-fancy asian\\xe\\x\\xa \\xe\\x\\xaand half-jungle asian. yeah! you guys know the difference. the fancy asians are the chinese, the japanese. they get to do fancy things like host olympics. jungle asians host diseases. it\\xe\\x\\xs\\xe\\x\\xa it\\xe\\x\\xs different. but he grew up on the east coast, going to private school, playing lacrosse, uh, you know, learning latin and playing chess and rugby. he grew up like filipino carlton, ok? so, he didn\\xe\\x\\xt know anything about vietnamese people until he met me. and on one of our first dates, he took me to this restaurant on the west side of los angeles called pho show. he was like, \\xe\\x\\xcit\\xe\\x\\xs authentic vietnamese. i read about it on yelp!\\xe\\x\\xd i was like, \\xe\\x\\xcit\\xe\\x\\xs not authentic, ok?\\xe\\x\\xd you can tell, first and foremost, by the name, \\xe\\x\\xcause it don\\xe\\x\\xt got a number in it. second of all, you can tell by the bathroom. if it was legit, the bathroom would double as a supply closet. when i pee, i need to see ten gallons of bleach, an atm machine and a grandma with glaucoma napping in the corner. and the wait staff here is too nice. we need to leave this restaurant deaf and emotionally abused.q\\xx;\\x\\x\\xi grew up going to private school, too. him and i are both total, like, private school asians. we both are big hippies, too. we like to backpack through southeast asia. we like to do yoga. we do ayahuasca ceremonies. we do silent meditation retreats. that\\xe\\x\\xs right, we pay $ to shut up for a weekend. we do shit like that. uh, we eat gluten-free, which means we eat all that bread that tastes like free-range chewbacca. we eat that lesbian bread that\\xe\\x\\xs like\\xe\\x\\xa \\xe\\x\\xaa thousand percent of your daily fiber\\xe\\x\\xa and  percent spoken word poetry. when you eat it, you queef a shitty poem about\\xe\\x\\xa \\xe\\x\\xasupporting caitlyn jenner or whatever. and so, it\\xe\\x\\xs funny, right, because he\\xe\\x\\xs asian, too. but sometimes, all of this hippy-dippy shit we do\\xe\\x\\xa makes me feel like we are white people doing an impression of asian people. like, we have these chinese scrolls up on the wall\\xe\\x\\xa and neither of us know what the fuck they mean. we\\xe\\x\\xre like, \\xe\\x\\xcoh, that seems to go very well with our buddha piggy bank from pier  imports. that seems to be providing some good feng shui for the house.q\\xx\\xac\\x\\x\\xhim and i had been dating for four years and i\\xe\\x\\x i just had this sneaking suspicion that he was gonna propose\\xe\\x\\xa because\\xe\\x\\xa i had been pressuring him to do it. so, you know, i just had this wacky women\\xe\\x\\xs intuition. that\\xe\\x\\xs how proposals really work, ok? a woman has to incept the idea into the man\\xe\\x\\xs head. first passively and then if he doesn\\xe\\x\\xt get the message, extremely aggressively. you gotta threaten to leave without ever actually leaving, because you know that you\\xe\\x\\xre too old and it\\xe\\x\\xs too late to go back out there and find a new man and start the whole manipulation cycle all over again. so, you\\xe\\x\\xre like, \\xe\\x\\xci\\xe\\x\\xm just gonna stick with this dude, focus on trapping this dude, and just nag the shit outta him until he becomes weak and caves in and gets fed up and is like, \\xe\\x\\xcshut the fuck up! fine, will you marry me?\\xe\\x\\xd and then afterwards, the woman is always, like, \\xe\\x\\xcoh, my god! he proposed!\\xe\\x\\xd \\xe\\x\\xcit came outta nowhere. and look, he got me the exact ring i wanted. how did he know? maybe he saw it on my pinterest page or something\\xe\\x\\xa that i sent to my best friend, that i told her to send to him every day.\\xe\\x\\xd let me tell you something. if a man has a pinterest page\\xe\\x\\xa he\\xe\\x\\xs probably pinterested in men. we got engaged on a saturday. i bought my wedding dress the following tuesday\\xe\\x\\xa because i had tried it on in . i was ready. i was ripe. i was rotten. i need to be made into banana bread. that\\xe\\x\\xs how rotten i was.q\\xx\\xb\\x\\x\\xpeople are always very surprised at how, off-stage, with my husband, i\\xe\\x\\xm a completely different person. you\\xe\\x\\x like, you would not recognize my personality at all with him. with him, i\\xe\\x\\xm very soft, and, like, very nurturing and very domestic. we\\xe\\x\\xve been together now for five years, and for five years, i\\xe\\x\\xve packed his lunch every single day. yeah. yes. yes. yes. i did that so that he\\xe\\x\\xd become dependent on me. \\xe\\x\\xcause he graduated from harvard business school, and i don\\xe\\x\\xt wanna work anymore. i don\\xe\\x\\xt. i straight up don\\xe\\x\\xt wanna work anymore. i don\\xe\\x\\xt feed him out of the goodness of my heart. i do it as an investment in my financial future. \\xe\\x\\xcause i don\\xe\\x\\xt wanna work anymore. i\\xe\\x\\xve been reading that book by sheryl sandberg, she\\xe\\x\\xs the c.o.o. of facebook, and she wrote that book that got women all riled up about our careers. talking about how we as women should challenge ourselves to sit at the table and rise to the top. and her book is called lean in. well, i don\\xe\\x\\xt wanna lean in, ok? i wanna lie down. i want to lie the fuck down. i think feminism is the worst thing that ever happened to women. our job used to be no job. we had it so good. we could have done the smart thing, which would have been to continue playing dumb for the next century and be like, \\xe\\x\\xcwe\\xe\\x\\xre dumb women. we don\\xe\\x\\xt know how to do anything. so, i guess we better just stay at home all day and eat snacks and watch ellen.\\xe\\x\\xd \\xe\\x\\xc\\xe\\x\\xcause we\\xe\\x\\xre too stupid to have any real responsibility.\\xe\\x\\xd and then, all these women had to show off and be like, \\xe\\x\\xcwe could do it! we could do anything.\\xe\\x\\xd \\xe\\x\\xcbitch, shut up!\\xe\\x\\xd \\xe\\x\\xcdon\\xe\\x\\xt tell them the secret.\\xe\\x\\xd they ruined it for us, and now we\\xe\\x\\xre expected to work. when i hear the phrase, \\xe\\x\\xcdouble-income household,\\xe\\x\\xd i wanna throw up. a lot of women get very upset with me about those comments. and they\\xe\\x\\xre like, \\xe\\x\\xcbut, ali, we have so many more options now.\\xe\\x\\xd oh, you don\\xe\\x\\xt think we had a lot of options when our day was free? unscheduled, unsupervised, and most importantly, sponsored? do you know how much shittier food tastes when you know you have to earn it?\\na lot of my friends, when we walk around together, they\\xe\\x\\xll get very judgmental about housewives that we\\xe\\x\\xll see on the street. and they\\xe\\x\\xll be like, \\xe\\x\\xclook at that fucking housewife. not doing anything. look at that housewife, just walking around all day, getting massages in her lululemon pants.\\xe\\x\\xd i\\xe\\x\\xm like, \\xe\\x\\xcthat bitch is a genius.\\xe\\x\\xd \\xe\\x\\xcshe\\xe\\x\\xs not a housewife, she\\xe\\x\\xs retired.\\xe\\x\\xd\\ni do write for fresh off the boat on abc. yeah. which is\\xe\\x\\xa it\\xe\\x\\xs a great show. i love it a lot. i love my co-workers. it\\xe\\x\\xs a great writing staff and in terms of day jobs, it\\xe\\x\\xs probably one of the best you could ask for, but i still gotta work at a office every day. which means i gotta shit in a office every day. housewives, they don\\xe\\x\\xt gotta shit in a office. housewives get to shit in their house. skin to seat. they don\\xe\\x\\xt gotta use that horrible toilet paper cover. they don\\xe\\x\\xt gotta\\xe\\x\\xa \\xe\\x\\xaten times a day, every day\\xe\\x\\xa like you\\xe\\x\\xre about to eat a sad-ass meal. they don\\xe\\x\\xt gotta do that. they don\\xe\\x\\xt gotta use that one-ply toilet paper, that office toilet paper, that they purposely make difficult to pull out. they try to ration me with their communist toilet paper that\\xe\\x\\xs not even effective. it basically just dehydrates your butt hole. it\\xe\\x\\xs basically like wiping your butt with the desert. i literally spat on my toilet paper two days ago, to try to make a macgyver baby wipe, to moisten it, and then it backfired \\xe\\x\\xcause my fingers broke through and digitally stimulated more doo doo to come out, and then i had to start all over again. and you can never finish wiping at work because you always feel rushed \\xe\\x\\xcause you\\xe\\x\\xre paranoid that your co-worker\\xe\\x\\xs gonna recognize your shoes underneath the stall. and you\\xe\\x\\xre like, \\xe\\x\\xcoh, no! courtney\\xe\\x\\xs listening. she\\xe\\x\\xs waiting. she\\xe\\x\\xs timing me.\\xe\\x\\xd and then you hurry, hurry, hurry, and then you never finish wiping and then your butt hole feels caked in doo doo all day long. and then if you dare scratch yourself, your underwear at the end of the day looks like it\\xe\\x\\xs been run over by the goonies. housewives, they don\\xe\\x\\xt gotta muffle their shit, too. they don\\xe\\x\\xt gotta worry about the velocity with which their doo doo comes out. they don\\xe\\x\\xt gotta try to, you know, squeeze the butt cheeks together to make sure that the doo doo comes out at a slow and steady pace, so that no unpredictable noise suddenly escapes and brings you deep, deep shame. housewives are free to just blow ass into the toilet and let it echo and reverberate to the ends of their hallways while watching as much netflix on their ipad as they want. they don\\xe\\x\\xt gotta take these boring, repressed shits. they can listen to podcasts. planet money. they can do whatever they want.\\nyou know, it\\xe\\x\\xs\\xe\\x\\x it\\xe\\x\\xs very distracting for me when i hear my co-workers blow ass into the toilet. i lose respect for them. nothing they say to me anymore holds any sort of credence. i heard one of my co-workers blow ass into the toilet the other day. this bitch had the nerve to come up to me and say, \\xe\\x\\xcyou need to get to work on time.\\xe\\x\\xd i was like, \\xe\\x\\xcyou need to eat bananas.\\xe\\x\\xd \\xe\\x\\xci saw those green ballet flats. i know that shit was you. don\\xe\\x\\xt try to tell me to get my shit together when i heard you not have your shit together.\\xe\\x\\xdq\\xx\\xe\\xb\\x\\xmy father-in-law had this huge sit-down with me and my husband recently. um, and he was like, \\xe\\x\\xchey, i wanna talk to you guys about money. you guys need to make a lot more money if you wanna provide your children with the same kind of privileged childhood that you guys had.\\xe\\x\\xd i was like, \\xe\\x\\xcwhy you telling me this shit? i should not be a part of this conversation. you tell you son that. don\\xe\\x\\xt your understand that i trapped your son for his earning potential? why else would i choose to fuck one person for the rest of my life? i chose to marry him on the promise of early retirement, and when i said, \\xe\\x\\xi do,\\xe\\x\\x what i really meant was, \\xe\\x\\xoh, i\\xe\\x\\xm done.'\\xe\\x\\xd i\\xe\\x\\xm done. i don\\xe\\x\\xt wanna work anymore and i\\xe\\x\\xm not dieting anymore. since i got married last year, i\\xe\\x\\xve been eating fried chicken skin every day since. that\\xe\\x\\xs right. and just fulfilling my destiny. which is to turn into a circle with eyelashes. like mrs. pacman, just\\xe\\x\\xa let\\xe\\x\\xs redecorate.\\ni gave up a lot of myself when i got married. i\\xe\\x\\xm a\\xe\\x\\x i\\xe\\x\\xm a disgusting pervert. i\\xe\\x\\xm a pervert. i\\xe\\x\\xm a gross filthy animal. and i think it\\xe\\x\\xs because i started watching porn at a very young age. and what happens when you start watching porn at a young age is that\\xe\\x\\xa y-you get sicker, and sicker, and sicker. the images you crave get sicker, and sicker, and sicker, but it\\xe\\x\\xs ok, because the internet will always catch up to you.\\ni broke up with my last boyfriend because he refused to put it in the back. i was like, \\xe\\x\\xcuh, you\\xe\\x\\xre a idiot, dude. do you realize that if i went on craigslist\\xe\\x\\xa and posted \\xe\\x\\xtiny asian female seeking anal\\xe\\x\\xa\\xe\\x\\x the internet would crash.\\xe\\x\\xd \\xe\\x\\xcand all the jewish male heads in the universe would simultaneously explode.\\xe\\x\\xd they would explode. a lot of women get really, you know\\xe\\x\\xa freaked out about anal. and they\\xe\\x\\xre like, \\xe\\x\\xcoh, i don\\xe\\x\\xt wanna do that. i\\xe\\x\\xm scared of\\xe\\x\\x of the pain.\\xe\\x\\xd you ain\\xe\\x\\xt scared of the pain. women, they wax their eyebrows, they do all sorts of crazy shit. you\\xe\\x\\xre not scared of the pain. what you\\xe\\x\\xre really scared of is doo doo on the dick. you\\xe\\x\\xre scared that he\\xe\\x\\xs gonna see that and that\\xe\\x\\xs gonna be all of your shame, your inner evil, all your secrets and lies. sephora can\\xe\\x\\xt help you now. but don\\xe\\x\\xt worry, \\xe\\x\\xcause when he puts it in the butt, all he\\xe\\x\\xs thinking about is, \\xe\\x\\xci just put it in her butt.\\xe\\x\\xd \\xe\\x\\xci gotta go call my mom, my dad, dave, my grandma.\\xe\\x\\xd you\\xe\\x\\xre\\xe\\x\\x if you\\xe\\x\\xre married, you\\xe\\x\\xre gonna have to do anal eventually, ok? you have to, because you gotta change it up. you gotta change it up, so that you don\\xe\\x\\xt cheat on each other. you gotta keep it interesting. if you put it in different holes, maybe you\\xe\\x\\xll feel like you\\xe\\x\\xre fucking different people. i was very sexually active in my s, and as a result, i\\xe\\x\\xm a little bit\\xe\\x\\xa \\xe\\x\\xastretched out down there, ok? so, when i finally did anal, i just felt like i got a second chance at life, you know? i was, like, \\xe\\x\\xcoh, my god! it\\xe\\x\\xs like i\\xe\\x\\xm going back in time!\\xe\\x\\xd \\xe\\x\\xaa a whole new world \\xe\\x\\xaa it was magical.q\\txe\\x\\x\\xa big fantasy of mine before i got married was to help as many men as possible discover their prostate. yeah, like a conqueror. i just wanted to\\xe\\x\\xa now, if you haven\\xe\\x\\xt done it before, ladies, go home and treat yourself. do it tonight. you only live once. yolo. just sneak your\\xe\\x\\x just give your man a little\\xe\\x\\x a little push-push in the tush-tush. just give him a little atari, you know, and you\\xe\\x\\xll get a lot of resistance from the man at first. you\\xe\\x\\xll get a lot of \\xe\\x\\xcno! no! no! no, please! no, really, i don\\xe\\x\\xt\\xe\\x\\x no! i don\\xe\\x\\xt! i don\\xe\\x\\xt! no!\\xe\\x\\xd they get all squirmy wormy because\\xe\\x\\xa they\\xe\\x\\xre scared. they\\xe\\x\\xre scared that if you stick your thumb up there and succeed, and they like it, that then, it might mean that they\\xe\\x\\xre gay. and i like that fear. that shit turns me on, you know? especially when that fear metamorphosizes into pleasure. oh, my god! and you just see the look in the man\\xe\\x\\xs eye like he\\xe\\x\\xs discovered nirvana. and it\\xe\\x\\xs like you\\xe\\x\\xre the first lady to show him that he had a magical clit in his butt hole. and then, you as the woman, in his eyes, just become the lord of the rim, you know?q\\nxn\\x\\x\\xmy husband is unfortunately just not as freaky as me. when\\xe\\x\\x when i\\xe\\x\\xve asked him to spank me, this is what he does. \\xe\\x\\xchey. hey, are you ok? are you all right? you know i respect you, right?\\xe\\x\\xd i\\xe\\x\\xm, like, \\xe\\x\\xcyes, i know you respect me and that\\xe\\x\\xs why you need to abuse me. ok?\\xe\\x\\xd \\xe\\x\\xcause it\\xe\\x\\xs the most strong-headed, loud-mouthed women who like to be abused the most in bed. women who are c.e.o.s, they just wanna be roughed around. they just want their\\xe\\x\\x glasses always means the woman wants some\\xe\\x\\x it\\xe\\x\\xs because we\\xe\\x\\xre so in control all the time, that we just wanna experience some risk and be out of control, you know? like, \\xe\\x\\xci don\\xe\\x\\xt wanna die! don\\xe\\x\\xt kill me! i don\\xe\\x\\xt wanna die!\\xe\\x\\xd but i also don\\xe\\x\\xt want to be sure that i\\xe\\x\\xm gonna live. you know? i just wanna be out of control for once. just\\xe\\x\\x just choke me enough so that i can\\xe\\x\\xt talk. \\xe\\x\\xcause if i can talk, i\\xe\\x\\xm gonna tell you what to do. and i\\xe\\x\\xm tired of being the boss. i\\xe\\x\\xm the boss all the time, so, in the bedroom, you be the boss. yes. because i\\xe\\x\\xm the real boss. and i told you so, motherfucker, so do it.q\\xbx\\xca\\x\\x\\xsheryl sandberg, that woman who wrote lean in, has had such a big impact that now, because of her, there is a ban on the word \\xe\\x\\xcbossy\\xe\\x\\xd in elementary schools, because according to her, it\\xe\\x\\xs sexist to use the word \\xe\\x\\xcbossy,\\xe\\x\\xd because boys are never called bossy. so, now, instead of saying, \\xe\\x\\xcyou\\xe\\x\\xre bossy,\\xe\\x\\xd you\\xe\\x\\xre supposed to say, \\xe\\x\\xcyou have executive leadership skills.\\xe\\x\\xd which is a very roundabout way of saying: \\xe\\x\\xcyou\\xe\\x\\xre a little cunt.\\xe\\x\\xdq\\xcx\\xdf\\x\\x\\xi\\xe\\x\\xm just waiting for the right moment to, like, become a housewife, financially, you know? i want my husband to get us to, like, a certain point financially. i wanna get to the point as a couple where i can comfortably afford sliced mango. know what i\\xe\\x\\xm talking about? i\\xe\\x\\xm talking about that whole foods mango. that $-a-box whole foods mango that was sliced by white people. that\\xe\\x\\xs the kind of income bracket i\\xe\\x\\xm striving for. that\\xe\\x\\xs when you know you\\xe\\x\\xve made it, when you\\xe\\x\\xre eating mango that was sliced by a dude named noah. i want noah mango\\xe\\x\\xa \\xe\\x\\xarebecca kiwi, danielle pineapple. you know what else i want? i wanna be able to take a stroll on a sidewalk, see a quarter, and just keep on walking. like a princess.q\\rx}\\x\\x\\xi have some useful advice for all my asian-american brothers and sisters. yeah! never go paintballing with a vietnam veteran.q\\xex~\\xb\\x\\xso, i don\\xe\\x\\xt know if you guys can tell, but i am seven and a half months pregnant. yeah. it\\xe\\x\\xs very rare and unusual to see a female comic perform pregnant, because female comics\\xe\\x\\xa don\\xe\\x\\xt get pregnant. just try to think of one. i dare you. there\\xe\\x\\xs\\xe\\x\\x none of them. once they do get pregnant, they generally disappear. that\\xe\\x\\xs not the case with male comics. once they have a baby, they\\xe\\x\\xll get up on stage a week afterwards and they\\xe\\x\\xll be like, \\xe\\x\\xcguys, i just had this fucking baby. that baby\\xe\\x\\xs a little piece of shit. it\\xe\\x\\xs so annoying and boring.\\xe\\x\\xd and all these other shitty dads in the audience are, like, \\xe\\x\\xcthat\\xe\\x\\xs hilarious. i identify.\\xe\\x\\xd and their fame just swells because they become this relatable family funny man all of a sudden. meanwhile, the mom is at home, chapping her nipples, feeding the fucking baby, and wearing a frozen diaper \\xe\\x\\xcause her pussy needs to heal from the baby\\xe\\x\\xs head shredding it up. she\\xe\\x\\xs busy. so, i don\\xe\\x\\xt know what\\xe\\x\\xs gonna happen to me. you know, a lot of my female stand-up comic friends who are a lot more successful and famous than me discouraged me from having a kid. and they were like, \\xe\\x\\xcali, why are you gonna have a kid? you just gonna become\\xe\\x\\x you\\xe\\x\\xre gonna disappear, and you\\xe\\x\\xre gonna become some lame stay-at-home mom.\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, that\\xe\\x\\xs the dream.\\xe\\x\\xd that\\xe\\x\\xs the point. this is the ultimate trap. i won, you know?\\nanother thing a lot of my friends said to me when they were discouraging me from having a kid, they were like, \\xe\\x\\xcwhy are you gonna have a kid? why don\\xe\\x\\xt you just travel the world with your husband and just do whatever you want for the rest of your lives with no kid attached.\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, that\\xe\\x\\xs cool\\xe\\x\\xa until my husband dies.\\xe\\x\\xd which he\\xe\\x\\xs definitely gonna before me. because i\\xe\\x\\xm a asian woman, and therefore, guaranteed to live until i\\xe\\x\\xm a billion. i\\xe\\x\\xm guaranteed, like a turtle from the galapagos, ok? we all know the phrase \\xe\\x\\xcblack don\\xe\\x\\xt crack.\\xe\\x\\xd well, asian don\\xe\\x\\xt die. we don\\xe\\x\\xt die. especially the women, we live forever. and you know why we\\xe\\x\\xre such bad drivers? because we\\xe\\x\\xre trying to die. we\\xe\\x\\xre like, \\xe\\x\\xcyeah! let me see how invincible i really am!\\xe\\x\\xd \\xe\\x\\xcimma make this left hand turn signal and ignore this red light completely.\\xe\\x\\xd \\xe\\x\\xci\\xe\\x\\xm gonna make a right turn\\xe\\x\\x i changed my mind, it\\xe\\x\\xs a u-turn!\\xe\\x\\xd \\xe\\x\\xci changed my mind again. it\\xe\\x\\xs a o-turn!\\xe\\x\\xd every time i get into a car accident\\xe\\x\\xa \\xe\\x\\xai\\xe\\x\\xm like, \\xe\\x\\xcoh, my god, not again!\\xe\\x\\xd i need to hide my face so that everybody doesn\\xe\\x\\xt see that it\\xe\\x\\xs what everybody thought it was gonna be. so embarrassing. my toyota corolla is a mess. there\\xe\\x\\xs this huge bear claw scratch on the side from this aggressive brick wall that came out of nowhere. and then, on the hood, there\\xe\\x\\xs multiple hand prints from pedestrians who have had to alert me of their existence. i don\\xe\\x\\xt know what\\xe\\x\\xs wrong with me, but i\\xe\\x\\xm still here, you know?q\\xfx\\xb\\x\\x\\xi need to have children to keep me company when i get older. it\\xe\\x\\xs lonely. my mom is , going through a full blown mid-life crisis. \\xe\\x\\xcause she knows that she\\xe\\x\\xs got a century more to go. and she is so lonely. all of her white friends, dead. her mexican friends, dead. black friends, dead. i\\xe\\x\\xm just kidding. she doesn\\xe\\x\\xt have any black friends. life is not rush hour, the movie, ok? i need children to be there for me when i\\xe\\x\\xm older, when i get as old as her. and when i say be there for me, i mean pay for me when my husband isn\\xe\\x\\xt around to support me anymore. i\\xe\\x\\xm not trying to be one of those old chinese ladies who recycles for a living. that\\xe\\x\\xs not my destiny, ok? old chinese ladies, they don\\xe\\x\\xt give a fuck. they got no shame. they\\xe\\x\\xre like, \\xe\\x\\xci\\xe\\x\\xm just gonna recycle\\xe\\x\\xa go bald\\xe\\x\\xa go to the park, do this shit.\\xe\\x\\xd they do that \\xe\\x\\xcause it\\xe\\x\\xs a free activity. for them. they do it in their\\xe\\x\\x their big-ass v. stiviano visor, their darth vader-tomb raider- boba fett helmet. they wear that to protect themselves from their arch-nemesis, the sun. their in a contest to see who\\xe\\x\\xs gonna burn out first. old asian ladies and the sun are like the tupac and biggie of longevity.q\\xx\\xcc\\x\\x\\xi also decided to have a kid because uh, i\\xe\\x\\xm only , which, i know, is not technically high-risk, but my body was starting to show signs of change. and it\\xe\\x\\x and it scared me. like, i\\xe\\x\\xm only  and\\xe\\x\\xa \\xe\\x\\xamy pussy is not as wet as it used to be. it\\xe\\x\\xs very demoralizing, ok? do you remember when you were  years old, and your pussy was just sopping wet all the time? all the time, you just took it for granted that you could just reach your hand down your pants at any given moment, you throw up the peace sign afterwards, and there would be that snail-trail in between your fingers. oh, my god, it was so juicy. you could just blow a bubble wand with it, just\\xe\\x\\xa \\xe\\x\\xci slime you, i slime you. ghostbusters!\\xe\\x\\xdq\\xx\\x\\x\\x\\xi don\\xe\\x\\xt know what kind of mother i\\xe\\x\\xm gonna be. i\\xe\\x\\xm\\xe\\x\\x i\\xe\\x\\xm , and i did have to get a little bit of science involved when trying to get pregnant. and a lot of that\\xe\\x\\xa is most likely my fault. because, when i was in my s, i ate plan b like skittles. so, my uterus probably looked like a smoker\\xe\\x\\xs lung. and i found out that my progesterone levels were alarmingly low. so, then i had to take these hormone pills that were suppositories, and push pop them up myself every single night. and then, at my writing job, at fresh off the boat, i would be storyboarding in front of my co-workers, and then, at some point, the pill would inevitably dissolve and melt into my underwear, and i had to act like everything was ok, when everything was clearly not ok. and then, a side effect of the progesterone was that it made me extremely itchy. so, then i had to find ways to discretely scratch myself underneath the conference table, and then resist the urge to immediately smell my fingers afterwards. i want to be able to smell my fingers when i wanna smell my own goddamn fingers. housewives, they can just scratch and sniff all day long. they just vacuum, scratch, sniff. they make a sandwich. \\xe\\x\\xcuh, mmm.\\xe\\x\\xd they watch property brothers, scratch, \\xe\\x\\xcwhat\\xe\\x\\xs crackin\\xe\\x\\x? mmm.\\xe\\x\\xd every time you scratch yourself, all you can think about is, \\xe\\x\\xcwhen can i smell my fingers? when can i smell my fingers? when can i discretely find a way to\\xe\\x\\xa\\xe\\x\\xd \\xe\\x\\xc\\xe\\x\\xasmell my fingers?\\xe\\x\\xd nature made you urgently curious to protect you, \\xe\\x\\xcause you gotta check that it\\xe\\x\\xs all good in the hood. if it\\xe\\x\\xs too funky, you need to see a doctor. your fingers are your first webmd.q\\xx\\xa\\t\\x\\xwhen my husband and i were trying to have a kid, a lot of people were like, \\xe\\x\\xcoh, my god, that\\xe\\x\\xs so hot. you guys doin\\xe\\x\\x a lot of fuckin\\xe\\x\\x?\\xe\\x\\xd no, dude. that\\xe\\x\\xs\\xe\\x\\x that\\xe\\x\\xs shit you do in your s, ok? when in\\xe\\x\\x when you\\xe\\x\\xre in your s, and you\\xe\\x\\xve been trying to get pregnant for a while, it gets very clinical. you pee on these ovulation strips that tell you when the eggs are droppin\\xe\\x\\x. it tells you when it\\xe\\x\\xs easter time. and i would only fuck him when it was easter time. it was, like, only four days out of the month, and outside of that, i would be like, \\xe\\x\\xcwe\\xe\\x\\xre not fuckin\\xe\\x\\x. i need you to save it. i want your sperm to be as pent-up, and as angry and rapey as possible. so that, when they come out, it\\xe\\x\\xs like, \\xe\\x\\xrelease the kraken!'\\xe\\x\\xd and they just come out like a bunch of angry refugees escaping a dictatorship, you know? and, um\\xe\\x\\xa yeah, and most of the time, like, we wouldn\\xe\\x\\xt even have sex, \\xe\\x\\xcause i was so tired when i would come home, and see the smiley face on the ovulation strip, and i\\xe\\x\\xd be like, \\xe\\x\\xcok, it\\xe\\x\\xs go time,\\xe\\x\\xd and i would just give my husband a hand job most of the time, and he would close his eyes immediately. i know what that means, ok? when somebody closes their eyes during sex, it\\xe\\x\\xs not because they\\xe\\x\\xre in such ecstasy with you that\\xe\\x\\x that they need to close their eyes. when somebody closes their eyes during sex, it\\xe\\x\\xs because they\\xe\\x\\xre literally trying to shut the image of your face out of their head and instead project two latina lesbians that they saw earlier that day on redtube onto the back of their eyelids. which is fine by me, because then he doesn\\xe\\x\\xt have to see the expression on my face that says, \\xe\\x\\xcplease, hurry the fuck up.\\xe\\x\\xd and then, when he was about to finish, i could always tell because the indication is very universal when a man is about to finish. it\\xe\\x\\xs when they get that\\xe\\x\\xa that stupid-ass look on their face\\xe\\x\\xa \\xe\\x\\xawhere they look like they just got bit by a zombie, just\\xe\\x\\xa and then, because we\\xe\\x\\xre hippies, i\\xe\\x\\xd be like, \\xe\\x\\xchey, hey! please look me in the eye and remember to come with intention, ok?\\xe\\x\\xd and then, i would jump on him, and hold onto his neck, and i would just twerk, twerk, twerk the shit out of him\\xe\\x\\xa and do some of this shit that i learned in atlanta. and then i would turn upside down immediately afterwards\\xe\\x\\xa to make sure all of that harvard nectar would just drain inside of me. that\\xe\\x\\xs right. \\xe\\x\\xcause i don\\xe\\x\\xt wanna work anymore.q\\xx\\xd\\x\\x\\xi\\xe\\x\\xm very grateful to be pregnant and to be\\xe\\x\\xa this far along, to be seven and a half months pregnant, because, last year, i had a miscarriage, which is very common. and a lot of women who are in their s flip out when they hear that. they\\xe\\x\\xre like, \\xe\\x\\xcoh, my god. that\\xe\\x\\xs so dark and terrible. i can\\xe\\x\\xt believe that.\\xe\\x\\xd i\\xe\\x\\xm . girl, when you\\xe\\x\\xre , you\\xe\\x\\xll know plenty of women who have had a miscarriage. it\\xe\\x\\xs super common, and i wish more women would talk about it so they wouldn\\xe\\x\\xt feel so bad when they go through it. when i told my mom\\xe\\x\\x she\\xe\\x\\xs from a third world country, and when i told her i had one, she was like, \\xe\\x\\xcuh, yeah. where i\\xe\\x\\xm from, that\\xe\\x\\xs like losing a pair of shoes. it\\xe\\x\\xs whatevs, ok?\\xe\\x\\xd and everything happens for a reason. i found out at my six-week sonogram, which is very early. and the doctor says to me, \\xe\\x\\xcoh, my god, i see two sacks, which means you\\xe\\x\\xre having twins.\\xe\\x\\xd and i was like, \\xe\\x\\xcno!\\xe\\x\\xd and then she said, \\xe\\x\\xcbut what i don\\xe\\x\\xt see is a heartbeat.\\xe\\x\\xd and i was like, \\xe\\x\\xcyes!\\xe\\x\\xd \\xe\\x\\xcthe lord is mysterious!\\xe\\x\\xd don\\xe\\x\\xt feel bad, ok? they were the size of poppy seeds. i\\xe\\x\\xve picked boogers larger than the twins that i lost. and most women won\\xe\\x\\xt let their husbands watch when they\\xe\\x\\xre going through a miscarriage. i sat my husband down in front of me while i sat on the toilet, and i was like, \\xe\\x\\xcyou look.\\xe\\x\\xd \\xe\\x\\xcyou watch the whole thing.\\xe\\x\\xd and he felt so bad for me. and i used it as leverage and held that shit over his head for a month and got him to do whatever the fuck i wanted him to do for  days. he took me to see beyonc\\xc\\xa. he bought me a bike off of craigslist. that\\xe\\x\\xs my miscarriage bike, and i love it very much. for  days, i finally had the marriage i always wanted.q\\xx\\xdc\\x\\x\\xi\\xe\\x\\xm scared about giving childbirth, though. i\\xe\\x\\xm\\xe\\x\\x i\\xe\\x\\xm very, very scared of childbirth. that\\xe\\x\\xs why i\\xe\\x\\xm going to hire a doula. you know what that is? you know what a doula is? that\\xe\\x\\xs a white hippie witch\\xe\\x\\xa \\xe\\x\\xathat blows quinoa into your pussy to keyser s\\xc\\xbze all the pain away. a lot of women tried to freak me out. they tried to freak me out about childbirth by saying, \\xe\\x\\xcali, did you know that you\\xe\\x\\xre gonna poop on the table?\\xe\\x\\xd i was like, \\xe\\x\\xcyeah, i look forward to it.\\xe\\x\\xd i\\xe\\x\\xm all backed up from holding in my shit at work. i can\\xe\\x\\xt wait to cleanse. it makes sense, like, that you\\xe\\x\\x that that happens because when you\\xe\\x\\xre in labor, you push, you push, you push, and your husband will be asked to assist in the labor by lifting up your leg, which subsequently turns into a soft serve lever. you just shit on the floor in front of the love of your life. and just when you think that\\xe\\x\\xs enough to make him finally leave you, boom, a baby comes out, and he gotta stay. that\\xe\\x\\xs the real miracle of life, right there. i can already see how a child can really take its toll on a marriage, because the baby hasn\\xe\\x\\xt even come out yet and i am already so resentful towards my husband. so much resentment, especially when he asks me to do shit around the house. \\xe\\x\\xchey, can you wash the dishes?\\xe\\x\\xd \\xe\\x\\xcno!\\xe\\x\\xd \\xe\\x\\xccan you water the plants?\\xe\\x\\xd \\xe\\x\\xci am not doing jack shit anymore. i\\xe\\x\\xm busy makin\\xe\\x\\x a eyeball, ok? are you makin\\xe\\x\\x a foot? i didn\\xe\\x\\xt think so. you change the channel.\\xe\\x\\xdq\\xx\\xe\\x\\x\\xi can already see how there\\xe\\x\\xs, like, this crazy double standard in our society of how it takes so little to be considered a great dad. and it also takes so little to be considered a shitty mom. people praise my husband for coming to all of my doctor\\xe\\x\\xs appointments with me. \\xe\\x\\xcoh, my god. i can\\xe\\x\\xt believe he comes to all your doctor\\xe\\x\\xs appointments. he is so supportive.\\xe\\x\\xd guess who else has to go to those doctor appointments. me! i\\xe\\x\\xm the star of the show. there\\xe\\x\\xs nothing for the camera to see if i\\xe\\x\\xm not there. but he\\xe\\x\\xs the hero for playing candy crush while i get my blood drawn. meanwhile, if i do mushrooms seven months pregnant, i\\xe\\x\\xm a bad mommy.q\\xx~\\x\\x\\xyou know, i\\xe\\x\\x i\\xe\\x\\x i, like, i berate my husband on, like, a daily basis. partially because i really am mad at him. but mostly out of survival, because if he leaves me, i\\xe\\x\\xm fucked. so, i have to chip away at his self-esteem on a daily basis\\xe\\x\\xa to keep him down so that he doesn\\xe\\x\\xt believe that he\\xe\\x\\xs worthy of another woman\\xe\\x\\xs affection and leaves me. i gotta keep him around by keeping him down. people don\\xe\\x\\xt tell you about all this shit that goes down with your body when you get pregnant, you know? your nipples get huge and dark. i didn\\xe\\x\\xt know that. i didn\\xe\\x\\xt know that they get dark so that the baby can see, like, a bullseye. so that the baby can find it easier. and then, you know, they get big\\xe\\x\\x they get big, like fingers. like, \\xe\\x\\xcyou, you. you owe me money, you.\\xe\\x\\xd my nipples look like whoppers now, and naked, i look like a minion. but i\\xe\\x\\xm not gonna be one of those crazy pregnant ladies who tries to get all back in shape right after they get pregnant. no. hopefully, if you see me in a year, i will have the kind of body where, if i do a nude scene on television, people will commend me for being courageous. for doing it.q\\xx\\xbf\\x\\x\\xnow that i\\xe\\x\\xm seven and a half months pregnant, my pussy\\xe\\x\\xs all wet again. but it\\xe\\x\\xs different. it\\xe\\x\\xs not like when i was  years old, when it was like, really hot, you know? and i was like, \\xe\\x\\xcwhy is it different?\\xe\\x\\xd and i looked it up, and my pussy\\xe\\x\\xs all wet again because my\\xe\\x\\x my body\\xe\\x\\xs secreting mucus to protect the baby from bacteria attacking it. that\\xe\\x\\xs not the same. when it\\xe\\x\\xs straight up soldier glue, when it\\xe\\x\\xs neosporin.q\\xx\\xd\\x\\x\\xso, you know, i\\xe\\x\\x i, in\\xe\\x\\x previously, before i met my husband, i had dated a bunch of losers. and then, i meet this dream guy, who\\xe\\x\\xs, like, way more handsome than me, out of my league, graduated from harvard business school. worked hard to trap his ass. got him to propose to me. oh, my god, then we got married, all my dreams coming true, and then we got pregnant, and recently we bought our first home together. and, uh, two weeks into the escrow process, i discovered that my beautiful, harvard-educated husband was $, in debt. and me, with my hard-earned tv money, paid it all off. so, as it turns out, he\\xe\\x\\xs the one who trapped me. how did he do it? how did he bamboozle me? oh! maybe because he went to harvard business school, the epicenter of white-collar crime. he enron\\xe\\x\\xd my ass. and now, if i don\\xe\\x\\xt work, we die. why else do you think i\\xe\\x\\xm performing seven and a half months pregnant? all right, i\\xe\\x\\xve been ali wong. have a good night, everybody. thank you.q\\xe.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpNH7nEceZKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}